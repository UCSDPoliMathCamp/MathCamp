[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UCSD Political Science Math Camp",
    "section": "",
    "text": "This booklet is adapted from the Harvard Gov Prefresher booklet, maintained by Shiro Kuriwaki. It will serve as as the text for the UCSD Math Camp, taught by Bertrand Wilden and Keng-Chi Chang, and we have reordered and adapted it to fit the structure of our course. For information about the role of this math camp as an introduction to graduate school, you may be interested in “The Math Prefresher and The Collective Future of Political Science Graduate Training”, in PS: Political Science & Politics, by Gary King, Shiro Kuriwaki, and Yon Soo Park.\n\nFor information about the authors of the Harvard Gov Prefresher booklet, see here.\nWe have also updated it to include some material from previous instructors of the class at UCSD, including Rachel Schoner (2021), Luke Sanford (2019-2020), Kathryn Baragwanath (2019-2020), Brandon Merrell (2018), Inbok Rhee (2018).\n\nWe transitioned the booklet into a bookdown github repository in 2021. As we update this version, we appreciate any bug reports or fixes appreciated.\nAll changes should be made in the .Rmd files in the project root. To contribute a change, please make a pull request and set the repository maintainer as the reviewer."
  },
  {
    "objectID": "00_warmup.html",
    "href": "00_warmup.html",
    "title": "Warmup Questions",
    "section": "",
    "text": "Before our first meeting, please try solving these questions. They are a sample of the very beginning of each math section. We have provided links to the parts of the book you can read if the concepts are new to you.\nThe goal of this “pre”-math camp assignment is not to intimidate you but to set common expectations so you can make the most out of the actual Math Camp. Even if you do not understand some or all of these questions after skimming through the linked sections, your effort will pay off, and you will be better prepared for the math camp. We are also open to adjusting these expectations based on feedback (this class is for you), so please do not hesitate to write to the instructors for feedback."
  },
  {
    "objectID": "00_warmup.html#operations",
    "href": "00_warmup.html#operations",
    "title": "Warmup Questions",
    "section": "Operations",
    "text": "Operations\nSummation\nSimplify the following\n\n\\sum\\limits_{i = 1}^3 i\n\\sum\\limits_{k = 1}^3(3k + 2)\n\\sum\\limits_{i= 1}^4 (3k + i + 2)\nProducts\n\n\\prod\\limits_{i= 1}^3 i\n\\prod\\limits_{k=1}^3(3k + 2)\nLogs and exponents\nSimplify the following:\n\n4^2\n4^2 2^3\n\\log_{10}100\n\\log_{2}4\n\n\\log e, where \\log is the natural log (also written as \\ln) – a log with basee, and e is Euler’s constant\n\ne^a, e^b, e^c, where a, b, c are each constants\n\\log 0\ne^0\ne^1\n\\log e^2"
  },
  {
    "objectID": "00_warmup.html#limits",
    "href": "00_warmup.html#limits",
    "title": "Warmup Questions",
    "section": "Limits",
    "text": "Limits\nFind the limit of the following.\n\n\\lim\\limits_{x \\to 2} (x - 1)\n\\lim\\limits_{x \\to 2} \\frac{(x - 2) (x - 1)}{(x - 2)}\n\\lim\\limits_{x \\to 2}\\frac{x^2 - 3x + 2}{x- 2}"
  },
  {
    "objectID": "00_warmup.html#linear-algebra",
    "href": "00_warmup.html#linear-algebra",
    "title": "Warmup Questions",
    "section": "Linear Algebra",
    "text": "Linear Algebra\nVectors\nDefine the vectors\nu = \\begin{pmatrix} 1 \\\\2 \\\\3 \\end{pmatrix},\nv = \\begin{pmatrix} 4\\\\5\\\\6 \\end{pmatrix},\nand the scalar c = 2.\nCalculate the following:\n\nu + v\ncv\nu \\cdot v\n\nAre the following sets of vectors linearly independent?\n\nu = \\begin{pmatrix} 1\\\\ 2\\end{pmatrix}, v = \\begin{pmatrix} 2\\\\4\\end{pmatrix}\nu = \\begin{pmatrix} 1\\\\ 2\\\\ 5 \\end{pmatrix}, v = \\begin{pmatrix} 3\\\\ 7\\\\ 9 \\end{pmatrix}\na = \\begin{pmatrix} 2\\\\ -1\\\\ 1 \\end{pmatrix}, b = \\begin{pmatrix} 3\\\\ -4\\\\ -2 \\end{pmatrix}, c = \\begin{pmatrix} 5\\\\ -10\\\\ -8 \\end{pmatrix} (this requires some guesswork)\nMatrices\nGiven that\n\n\\mathbf{A}=\\begin{bmatrix}\n            7 & 5 & 1 \\\\\n            11 & 9 & 3 \\\\\n            2 & 14 & 21 \\\\\n            4 & 1 & 5\n        \\end{bmatrix}\n\nWhat is the dimensionality of matrix \\mathbf{A}?\nWhat is the element a_{23} of \\mathbf{A}?\nGiven that\n\n\\mathbf{B}\n=\n\\begin{bmatrix}\n    1 & 2 & 8 \\\\\n    3 & 9 & 11 \\\\\n    4 & 7 & 5 \\\\\n    5 & 1 & 9\n\\end{bmatrix}\n\nWhat is \\mathbf{A} + \\mathbf{B}?\nGiven that\n\n\\mathbf{C}=\\begin{bmatrix}\n            1 & 2 & 8 \\\\\n            3 & 9 & 11 \\\\\n            4 & 7 & 5\n        \\end{bmatrix}\n\nWhat is \\mathbf{A} + \\mathbf{C}?\nGiven that\n\nc = 2\n\nWhat is c {\\bf A}?"
  },
  {
    "objectID": "00_warmup.html#calculus",
    "href": "00_warmup.html#calculus",
    "title": "Warmup Questions",
    "section": "Calculus",
    "text": "Calculus\nFor each of the following functions f(x), find the derivative f'(x) or \\frac{d}{dx}f(x)\n\nf(x)=c\nf(x)=x\nf(x)=x^2\nf(x)=x^3\nf(x)=3x^2+2x^{1/3}\nf(x)=(x^3)(2x^4)"
  },
  {
    "objectID": "00_warmup.html#optimization",
    "href": "00_warmup.html#optimization",
    "title": "Warmup Questions",
    "section": "Optimization",
    "text": "Optimization\nFor each of the followng functions f(x), does a maximum and minimum exist in the domain x \\in \\mathbf{R}? If so, for what are those values and for which values of x?\n\nf(x) = x\nf(x) = x^2\nf(x) = -(x - 2)^2\n\nIf you are stuck, please try sketching out a picture of each of the functions."
  },
  {
    "objectID": "00_warmup.html#probability",
    "href": "00_warmup.html#probability",
    "title": "Warmup Questions",
    "section": "Probability",
    "text": "Probability\n\nIf there are 12 cards, numbered 1 to 12, and 4 cards are chosen, how many distinct possible choices are there? (unordered, without replacement)\nLet A = \\{1,3,5,7,8\\} and B = \\{2,4,7,8,12,13\\}. What is A \\cup B? What is A \\cap B? If A is a subset of the Sample Space S = \\{1,2,3,4,5,6,7,8,9,10\\}, what is the complement A^C?\nIf we roll two fair dice, what is the probability that their sum would be 11?\nIf we roll two fair dice, what is the probability that their sum would be 12?"
  },
  {
    "objectID": "01_prerequisites.html",
    "href": "01_prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "The syllabus lists the assumed knowledge for Math Camp (Chapters 1-4 of Moore and Siegel). Below, you will find additional review material, examples, and sample exercises."
  },
  {
    "objectID": "01_prerequisites.html#operators",
    "href": "01_prerequisites.html#operators",
    "title": "Prerequisites",
    "section": "Operators",
    "text": "Operators\nAddition (+), Subtraction (-), multiplication and division are basic operations of arithmetic – combining numbers. In statistics and calculus, we want to add a sequence of numbers that can be expressed as a pattern without needing to write down all its components. For example, how would we express the sum of all numbers from 1 to 100 without writing a hundred numbers?\nFor this we use the summation operator \\sum and the product operator \\prod.\nSummation\n\n\\sum\\limits_{i=1}^{100} x_i = x_1+x_2+x_3+\\cdots+x_{100}\n\nThe bottom of the \\sum symbol indicates an index (here, i), and its start value 1. At the top is where the index ends. The notion of “addition” is part of the \\sum symbol. The content to the right of the summation is the meat of what we add. While you can pick your favorite index, start, and end values, the content must also have the index.\n\nCorollary 1 \n\n\\sum\\limits_{i=1}^n c x_i = c \\sum\\limits_{i=1}^n x_i\n\\sum\\limits_{i=1}^n (x_i + y_i) = \\sum\\limits_{i=1}^n x_i + \\sum\\limits_{i=1}^n y_i\n\\sum\\limits_{i=1}^n c = n c\n\n\nProduct\n\n\\prod\\limits_{i=1}^n x_i = x_1 x_2 x_3 \\cdots x_n\n\n\nCorollary 2 \n\n\\prod\\limits_{i=1}^n c x_i = c^n \\prod\\limits_{i=1}^n x_i\n\\prod\\limits_{i=k}^n c x_i = c^{n-k+1} \\prod\\limits_{i=k}^n x_i\n\n\\prod\\limits_{i=1}^n (x_i + y_i) = a total mess\n\\prod\\limits_{i=1}^n c = c^n\n\n\nFactorials\n\nDefinition 1 (Factorials) \n\nx! = x\\cdot (x-1) \\cdot (x-2) \\cdots (1)\n\n\nModulo\nTells you the remainder when you divide the first number by the second.\n\n17 \\mod 3 = 2\n100 \\ \\% \\ 30 = 10\n\n\nExercise 1 (Operators) Let x_1 = 4, x_2 = 3, x_3 = 7, x_4 = 11, x_5 = 2. Find the following:\n\n\\sum\\limits_{i=1}^{5} i\n\\prod\\limits_{i=1}^{5} i\n14 \\mod 4\n4!\n\\sum\\limits_{i=1}^{3} (7)x_i\n\\sum\\limits_{i=1}^{5} 2\n\\prod\\limits_{i=3}^{5} (2)x_i"
  },
  {
    "objectID": "01_prerequisites.html#functions",
    "href": "01_prerequisites.html#functions",
    "title": "Prerequisites",
    "section": "Functions",
    "text": "Functions\nA function is a mapping that relates members of one set to members of another set.\nFor instance, if you have two sets: set A and set B, a function f from A to B maps every value a in set A such that f(a) \\in B.\n\nThe set A is called the domain of function f\n\nThe set B is called the range of function f\n\n\nFunctions can be many-to-one, where many values from set A produce a single output in set B, or they can be one-to-one, where each value in set A corresponds to a single value in set B.\nA function by definition has a single function value for each element of its domain. This means, there cannot be “one-to-many” mapping.\nDimensionality\n\\mathbb{R}^1 is the set of all real numbers extending from -\\infty to +\\infty — i.e., the real number line. \\mathbb{R}^n is an n-dimensional space, where each of the n axes extends from -\\infty to +\\infty.\n\n\n\\mathbb{R}^1 is a one dimensional line.\n\n\\mathbb{R}^2 is a two dimensional plane.\n\n\\mathbb{R}^3 is a three dimensional space.\n\nPoints in \\mathbb{R}^n are ordered n-tuples (just means an combination of n elements where order matters), where each element of the n-tuple represents the coordinate along that dimension.\nFor example:\n\n\n\\mathbb{R}^1: (3)\n\n\n\\mathbb{R}^2: (-15, 5)\n\n\n\\mathbb{R}^3: (86, 4, 0)\n\n\n\n\n\n\n\n\nNotation (Functions)\n\n\n\nFunction of one variable:\n\nf:\\mathbb{R}^1\\to\\mathbb{R}^1\n\n\nExample: f(x)=x+1\n\nFor each x in \\mathbb{R}^1, f(x) assigns the number x+1\n\n\n\n\nFunction of two variables:\n\nf: \\mathbb{R}^2\\to\\mathbb{R}^1\n\n\nExample: f(x,y)=x^2+y^2\n\nFor each ordered pair (x,y) in \\mathbb{R}^2, f(x,y) assigns the number x^2+y^2\n\n\n\n\n\n\nWe often use variable x as input and another y as output, e.g. y=x+1\n\nExercise 2 (Functions) For each of the following, state whether they are one-to-one or many-to-one functions.\n\nFor x \\in [0,\\infty], f : x \\rightarrow x^2 (this could also be written as f(x) = x^2).\nFor x \\in [-\\infty, \\infty], f: x \\rightarrow x^2.\nFor x \\in [-3, \\infty], f: x \\rightarrow x^2.\nFor x \\in [0, \\infty], f: x \\rightarrow \\sqrt{x}\n\n\n\nSome functions are defined only on proper subsets of \\mathbb{R}^n.\n\n\nDomain: the set of numbers in X at which f(x) is defined.\n\nRange: elements of Y assigned by f(x) to elements of X, or we can use the notation f(X) to denote the range, where f(X)=\\{ y : y=f(x), x\\in X\\}\n\nTypes of Functions\nMonomials: f(x)=a x^k\na is the coefficient. k is the degree.\nExamples: y=x^2, y=-\\frac{1}{2}x^3\nPolynomials: sum of monomials.\nExamples: y=-\\frac{1}{2}x^3+x^2, y=3x+5\nThe degree of a polynomial is the highest degree of its monomial terms. Also, it’s often a good idea to write polynomials with terms in decreasing degree.\nExponential Functions: Example: y=2^x"
  },
  {
    "objectID": "01_prerequisites.html#logexponents",
    "href": "01_prerequisites.html#logexponents",
    "title": "Prerequisites",
    "section": "Logs and Exponents",
    "text": "Logs and Exponents\nRelationship of logarithmic and exponential functions:\n\ny=\\log_a(x) \\iff a^y=x\n\nThe log function can be thought of as an inverse for exponential functions. a is referred to as the “base” of the logarithm.\nCommon Bases: The two most common logarithms are base 10 and base e.\n\nBase 10: \\quad y=\\log_{10}(x) \\iff 10^y=x. The base 10 logarithm is often simply written as “\\log(x)” with no base denoted.\nBase e: \\quad y=\\log_e(x) \\iff e^y=x. The base e logarithm is referred to as the “natural” logarithm and is written as ``\\ln(x)“.\n\nProperties of exponential functions:\n\na^x a^y = a^{x+y}\na^{-x} = 1/a^x\na^x/a^y = a^{x-y}\n(a^x)^y = a^{x y}\na^0 = 1\n\nProperties of logarithmic functions (any base):\nGenerally, when statisticians or social scientists write \\log(x) they mean \\log_e(x). In other words: \\log_e(x) \\equiv \\ln(x) \\equiv \\log(x)\n\n\\log_a(a^x)=x\n\nand\n\na^{\\log_a(x)}=x\n\n\n\\log(x y)=\\log(x)+\\log(y)\n\\log(x^y)=y\\log(x)\n\\log(1/x)=\\log(x^{-1})=-\\log(x)\n\\log(x/y)=\\log(x\\cdot y^{-1})=\\log(x)+\\log(y^{-1})=\\log(x)-\\log(y)\n\\log(1)=\\log(e^0)=0\n\nChange of Base Formula: Use the change of base formula to switch bases as necessary:\n\n\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\n\nExample:\n\n\\log_{10}(x) = \\frac{\\ln(x)}{\\ln(10)}\n\nYou can use logs to go between sum and product notation. This will be particularly important when you’re learning maximum likelihood estimation.\n\n\\begin{aligned}\n            \\log \\bigg(\\prod\\limits_{i=1}^n x_i \\bigg)\n            &= \\log(x_1 \\cdot x_2 \\cdot x_3 \\cdots \\cdot x_n) \\\\\n            &= \\log(x_1) + \\log(x_2) + \\log(x_3) + \\cdots + \\log(x_n) \\\\\n            &= \\sum\\limits_{i=1}^n \\log (x_i)\n\\end{aligned}\n\nTherefore, you can see that the log of a product is equal to the sum of the logs. We can write this more generally by adding in a constant, c:\n      \n\\begin{aligned}\n            \\log \\bigg(\\prod\\limits_{i=1}^n c x_i\\bigg)\n            &= \\log(cx_1 \\cdot cx_2 \\cdots cx_n) \\\\\n            &= \\log(c^n \\cdot x_1 \\cdot x_2 \\cdots x_n) \\\\\n            &= \\log(c^n) + \\log(x_1) + \\log(x_2) + \\cdots + \\log(x_n) \\\\\n            &= n \\log(c) +  \\sum\\limits_{i=1}^n \\log (x_i)\n\\end{aligned}   \n\n\nExercise 3 (Log) Evaluate each of the following logarithms\n\n\\log_4(16)\n\\log_2(16)\n\\log_\\frac{3}{2}(\\frac{27}{8})\n\nSimplify the following logarithm. By “simplify”, we actually really mean - use as many of the logarithmic properties as you can.\n\n\\log_4(x^3y^5)\n\\log(\\frac{x^9y^5}{z^3})\n\\ln{\\sqrt{xy}}"
  },
  {
    "objectID": "01_prerequisites.html#graphing-functions",
    "href": "01_prerequisites.html#graphing-functions",
    "title": "Prerequisites",
    "section": "Graphing Functions",
    "text": "Graphing Functions\nWhat can a graph tell you about a function?\n\nIs the function increasing or decreasing? Over what part of the domain?\nHow ``fast” does it increase or decrease?\nAre there global or local maxima and minima? Where?\nAre there inflection points?\nIs the function continuous?\nIs the function differentiable?\nDoes the function tend to some limit?\nOther questions related to the substance of the problem at hand."
  },
  {
    "objectID": "01_prerequisites.html#solving-for-variables",
    "href": "01_prerequisites.html#solving-for-variables",
    "title": "Prerequisites",
    "section": "Solving for Variables",
    "text": "Solving for Variables\nSometimes we’re given a function y=f(x) and we want to find how x varies as a function of y. Use algebra to move x to the left hand side (LHS) of the equation and so that the right hand side (RHS) is only a function of y.\n\nExample 1 (Solving for Variables) Solve for x:\n\ny=3x+2\ny=e^x\n\n\nSolving for variables is especially important when we want to find the roots of an equation: those values of variables that cause an equation to equal zero. Especially important in finding equilibria and in doing maximum likelihood estimation.\nProcedure: Given y=f(x), set f(x)=0. Solve for x.\nMultiple Roots:\n\nf(x)=x^2 - 9 \\quad\\Longrightarrow\\quad 0=x^2 - 9 \\quad\\Longrightarrow\\quad 9=x^2 \\quad\\Longrightarrow\\quad \\pm \\sqrt{9}=\\sqrt{x^2} \\quad\\Longrightarrow\\quad \\pm 3=x\n\nQuadratic Formula: For quadratic equations ax^2+bx+c=0, use the quadratic formula:\n\nx=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\n\n\nExercise 4 (Solving for Variables) Solve for x:\n\nf(x)=3x+2 = 0\nf(x)=x^2+3x-4=0\nf(x)=e^{-x}-10 = 0"
  },
  {
    "objectID": "01_prerequisites.html#answers-to-examples-and-exercises",
    "href": "01_prerequisites.html#answers-to-examples-and-exercises",
    "title": "Prerequisites",
    "section": "Answers to Examples and Exercises",
    "text": "Answers to Examples and Exercises\nAnswer to Exercise 1:\n\n1 + 2 + 3 + 4 + 5 = 15\n1 * 2 * 3 * 4 * 5 = 120\n2\n4 * 3 * 2 * 1 = 24\n7(4 + 3 + 7) = 98\n2 + 2 + 2 + 2 + 2 = 10\n2^3(7)(11)(2) = 1232\n\nAnswer to Exercise 2:\n\none-to-one\nmany-to-one\nmany-to-one\none-to-one\n\nAnswer to Exercise 3:\n\n2\n4\n3\n3\\log_4(x) + 5\\log_4(y)\n9\\log(x) + 5\\log(y) - 3\\log(z)\n\\frac{1}{2}(\\ln{x} + \\ln{y})\n\nAnswer to Example 1:\n\ny=3x+2 \\quad\\Longrightarrow\\quad -3x=2-y \\quad\\Longrightarrow\\quad 3x=y-2 \\quad\\Longrightarrow\\quad x=\\frac{1}{3}(y-2)\nx = \\ln{y}\n\nAnswer to Exercise 4:\n\n\\frac{-2}{3}\nx = {1, -4}\nx = - \\ln10"
  },
  {
    "objectID": "11_orientation.html",
    "href": "11_orientation.html",
    "title": "\n1  Orientation and Reading in Data\n",
    "section": "",
    "text": "Welcome to Math Camp! The first day we will get to know each other and get acquainted with R. We will be working with R throughout this course, and today is the beginning, where you will learn about this program. It can be overwhelming to learn any programming language, but we will spend a lot of time and practice with it. Please work through the following tutorials and exercises. There is a lot of information here, and it will take time to understand everything. In fact, programming is a continual learning experience. Please come to class with areas of confusion and questions; we will walk through more examples together.\nYou should download the latest versions of R and R Studio.\nR Studio Cloud has great resources we will be using throughout this course. Please complete the following primer tutorial for the first session: The Basics: Programming Basics"
  },
  {
    "objectID": "11_orientation.html#where-are-we-starting",
    "href": "11_orientation.html#where-are-we-starting",
    "title": "\n1  Orientation and Reading in Data\n",
    "section": "Where are we starting?",
    "text": "Where are we starting?\nToday we’ll cover:\n\nWhat’s what in RStudio\nWhat R is, at a high level\nHow to read in data\nHow to create cool graphs using the ggplot2 package\nBest practices for reproducible workflow using R Markdown"
  },
  {
    "objectID": "11_orientation.html#orienting",
    "href": "11_orientation.html#orienting",
    "title": "\n1  Orientation and Reading in Data\n",
    "section": "\n1.1 Orienting",
    "text": "1.1 Orienting\n\n1.1.1 Getting to know RStudio\nRStudio is an Integrated Development Environment for the programming language R. An IDE is a piece of software which allows you to more easily interface with programming languages. You can program with other languages (such as Python or SQL) using RStudio, and you can use other IDEs to program with R, but typically R users use RStudio—and vice versa. This is because RStudio was specifically created to facilitate R programming and comes with a ton of helpful features.\nThere are four main sections, or “panes”, in RStudio.\n\n\nBottom Left. This is the Console. It is the place that executes your R code. You can type directly in your Console and it will display the output immediately below. If your code generates errors or warning messages they will be displayed here too. You should rarely type code directly into your Console, however, because it can be difficult to keep track of things line by line. Also, every time you restart RStudio your Console will refresh itself which means you will lose your previous work! This is not only a problem for your own analysis, but it also makes it impossible for anyone else to replicate your steps. I only write in the Console directly if I’m testing small code snippets or for quick data exploration (for example using the summary() function on a variable).\nUseful tip: use the Up-Arrow on your keyboard to quickly re-run pieces of code which were previously sent to the Console.\n\n\nTop Left. If you go to “File > New File” you can open up a script file which will then appear in your Source window. Script files are text documents containing written R code which then gets sent down to the Console when executed. Script files are great because we can save them onto our computer to rerun our work or to continue writing later. Plus we can send these files to anyone else with R installed on their computer and they should be able to rerun our analysis too. This is a core concept in ensuring your research is reproducible.\nThere are two types of script files people typically use when programming in R: .R and .Rmd files. Most R users do the bulk of their programming in .R files. These are plain text files containing only commands for R to execute. If you want to write something else in .R files (such as English sentences), you can do so by starting a line with a # character. These are called comments and are a great way to explain what your R code is supposed to be doing. Comments make it helpful for other people to understand your code, as well as for yourself if you revisit a project months or years later!\nThe other common type of file used to write R code is an .Rmd, or R Markdown, file. We will cover R Markdown in much greater detail in a later section, but these are the basics for now. R Markdown allows you to seamlessly combine R code with written text to create a wide variety of possible documents. All of my papers in grad school have been written in R Markdown, as well as my presentation slides and website. This book you’re reading right now was written in R Markdown too. The strength of combining R code and written text comes from how easy it is to update your document when something in your analysis changes. New data? Simply plug it in to the top of your R Markdown document and every graph and table will be automatically updated once you compile a new document. No more copy and pasting figures into Word.\n\nTop Right. This is your Environment tab and it keeps track of which object you’ve created in R. Objects in R are things like data frames, vectors, and functions. Many people refer to R as an “object-oriented language”, by which they mean that most of your code either creates new objects or modifies existing objects. This aspect is probably the largest difference between R and statistical programs like Stata. Each object in R has a specific type which defines what you can and cannot do with it. For example, you cannot add objects that are character types together \"UC\" + \"SD\", but you can add two objects with numeric types 3 + 5. Getting to know the rules surrounding object types is one of the trickier aspects of learning R. But overall, this method of programming is generally pretty intuitive.\n\nBottom Right. Three important tabs live here. When you execute the code which makes a plot in a .R file it will, appropriately enough, show up down in your Plot tab.\nThe Help tab is where you can read the documentation for a specific function in R. To find the right help file you can either enter the function name into the search bar, or you can type ?function_name in the Console. Use the Help tab often! This should be the first place you go when you encounter a problem with your R code.\nLastly, the Files tab is very handy for keeping track of the various R scripts and data you may be working with on a particular project. It acts like a replacement File Explorer (if using a PC) or Finder (if using a Mac) without you having to have multiple windows open on your computer.\n\n\n\n1.1.2 RStudio Projects\nSpeaking of files and file paths…\nThroughout your time in the Political Science PhD program you will likely load hundreds of data sets into R. The first step to loading data into R is locating the file holding on the data on your computer. This is done using a file path–a string of characters which points to the file. For example, \"/Users/bertrandwilden/Documents/UCSD/amazing_paper/data/cool_data.csv\" tells us the location of the file “cool_data.csv” located in the folder “data” which is a sub-directory of “amazing_paper” and so on. Getting a hang of using file paths to locate files can be one of the most frustrating parts of using a programming language like R. Modern computer systems, such as your phone, have made file paths invisible to most users. So don’t worry if any of this is confusing to you in the beginning!\nThere are two aspects of file paths that make them particularly annoying/difficult to work with. First, a file path that correctly locates a file on one computer will not locate the same file in another computer. This is because everyone has their own unique folder structures on their computer. Computer-specific file paths make it difficult to share code with others or to collaborate on the same project. They also lead to headaches when revisiting old code on a new computer.\nThe second, but related, issue with file paths is that they differ between Mac and PC computers. Mac file paths use the forward slash “/” between folders whereas PCs use the back slash “\\”. Back slashes in R strings are not processed literally–instead they are considered “escape” characters and serve a different purpose. This means you have to manually change all your backslashes to forward slashes to locate files when using a PC. Or you can manually add an extra back slash in front of each folder (\"C:\\\\Users\\\\bertrandwilden\\\\Documents\\\\UCSD\\\\amazing_paper\\\\data\\\\cool_data.csv\"). What a hassle!\nLuckily tools have been developed to solve all these file path annoyances. The first solution is to use RStudio Projects. When you create a new RStudio Project it adds a .Rproj file with your project name to a folder on your computer. The .Rproj file now serves as the top level directory for any R code or data files in folders below it. So instead of using the full path \"/Users/bertrandwilden/Documents/UCSD/amazing_paper/data/cool_data.csv\" to locate your data, you now only need to type \"data/cool_data.csv\"! This is sometimes called a relative path. Each RStudio Project is self-contained and easily portable to other machines. RStudio Projects also have the benefit of making it easy to switch between various projects–giving you a clean slate with which to work from every time.1\nAwesome—RStudio Projects helped solve one of our file path issues by using relative paths, but what about the Mac vs PC problem with different slashes? That’s where the R package {here} shines. The here package allows you to simply put each folder name in quotes and stitches the full path together behind the scenes. The file path \"data/cool_data.csv\" becomes here(\"data\", \"cool_data.csv\"). This code will now point to the correct file on any computer.2\n\n\n1.1.3 Installing Packages\nWhile it is technically feasible to use only the functions that come with R when you install it (aka “base R”), thousands of open source packages have been written to provide extra functionality. The term “open source” means that the underlying code for these packages lives on online repositories, such as GitHub, and can be viewed publicly. While open source packages can be written by anyone (including you someday!), there is a special process packages must undergo in order to be hosted officially by CRAN. Packages that have passed this systematic review by CRAN can be installed on your computer using the following command:\n\ninstall.packages(\"package_name_here\")\n\nIt is good practice to only use the install.packages command in your Console, rather than in a .R or .qmd script file. This is because you only need to install a particular R package once and then you can then use it forever. Putting install.packages in your script file will make R attempt to download the package each time your code is run.\nAfter using the install.packages command, you then need to use the following command to access the package’s functions:\n\nlibrary(package_name_here)\n\nUnlike the install.packages command, the library command should be included at the top of any script files which then make use of the package’s functions. Another thing to note: the install.packages command requires the package name to be in quotes, whereas the library command requires the package name to not be in quotes. Don’t worry—mixing up when to use quotes and when not to is a common error you might encounter when starting out!\n\n1.1.4 Installing the Tidyverse and Here Packages\nIn this course we will be making extensive use of the packages included in the Tidyverse. The Tidyverse is a set of packages designed to make data analysis in R easier and more streamlined.\n\n\n\nThis approach is usually contrasted against “base R” functions, which do not require external packages. While everything Tidyverse can do, base R can do too, I find the Tidyverse approach much more intuitive. In fact, almost all my script files begin with the command library(tidyverse). There are also a multitude of packages that, although not technically part of the Tidyverse, share the same coding conventions as the core Tidyverse. So learning the Tidyverse will help when you when using more advanced packages.\n\n\n\nInstall the Tidyverse using:\n\n# This might take a couple minutes to download all packages\ninstall.packages(\"tidyverse\")\n\nI also highly recommend using the “here” package for file path management as explained earlier.\n\ninstall.packages(\"here\")\n\nOnce both packages are done installing, run the following lines of code to load them into R and make them available for use.\n\nlibrary(tidyverse)\nlibrary(here)"
  },
  {
    "objectID": "11_orientation.html#reading-in-data",
    "href": "11_orientation.html#reading-in-data",
    "title": "\n1  Orientation and Reading in Data\n",
    "section": "\n1.2 Reading in Data",
    "text": "1.2 Reading in Data\nFor our data visualization exercises we will be using the data set “county_elections.csv” which you can download at the Math Bootcamp GitHub repository here. After you download “county_elections.csv”, either copy or move it into your “data” folder in your Math Camp R Project directory. The source for this data comes from the MIT Election Data Science Lab and from the US Census accessed via IPUMS NHGIS.\nNow read the “county_elections.csv” data set into R using the following command:\n\ncounty_elections <- read_csv(here(\"data\", \"county_elections.csv\"))\n\nLet’s break down this line of code.\n\nThe function read_csv is from the package readr which is part of the Tidyverse. It loads a .csv data set file into R. The suffix .csv stands for “comma separated value” and is a very common format for storing tabular data. Inside read_csv(...) we put the file path pointing to the file we want to read into R.\nWe saw the here function earlier. Remember that this is just a convenient way of dealing with file paths. Try only running the command here(\"data\", \"county_elections.csv\") in your console to see how it creates an automatic file path for you.\nIn R, <- is the operator we use when we want to assign a value to an object. So the expression county_elections <- ... can be read as “take the thing on the right side of the arrow and assign it to an object named county_elections”. Check your Environment tab and verify that there is now an object called county_elections there. We can now take the county_elections object and do a bunch of stuff with it!\n\nWhen you read a new data set into R it’s often a good idea to do a quick visual inspection. Does the data look like what we’d expect? To do this, either click on the county_elections object in your Environment tab or type View(county_elections) in your Console. This will make the raw data pop up in a spreadsheet that you can scroll through and check out."
  },
  {
    "objectID": "12_functions_obj_loops.html",
    "href": "12_functions_obj_loops.html",
    "title": "2  Objects, Functions, Loops",
    "section": "",
    "text": "Up till now, you should have covered:\n\nR basic programming\nData Import\n\nToday we’ll cover\n\nObjects\nFunctions\nLoops"
  },
  {
    "objectID": "12_functions_obj_loops.html#what-is-an-object",
    "href": "12_functions_obj_loops.html#what-is-an-object",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.1 What is an object?",
    "text": "2.1 What is an object?\nNow that we have covered how to load in data and some basic information about R, let’s dive into some fundamentals of the R language.\nLet’s first set up\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(haven)\nlibrary(ggplot2)\n\n\ncen10 <- read_csv(\"data/input/usc2010_001percent.csv\", col_types = cols())\n\nObjects are abstract symbols in which you store data. Here we will create an object from copy, and assign cen10 to it.\n\ncopy <- cen10 \n\nThis looks the same as the original dataset:\n\ncopy\n\n# A tibble: 30,871 × 4\n   state         sex      age race       \n   <chr>         <chr>  <dbl> <chr>      \n 1 New York      Female     8 White      \n 2 Ohio          Male      24 White      \n 3 Nevada        Male      37 White      \n 4 Michigan      Female    12 White      \n 5 Maryland      Female    18 Black/Negro\n 6 New Hampshire Male      50 White      \n 7 Iowa          Female    51 White      \n 8 Missouri      Female    41 White      \n 9 New Jersey    Male      62 White      \n10 California    Male      25 White      \n# … with 30,861 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nWhat happens if you do this next?\n\ncopy <- \"\"\n\nIt got reassigned:\n\ncopy\n\n[1] \"\"\n\n\n\n2.1.1 lists\nLists are one of the most generic and flexible type of object. You can make an empty list by the function list()\n\nmy_list <- list()\nmy_list\n\nlist()\n\n\nAnd start filling it in. Slots on the list are invoked by double square brackets [[]]\n\nmy_list[[1]] <- \"contents of the first slot -- this is a string\"\nmy_list[[\"slot 2\"]] <- \"contents of slot named slot 2\"\nmy_list\n\n[[1]]\n[1] \"contents of the first slot -- this is a string\"\n\n$`slot 2`\n[1] \"contents of slot named slot 2\"\n\n\neach slot can be anything. What are we doing here? We are defining the 1st slot of the list my_list to be a vector c(1, 2, 3, 4, 5)\n\nmy_list[[1]] <- c(1, 2, 3, 4, 5)\nmy_list\n\n[[1]]\n[1] 1 2 3 4 5\n\n$`slot 2`\n[1] \"contents of slot named slot 2\"\n\n\nYou can even make nested lists. Let’s say we want the 1st slot of the list to be another list of three elements.\n\nmy_list[[1]][[1]] <- \"subitem 1 in slot 1 of my_list\"\nmy_list[[1]][[2]] <- \"subitem 1 in slot 2 of my_list\"\nmy_list[[1]][[3]] <- \"subitem 1 in slot 3 of my_list\"\n\nmy_list\n\n[[1]]\n[1] \"subitem 1 in slot 1 of my_list\" \"subitem 1 in slot 2 of my_list\"\n[3] \"subitem 1 in slot 3 of my_list\" \"4\"                             \n[5] \"5\"                             \n\n$`slot 2`\n[1] \"contents of slot named slot 2\""
  },
  {
    "objectID": "12_functions_obj_loops.html#making-your-own-objects",
    "href": "12_functions_obj_loops.html#making-your-own-objects",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.2 Making your own objects",
    "text": "2.2 Making your own objects\nWe’ve covered one type of object, which is a list. You saw it was quite flexible. How many types of objects are there?\nThere are an infinite number of objects, because people make their own class of object. You can detect the type of the object (the class) by the function class\nObject can be said to be an instance of a class.\nAnalogies:\nclass - Pokemon, object - Pikachu\nclass - Book, object - To Kill a Mockingbird\nclass - DataFrame, object - 2010 census data\nclass - Character, object - “Programming is Fun”\nWhat is type (class) of object is cen10?\n\nclass(cen10)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nWhat about this text?\n\nclass(\"some random text\")\n\n[1] \"character\"\n\n\nTo change or create the class of any object, you can assign it. To do this, assign the name of your class to character to an object’s class().\nWe can start from a simple list. For example, say we wanted to store data about pokemon. Because there is no pre-made package for this, we decide to make our own class.\n\npikachu <- list(name = \"Pikachu\",\n                number = 25,\n                type = \"Electric\",\n                color = \"Yellow\")\n\nand we can give it any class name we want.\n\nclass(pikachu) <- \"Pokemon\"\nstr(pikachu)\n\nList of 4\n $ name  : chr \"Pikachu\"\n $ number: num 25\n $ type  : chr \"Electric\"\n $ color : chr \"Yellow\"\n - attr(*, \"class\")= chr \"Pokemon\"\n\npikachu$type\n\n[1] \"Electric\"\n\n\n\n2.2.1 Seeing R through objects\nMost of the R objects that you will see as you advance are their own objects. For example, here’s a linear regression object (which you will learn more about in 204B):\n\nols <- lm(mpg ~ wt + vs + gear + carb, mtcars)\nclass(ols)\n\n[1] \"lm\"\n\n\nAnything can be an object! Even graphs (in ggplot) can be assigned, re-assigned, and edited.\n\ngrp_race <- group_by(cen10, race)%>%\n  summarize(count = n())\n\ngrp_race_ordered <- arrange(grp_race, count) %>% \n  mutate(race = forcats::as_factor(race))\n\ngg_tab <- ggplot(data = grp_race_ordered) +\n  aes(x = race, y = count) +\n  geom_col() +\n  labs(caption = \"Source: U.S. Census 2010\")\n\ngg_tab\n\n\n\n\nYou can change the orientation\n\ngg_tab<- gg_tab + coord_flip()\n\n\n2.2.2 Parsing an object by str()s\n\nIt can be hard to understand an R object because its contents are unknown. The function str, short for structure, is a quick way to look into the innards of an object\n\nstr(my_list)\n\nList of 2\n $       : chr [1:5] \"subitem 1 in slot 1 of my_list\" \"subitem 1 in slot 2 of my_list\" \"subitem 1 in slot 3 of my_list\" \"4\" ...\n $ slot 2: chr \"contents of slot named slot 2\"\n\nclass(my_list)\n\n[1] \"list\"\n\n\nSame for the object we just made\n\nstr(pikachu)\n\nList of 4\n $ name  : chr \"Pikachu\"\n $ number: num 25\n $ type  : chr \"Electric\"\n $ color : chr \"Yellow\"\n - attr(*, \"class\")= chr \"Pokemon\"\n\n\nWhat does a ggplot object look like? Very complicated, but at least you can see it:\n\n# enter this on your console\nstr(gg_tab)"
  },
  {
    "objectID": "12_functions_obj_loops.html#types-of-variables",
    "href": "12_functions_obj_loops.html#types-of-variables",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.3 Types of variables",
    "text": "2.3 Types of variables\nIn the social science we often analyze variables. As you saw in the tutorial, different types of variables require different care.\nA key link with what we just learned is that variables are also types of R objects.\n\n2.3.1 scalars\nOne number. How many people did we count in our Census sample?\n\nnrow(cen10)\n\n[1] 30871\n\n\nQuestion: What proportion of our census sample is Native American? This number is also a scalar\n\n# Enter yourself\nunique(cen10$race)\n\n[1] \"White\"                            \"Black/Negro\"                     \n[3] \"Other race, nec\"                  \"American Indian or Alaska Native\"\n[5] \"Chinese\"                          \"Other Asian or Pacific Islander\" \n[7] \"Two major races\"                  \"Three or more major races\"       \n[9] \"Japanese\"                        \n\nmean(cen10$race == \"American Indian or Alaska Native\")\n\n[1] 0.009555894\n\n\nHint: you can use the function mean() to calcualte the sample mean. The sample proportion is the mean of a sequence of number, where your event of interest is a 1 (or TRUE) and others are 0 (or FALSE).\n\n2.3.2 numeric vectors\nA sequence of numbers.\n\ngrp_race_ordered$count\n\n[1]    77    88   295   354   869  1129  1839  4013 22207\n\nclass(grp_race_ordered$count)\n\n[1] \"integer\"\n\n\nOr even, all the ages of the millions of people in our Census. Here are just the first few numbers of the list.\n\nhead(cen10$age)\n\n[1]  8 24 37 12 18 50\n\n\n\n2.3.3 characters (aka strings)\nThis can be just one stretch of characters\n\nmy_name <- \"Meg\"\nmy_name\n\n[1] \"Meg\"\n\nclass(my_name)\n\n[1] \"character\"\n\n\nor more characters. Notice here that there’s a difference between a vector of individual characters and a length-one object of characters.\n\nmy_name_letters <-  c(\"M\",\"e\",\"g\")\nmy_name_letters\n\n[1] \"M\" \"e\" \"g\"\n\nclass(my_name_letters)\n\n[1] \"character\"\n\n\nFinally, remember that lower vs. upper case matters in R!\n\nmy_name2 <- \"shiro\"\nmy_name == my_name2\n\n[1] FALSE"
  },
  {
    "objectID": "12_functions_obj_loops.html#what-is-a-function",
    "href": "12_functions_obj_loops.html#what-is-a-function",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.4 What is a function?",
    "text": "2.4 What is a function?\nMost of what we do in R is executing a function. read_csv(), nrow(), ggplot() .. pretty much anything with a parentheses is a function. And even things like <- and [ are functions as well.\nA function is a set of instructions with specified ingredients. It takes an input, then manipulates it – changes it in some way – and then returns the manipulated product.\nOne way to see what a function actually does is to enter it without parentheses.\n\n# enter this on your console\ntable\n\nYou’ll see below that the most basic functions are quite complicated internally.\nYou’ll notice that functions contain other functions. wrapper functions are functions that “wrap around” existing functions. This sounds redundant, but it’s an important feature of programming. If you find yourself repeating a command more than two times, you should make your own function, rather than writing the same type of code.\n\n2.4.1 Write your own function\nIt’s worth remembering the basic structure of a function. You create a new function, call it my_fun by this:\n\nmy_fun <- function() {\n  \n}\n\nIf we wanted to generate a function that computed the number of men in your data, what would that look like?\n\ncount_men <- function(data) {\n  \n  nmen <- sum(data$sex == \"Male\")\n  \n  return(nmen)\n}\n\nThen all we need to do is feed this function a dataset\n\ncount_men(cen10)\n\n[1] 15220\n\n\nThe point of a function is that you can use it again and again without typing up the set of constituent manipulations. So, what if we wanted to figure out the number of men in California?\n\ncount_men(cen10[cen10$state == \"California\",])\n\n[1] 1876\n\n\nLet’s go one step further. What if we want to know the proportion of non-whites in a state, just by entering the name of the state? There’s multiple ways to do it, but it could look something like this\n\nnw_in_state <- function(data, state) {\n  \n  s.subset <- data[data$state == state,]\n  total.s <- nrow(s.subset)\n  nw.s <- sum(s.subset$race != \"White\")\n  \n  nw.s / total.s\n}\n\nThe last line is what gets generated from the function. To be more explicit you can wrap the last line around return(). (as in return(nw.s/total.s). return() is used when you want to break out of a function in the middle of it and not wait till the last line.\nTry it on your favorite state!\n\nnw_in_state(cen10, \"Massachusetts\")\n\n[1] 0.2040185"
  },
  {
    "objectID": "12_functions_obj_loops.html#checkpoint",
    "href": "12_functions_obj_loops.html#checkpoint",
    "title": "2  Objects, Functions, Loops",
    "section": "Checkpoint",
    "text": "Checkpoint\n1\nTry making your own function, average_age_in_state, that will give you the average age of people in a given state.\n\n# Enter on your own\n\n2\nTry making your own function, asians_in_state, that will give you the number of Chinese, Japanese, and Other Asian or Pacific Islander people in a given state.\n\n# Enter on your own\n\n3\nTry making your own function, ‘top_10_oldest_cities’, that will give you the names of cities whose population’s average age is top 10 oldest.\n\n# Enter on your own"
  },
  {
    "objectID": "12_functions_obj_loops.html#what-is-a-package",
    "href": "12_functions_obj_loops.html#what-is-a-package",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.5 What is a package?",
    "text": "2.5 What is a package?\nYou can think of a package as a suite of functions that other people have already built for you to make your life easier.\n\nhelp(package = \"ggplot2\")\n\nTo use a package, you need to do two things: (1) install it, and then (2) load it.\nInstalling is a one-time thing\n\ninstall.packages(\"ggplot2\")\n\nBut you need to load each time you start a R instance. So always keep these commands on a script.\n\nlibrary(ggplot2)\n\nIn rstudio.cloud, we already installed a set of packages for you. But when you start your own R instance, you need to have installed the package at some point."
  },
  {
    "objectID": "12_functions_obj_loops.html#conditionals",
    "href": "12_functions_obj_loops.html#conditionals",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.6 Conditionals",
    "text": "2.6 Conditionals\nSometimes, you want to execute a command only under certain conditions. This is done through the almost universal function, if(). Inside the if function we enter a logical statement. The line that is adjacent to, or follows, the if() statement only gets executed if the statement returns TRUE.\nFor example,\nFor example,\n\nx <- 5\nif (x >0) {\n  print(\"positive number\")\n} else if (x == 0)  {\n  print (\"zero\")\n} else {\n  print(\"negative number\")\n}\n\n[1] \"positive number\"\n\n\nYou can wrap that whole things in a function\n\nis_positive <- function(number) {\n  if (number >0) {\n    print(\"positive number\")\n  } else if (number == 0)  {\n    print (\"zero\")\n  } else {\n    print(\"negative number\")\n  }\n}\n\nis_positive(5)\n\n[1] \"positive number\"\n\nis_positive(-3)\n\n[1] \"negative number\""
  },
  {
    "objectID": "12_functions_obj_loops.html#for-loops",
    "href": "12_functions_obj_loops.html#for-loops",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.7 For-loops",
    "text": "2.7 For-loops\nLoops repeat the same statement, although the statement can be “the same” only in an abstract sense. Use the for(x in X) syntax to repeat the subsequent command as many times as there are elements in the right-hand object X. Each of these elements will be referred to the left-hand index x\nFirst, come up with a vector.\n\nfruits <- c(\"apples\", \"oranges\", \"grapes\")\n\nNow we use the fruits vector in a for loop.\n\nfor (fruit in fruits) {\n  print(paste(\"I love\", fruit))\n}\n\n[1] \"I love apples\"\n[1] \"I love oranges\"\n[1] \"I love grapes\"\n\n\nHere for() and in must be part of any for loop. The right hand side fruits must be a thing that exists. Finally the left-hand side object is “Pick your favor name.” It is analogous to how we can index a sum with any letter. \\sum_{i=1}^{10}i and sum_{j = 1}^{10}j are in fact the same thing.\n\nfor (i in 1:length(fruits)) {\n  print(paste(\"I love\", fruits[i]))\n}\n\n[1] \"I love apples\"\n[1] \"I love oranges\"\n[1] \"I love grapes\"\n\n\n\nstates_of_interest <- c(\"California\", \"Massachusetts\", \"New Hampshire\", \"Washington\")\n\nfor( state in states_of_interest){\n  state_data <- cen10[cen10$state == state,]\n  nmen <- sum(state_data$sex == \"Male\")\n\n  n <- nrow(state_data)\n  men_perc <- round(100*(nmen/n), digits=2)\n  print(paste(\"Percentage of men in\",state, \"is\", men_perc))\n\n}\n\n[1] \"Percentage of men in California is 49.85\"\n[1] \"Percentage of men in Massachusetts is 47.6\"\n[1] \"Percentage of men in New Hampshire is 48.55\"\n[1] \"Percentage of men in Washington is 48.19\"\n\n\nInstead of printing, you can store the information in a vector\n\nstates_of_interest <- c(\"California\", \"Massachusetts\", \"New Hampshire\", \"Washington\")\nmale_percentages <- c()\niter <-1 \n\nfor( state in states_of_interest){\n  state_data <- cen10[cen10$state == state,]\n  nmen <- sum(state_data$sex == \"Male\")\n  n <- nrow(state_data)\n  men_perc <- round(100*(nmen/n), digits=2)\n  \n  male_percentages <- c(male_percentages, men_perc)\n  names(male_percentages)[iter] <- state\n  iter <- iter + 1\n}\n\nmale_percentages\n\n   California Massachusetts New Hampshire    Washington \n        49.85         47.60         48.55         48.19"
  },
  {
    "objectID": "12_functions_obj_loops.html#nested-loops",
    "href": "12_functions_obj_loops.html#nested-loops",
    "title": "2  Objects, Functions, Loops",
    "section": "\n2.8 Nested Loops",
    "text": "2.8 Nested Loops\nWhat if I want to calculate the population percentage of a race group for all race groups in states of interest? You could probably use tidyverse functions to do this, but let’s try using loops!\n\nstates_of_interest <- c(\"California\", \"Massachusetts\", \"New Hampshire\", \"Washington\")\nfor (state in states_of_interest) {\n  for (race in unique(cen10$race)) {\n    race_state_num <- nrow(cen10[cen10$race == race & cen10$state == state, ])\n    state_pop <- nrow(cen10[cen10$state == state, ])\n    race_perc <- round(100*(race_state_num/(state_pop)), digits=2)\n    print(paste(\"Percentage of \", race , \"in\", state, \"is\", race_perc))\n  }\n}\n\n[1] \"Percentage of  White in California is 57.61\"\n[1] \"Percentage of  Black/Negro in California is 6.72\"\n[1] \"Percentage of  Other race, nec in California is 15.55\"\n[1] \"Percentage of  American Indian or Alaska Native in California is 1.12\"\n[1] \"Percentage of  Chinese in California is 3.75\"\n[1] \"Percentage of  Other Asian or Pacific Islander in California is 9.54\"\n[1] \"Percentage of  Two major races in California is 4.62\"\n[1] \"Percentage of  Three or more major races in California is 0.37\"\n[1] \"Percentage of  Japanese in California is 0.72\"\n[1] \"Percentage of  White in Massachusetts is 79.6\"\n[1] \"Percentage of  Black/Negro in Massachusetts is 5.87\"\n[1] \"Percentage of  Other race, nec in Massachusetts is 4.02\"\n[1] \"Percentage of  American Indian or Alaska Native in Massachusetts is 0.77\"\n[1] \"Percentage of  Chinese in Massachusetts is 2.32\"\n[1] \"Percentage of  Other Asian or Pacific Islander in Massachusetts is 4.33\"\n[1] \"Percentage of  Two major races in Massachusetts is 2.78\"\n[1] \"Percentage of  Three or more major races in Massachusetts is 0\"\n[1] \"Percentage of  Japanese in Massachusetts is 0.31\"\n[1] \"Percentage of  White in New Hampshire is 93.48\"\n[1] \"Percentage of  Black/Negro in New Hampshire is 0.72\"\n[1] \"Percentage of  Other race, nec in New Hampshire is 0.72\"\n[1] \"Percentage of  American Indian or Alaska Native in New Hampshire is 0.72\"\n[1] \"Percentage of  Chinese in New Hampshire is 0.72\"\n[1] \"Percentage of  Other Asian or Pacific Islander in New Hampshire is 2.17\"\n[1] \"Percentage of  Two major races in New Hampshire is 0.72\"\n[1] \"Percentage of  Three or more major races in New Hampshire is 0\"\n[1] \"Percentage of  Japanese in New Hampshire is 0.72\"\n[1] \"Percentage of  White in Washington is 76.05\"\n[1] \"Percentage of  Black/Negro in Washington is 2.9\"\n[1] \"Percentage of  Other race, nec in Washington is 5.37\"\n[1] \"Percentage of  American Indian or Alaska Native in Washington is 2.03\"\n[1] \"Percentage of  Chinese in Washington is 1.31\"\n[1] \"Percentage of  Other Asian or Pacific Islander in Washington is 6.68\"\n[1] \"Percentage of  Two major races in Washington is 4.79\"\n[1] \"Percentage of  Three or more major races in Washington is 0.29\"\n[1] \"Percentage of  Japanese in Washington is 0.58\""
  },
  {
    "objectID": "12_functions_obj_loops.html#exercises",
    "href": "12_functions_obj_loops.html#exercises",
    "title": "2  Objects, Functions, Loops",
    "section": "Exercises",
    "text": "Exercises\nExercise 1: Write your own function\nWrite your own function that makes some task of data analysis simpler. Ideally, it would be a function that helps you do either of the previous tasks in fewer lines of code. You can use the three lines of code that was provided in exercise 1 to wrap that into another function too!\n\n# Enter yourself\n\nExercise 2: Using Loops\nUsing a loop, create a crosstab of sex and race for each state in the set “states_of_interest”\n\nstates_of_interest <- c(\"California\", \"Massachusetts\", \"New Hampshire\", \"Washington\")\n# Enter yourself\n\nExercise 3: Storing information derived within loops in a global dataframe\nRecall the following nested loop\n\nstates_of_interest <- c(\"California\", \"Massachusetts\", \"New Hampshire\", \"Washington\")\nfor (state in states_of_interest) {\n  for (race in unique(cen10$race)) {\n    race_state_num <- nrow(cen10[cen10$race == race & cen10$state == state, ])\n    state_pop <- nrow(cen10[cen10$state == state, ])\n    race_perc <- round(100*(race_state_num/(state_pop)), digits=2)\n    print(paste(\"Percentage of \", race , \"in\", state, \"is\", race_perc))\n  }\n}\n\n[1] \"Percentage of  White in California is 57.61\"\n[1] \"Percentage of  Black/Negro in California is 6.72\"\n[1] \"Percentage of  Other race, nec in California is 15.55\"\n[1] \"Percentage of  American Indian or Alaska Native in California is 1.12\"\n[1] \"Percentage of  Chinese in California is 3.75\"\n[1] \"Percentage of  Other Asian or Pacific Islander in California is 9.54\"\n[1] \"Percentage of  Two major races in California is 4.62\"\n[1] \"Percentage of  Three or more major races in California is 0.37\"\n[1] \"Percentage of  Japanese in California is 0.72\"\n[1] \"Percentage of  White in Massachusetts is 79.6\"\n[1] \"Percentage of  Black/Negro in Massachusetts is 5.87\"\n[1] \"Percentage of  Other race, nec in Massachusetts is 4.02\"\n[1] \"Percentage of  American Indian or Alaska Native in Massachusetts is 0.77\"\n[1] \"Percentage of  Chinese in Massachusetts is 2.32\"\n[1] \"Percentage of  Other Asian or Pacific Islander in Massachusetts is 4.33\"\n[1] \"Percentage of  Two major races in Massachusetts is 2.78\"\n[1] \"Percentage of  Three or more major races in Massachusetts is 0\"\n[1] \"Percentage of  Japanese in Massachusetts is 0.31\"\n[1] \"Percentage of  White in New Hampshire is 93.48\"\n[1] \"Percentage of  Black/Negro in New Hampshire is 0.72\"\n[1] \"Percentage of  Other race, nec in New Hampshire is 0.72\"\n[1] \"Percentage of  American Indian or Alaska Native in New Hampshire is 0.72\"\n[1] \"Percentage of  Chinese in New Hampshire is 0.72\"\n[1] \"Percentage of  Other Asian or Pacific Islander in New Hampshire is 2.17\"\n[1] \"Percentage of  Two major races in New Hampshire is 0.72\"\n[1] \"Percentage of  Three or more major races in New Hampshire is 0\"\n[1] \"Percentage of  Japanese in New Hampshire is 0.72\"\n[1] \"Percentage of  White in Washington is 76.05\"\n[1] \"Percentage of  Black/Negro in Washington is 2.9\"\n[1] \"Percentage of  Other race, nec in Washington is 5.37\"\n[1] \"Percentage of  American Indian or Alaska Native in Washington is 2.03\"\n[1] \"Percentage of  Chinese in Washington is 1.31\"\n[1] \"Percentage of  Other Asian or Pacific Islander in Washington is 6.68\"\n[1] \"Percentage of  Two major races in Washington is 4.79\"\n[1] \"Percentage of  Three or more major races in Washington is 0.29\"\n[1] \"Percentage of  Japanese in Washington is 0.58\"\n\n\nInstead of printing the percentage of each race in each state, create a dataframe, and store all that information in that dataframe. (Hint: look at how I stored information about male percentage in each state of interest in a vector.)"
  },
  {
    "objectID": "12_visualization.html",
    "href": "12_visualization.html",
    "title": "3  Visualization",
    "section": "",
    "text": "This lesson is about creating effective data visualizations using the ggplot2 package (part of the Tidyverse). Becoming good at graphing your data is a key skill you will want to develop while in the PhD program. Each graph you make should clearly communicate an insight without overloading your audience with too much information. Today we will practice the nuts and bolts of the coding necessary to accomplish this.\nLet’s start by loading in our external packages: the Tidyverse, and here.\nWe will load in the same “county_elections.csv” data set from the previous chapter. Note: we will also remove each row in the data set containing missing values so that we avoid being spammed with warning messages from R. In a real data analysis project, you will want to investigate the source of missing data rather than blanket-removing everything."
  },
  {
    "objectID": "12_visualization.html#univariate-graphs",
    "href": "12_visualization.html#univariate-graphs",
    "title": "3  Visualization",
    "section": "\n3.1 Univariate Graphs",
    "text": "3.1 Univariate Graphs\nThe first graph we will make is a histogram. Histograms are the most common type of graph for continuous variables and make it easy to see the spread and central tendency of the data. Let’s plot the distribution of county median household income using the variable median_hh_inc in county_elections.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc) +\n  geom_histogram()\n\n\n\n\nEach graph you create using ggplot will contain the following three elements\n\n\nData. You need to tell ggplot which data set the variables that you want to graph come from. This section is ggplot(county_elections) in the code above.\n\nAesthetics. Now that we know which data set we’re working with, which variables do you want to use and in what way do we want them to be used? This information goes in the aes() section. Because histograms typically view the distribution of a single variable along the x-axis of a graph, we specify our aesthetic aes(x = median_hh_inc) in the code above.\n\nGeoms. The “geom” we choose defines the type of graph we’re ultimately creating (histogram, scatter plot, bar graph, etc). As you might expect, geom_histogram() creates a histogram for us!\n\nIn ggplot we combine these elements together using the + symbol. You could put the data, aesthetics, and geom sections all in the same line of code. But it is good practice to put each on its own line to make your code more readable.\nEach geom in ggplot has tons of extra options (also called arguments), which you can specify to make your graphs more pretty. Let’s begin to customize our histogram!\n\nggplot(county_elections) +\n  aes(x = median_hh_inc) +\n  geom_histogram(bins = 50,\n                 color = \"white\",\n                 fill = \"steelblue\")\n\n\n\n\nWow look at that! Now let’s fix the ugly default names on the x and y axes, and add an informative title for our graph. We add custom labels to a ggplot graph by adding another + followed by a labs() section.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc) +\n  geom_histogram(bins = 50,\n                 color = \"white\",\n                 fill = \"steelblue\") +\n  labs(title = \"Distribution of Median County Incomes\",\n       x = \"Median Household Income\",\n       y = \"Count\")\n\n\n\n\nThemes in ggplot control the overall look and background style of our graphs. For a complete list of themes: Link. There is also a package with a bunch of additional cool themes you can check out here: Link. Personally I’m a big fan of theme_minimal().\n\nggplot(county_elections) +\n  aes(x = median_hh_inc) +\n  geom_histogram(bins = 50,\n                 color = \"white\",\n                 fill = \"steelblue\") +\n  labs(title = \"Distribution of Median County Incomes\",\n       x = \"Median Household Income\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nOur county median household income variable looks like it’s a bit right-skewed—with a few extremely high income counties shown on the right hand side of the graph. Depending on your research question, it might make more sense to view this distribution on the log scale. It’s very easy to do this in ggplot using scale_x_log10().\n\nggplot(county_elections) +\n  aes(x = median_hh_inc) +\n  geom_histogram(bins = 50,\n                 color = \"white\",\n                 fill = \"steelblue\") +\n  labs(title = \"Distribution of Median County Incomes\",\n       x = \"Median Household Income\",\n       y = \"\",\n       caption = \"(log10 scale)\") +\n  theme_minimal() +\n  scale_x_log10(labels = scales::dollar)\n\n\n\n\nNow the data looks almost normally distributed. Also note the use of scales::dollar to make our x-axis a little easier to read. The scales package provides a ton of handy functions to deal with ugly default scales in ggplot. The :: operator is a way of accessing a single function from a package without loading all its other functions into R. It’s also a way of being explicit about which package’s function you are using. Sometimes you will run across situations where multiple packages have functions with the same name, but which do different things! Speaking from personal experience, this can lead to some really frustrating debugging sessions."
  },
  {
    "objectID": "12_visualization.html#bivariate-graphs",
    "href": "12_visualization.html#bivariate-graphs",
    "title": "3  Visualization",
    "section": "\n3.2 Bivariate Graphs",
    "text": "3.2 Bivariate Graphs\nIf histograms are the most common way to plot the distribution of a single continuous variable, scatter plots are the most common way to show the relationship between two continuous variables. Translating our histogram ggplot code to a scatter plot is straightforward: simply add a y-axis variable to aes(), and change the geom to geom_point(). The graph below displays the relationship between median household income and the population percentage in a county who did not complete high school.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point()\n\n\n\n\nIt looks like richer counties have lower rates of their population having less than a high school education. We can use the same customization options from histograms on our scatter plot to make things prettier.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point() +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n\n\n\nA lot of our data seems to be clustered up together. The solid points in geom_point() obscure this density so let’s fix this using the alpha argument. A geom’s alpha level specifies its transparency and ranges from 1 (solid) to 0 (invisible).\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point(alpha = 0.2, color = \"darkcyan\") +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n\n\n\nThe negative relationship between our two variables is clear just by eyeballing it, but if we want to be real scientists we need to add the magic regression line. If you are unfamiliar with regression lines, don’t worry—we will be covering them extensively in your introductory quantitative methods course. A linear regression line is essentially just the “best fitting” straight line to the data.\nAdding a regression line to the graph gives us our first opportunity to combine multiple geoms. In the code chunk below, notice how we simply use + to add geom_smooth() to our ggplot object. This overlays a fitted line on top of the dots from geom_point(). The argument method = \"lm\" tells ggplot to use a linear regression line (lm = “linear model”) as opposed to some other type of fitted line.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point(alpha = 0.2, color = \"darkcyan\") +\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nThis graph would look way more professional if it didn’t mistakenly predict negative high school percentage values for high income counties. Linear regression is clearly not flexible enough to reflect the true relationship between our two variables.\nWhat if we re-scaled median household income to the log10 scale again?\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point(alpha = 0.2, color = \"darkcyan\") +\n  geom_smooth(method = \"lm\", color = \"black\",\n              formula = \"y ~ log(x)\") +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n\n\n\nNot perfect, but now our fitted line is looking better!"
  },
  {
    "objectID": "12_visualization.html#trivariate-graphs",
    "href": "12_visualization.html#trivariate-graphs",
    "title": "3  Visualization",
    "section": "\n3.3 Trivariate(!) Graphs",
    "text": "3.3 Trivariate(!) Graphs\nWe are now experts are graphing one variable at a time, or two variables together, but what if we want to graph three or more variables at once? There are a number of ways to do this in ggplot as we will see below. However, first a word of caution: beware of cluttering your plots with too much information! It can be tempting to throw everything into a graph, but doing so can obscure the main point you’re trying to make. Always keep this in mind when going beyond graphing two variables at once.\n\n3.3.1 Using Colors and Shapes\nThe county_elections data set does not have a lot of categorical variables for us to work with. So let’s create one!\n\ncounty_elections <- county_elections |> \n  mutate(rural = ifelse(rural_pct > 50, \"Rural\", \"Not Rural\"))\n\nThis code chunk uses the mutate function to create a new variable in the county_elections data set called rural. The variable rural takes the value “Rural” if rural_pct is greater than 50 and takes the value “Not Rural” if rural_pct is less than or equal to 50. It is usually not a good idea to dichotomize a continuous variable in this way (using a binary Rural/Not Rural as opposed to the county’s rural percentage). Doing so throws away valuable information that is almost always relevant to the final analysis. In this case we can justify our choice to create a categorical variable because it will make plotting multiple variables much easier.\nLet’s now take our scatter plot showing the relationship between county median household income and education level, and color the points based on whether the county is rural or not. Doing so is as easy as adding color = rural to the aes() section in ggplot.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct,\n      color = rural) + # Coloring points based on rural variable\n  geom_point(alpha = 0.5) + # Removed color from geom\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n\n\n\nBy default, ggplot even gives us a handy legend to tell us which color points correspond to which value of rural.\nNow let’s try adding a third variable to our scatter plot which is continuous. One way to do this is with the size option in aes().\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct,\n      size = total_population) + # Changing size of points\n  geom_point(alpha = 0.2) + \n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic()\n\n\n\n\nAre we overdoing things with adding too much information to our graph? Possibly!\n\n3.3.2 Using Facets to Graph Comparisons\nOne of ggplot’s most powerful features is “faceting”. Facets allow you to easily graph comparisons between different levels of a categorical variable in a clear manner by creating side by side subgraphs. To apply a facet to our ggplot graph we can simply add + facet_wrap(~ facet_variable).\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point(alpha = 0.2, color = \"darkcyan\") +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic() +\n  facet_wrap(~ rural) # Adding faceting\n\n\n\n\nAs you can see, faceting is so powerful for showing comparisons because it preserves the scale in each subplot. This might be a better choice rather than coloring each point and overlapping everything. We can control whether we want the subgraphs side-by-side or on top of each other with the nrow argument.\n\nggplot(county_elections) +\n  aes(x = median_hh_inc, y = lesshs_pct) +\n  geom_point(alpha = 0.2, color = \"darkcyan\") +\n  labs(title = \"US Counties by Education and Income\",\n       x = \"Median Household Income\",\n       y = \"Less than High School %\") +\n  scale_x_continuous(label = scales::dollar) +\n  theme_classic() +\n  facet_wrap(~ rural, nrow = 2)"
  },
  {
    "objectID": "12_visualization.html#choropleth-maps",
    "href": "12_visualization.html#choropleth-maps",
    "title": "3  Visualization",
    "section": "\n3.4 Choropleth Maps",
    "text": "3.4 Choropleth Maps\nMaking maps in ggplot is relatively straightforward—and a much better idea than copying and pasting your data back and forth between R and a specialized program like ArcGIS. Choropleth maps show data broken down by geographic unit (in this case US counties). We will need to install an additional package urbnmapr to help ggplot make this type of graph. To install urbnmapr, run the following command in your Console.\n\ndevtools::install_github(\"UrbanInstitute/urbnmapr\")\n\nWe use the command devtools::install_github() because the developers of urbnmapr have not submitted their package to the official CRAN repository. So rather than using install.packages like we’re used to, we instead need to install the package directly from GitHub. A lot of excellent packages are not available on CRAN, but be aware that they might not have all the quality-control checks CRAN packages have.\nOnce you have the urbnmapr package installed, you can load it into R using:\n\nlibrary(urbnmapr)\n\nWe need to perform a couple data cleaning steps before the data is ready to map in ggplot. The first step is making our countyCode variable match the format of the corresponding US county code in the urbnmapr data. US counties are each given a unique 5-digit number called a FIPS code. However, at some point the “county_elections.csv” file was opened in Excel, which read the FIPS codes as numeric values thereby removing any 0’s from the start of each code. Never open your data in Excel! Now a bunch of the FIPS codes in our data are only 4-digits long instead of 5, which means they will not match the FIPS codes in the urbnmapr data. Luckily we can fix this using the Tidyverse. The function str_pad from the stringr package can be used to “pad” out a variable with a specific character until it becomes a specific size.\n\ncounty_elections <- county_elections |> \n  mutate(county_fips = str_pad(countyCode, width = 5, pad = \"0\"))\n\nNext we need to join our county_elections data with the mapping data from urbnmapr. We will do this using a left_join command, which, if you are not familiar with, we will cover in much greater detail in a future lesson. The big idea here is that we have one data set with county-level variables, such as median household income, that we need to merge with a data set containing the geographic coordinate information for each US county.\n\nmap_data <- left_join(county_elections, counties)\n\nAwesome! Now we are ready to make a map! Let’s check out the geographic distribution of population percentage without a high school diploma.\n\nggplot(map_data) +\n  aes(x = long, y = lat, \n      group = group, fill = lesshs_pct) +\n  geom_polygon(color = NA) +\n  # This second geom_polygon shows the state borders\n  geom_polygon(data = states, mapping = aes(long, lat, group = group),\n               fill = NA, size = 0.1, color = \"white\") +\n  # Making maps requires you to choose a geographic projection\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  # theme_void gives us a blank canvas\n  theme_void()\n\nDon’t worry if you are not yet able to understand every aspect of the ggplot code that produced this map. Try playing around with some of the arguments and see what happens to the map!\n\nggplot(map_data) +\n  aes(x = long, y = lat, \n      group = group, fill = lesshs_pct) +\n  geom_polygon(color = NA) +\n  geom_polygon(data = states, mapping = aes(long, lat, group = group),\n               fill = NA, size = 0.1, color = \"white\") +\n  coord_map(projection = \"albers\", lat0 = 39, lat1 = 45) +\n  # This creates a diverging color scale\n  # that is also colorblind friendly\n  scale_fill_viridis_c() +\n  labs(fill = \"Less than High School %\") +\n  theme_void() +\n  theme(legend.position = \"bottom\") \n\nSometimes a diverging color scale is better for contrasting high and low value areas."
  },
  {
    "objectID": "13_data_wrangling_cleaning.html",
    "href": "13_data_wrangling_cleaning.html",
    "title": "4  Data Wrangling and Cleaning",
    "section": "",
    "text": "The raw data used in much of political science research rarely comes to us in a format that is immediately accessible for analysis. Instead, we frequently need to write an R script to “clean” the data first. Only after cleaning the data will it be usable for visualization or statistical modeling. This process (also known as “data wrangling”) can be extremely arduous and time-consuming—depending on how messy the raw data is in the first place. According to the common aphorism, the time you spend writing R code to clean your data sets will far exceed the time you spend subsequently running any sort of statistical analysis on the cleaned data.\nAlthough data cleaning has a reputation as a dull, menial task (compared to the “fun” of statistical modeling), try to avoid treating the process like it is merely a roadblock—something to be overcome before you can begin the real analysis. In fact, each decision you make when wrangling your raw data into its final state is a crucial part of the final research product. Whether or not to drop certain observations, or using different levels of data aggregation are some examples of choices which can have massive downstream effects. You should be thoughtful and transparent about your decision-making process the whole time you spend cleaning data."
  },
  {
    "objectID": "13_data_wrangling_cleaning.html#cleaning-data-using-dplyr",
    "href": "13_data_wrangling_cleaning.html#cleaning-data-using-dplyr",
    "title": "4  Data Wrangling and Cleaning",
    "section": "\n4.2 Cleaning Data Using dplyr",
    "text": "4.2 Cleaning Data Using dplyr\nAs in the other sections of this book, we will be using the Tidyverse approach to data cleaning here. The Tidyverse package for data cleaning is dplyr and it contains most of the functions we will be using in this chapter.\nRather than downloading a .csv file and using the read_csv() function to load in our data for this chapter, we will be using a package which contains multiple data sets. The data come from the United Nations General Assembly. First install the unvotes package by running the following command in your Console.\n\ninstall.packages(\"unvotes\")\n\nThen run\n\nlibrary(unvotes)\nlibrary(tidyverse)\n\nWhen you use the library() function, many packages automatically load small data sets that immediately become available for use. However, accessing these data can be a bit confusing because they do not automatically show up as objects in your Environment tab. Let’s add the unvotes data sets to our Environment with the following chunk of code:\n\nun_votes <- un_votes\nun_roll_calls <- un_roll_calls\nun_roll_call_issues <- un_roll_call_issues\n\n\n\nun_votes, country-vote level data. Each row is a country’s vote on a particular UN Assembly resolution.\n\nun_roll_calls, resolution level data. Contains information about each resolution.\n\nun_roll_call_issues, resolution level data. Contains the issue-area for each resolution.\n\n\n4.2.1 The Pipe Operator\nBefore we get started using dplyr we need to first introduce the “pipe” operator |>. Pipes are an extremely convenient tool for linking sequences of functions together. They work by passing the object on the left hand side of the pipe into the function following the pipe. Here is an example.\n\n# The pipe way\nme |> \n  wake_up(time = \"8:00\") |> \n  get_out_of_bed(side = \"correct\") |> \n  get_dressed(pants = TRUE, shirt = TRUE) |> \n  leave_house(car = FALSE, bike = TRUE)\n\n# The non-pipe way\nleave_house(get_dressed(get_out_of_bed(wake_up(me, time = \"8:00\"), side = \"correct\"), pants = TRUE, shirt = TRUE), car = FALSE, bike = TRUE)\n\nBoth code chunks above will end up doing the same thing. But the pipe method is much easier to write, and much easier for others to read and understand.\nBefore R version 4.1, the pipe operator was only available in the magrittr package (which remains part of the Tidyverse). The magrittr pipe is written %>% and many R users continue to use this over the native R |>. There are a few very minor differences between the two pipes, which you should feel free to ignore. We use the native R |> pipe in this book because it is generally a good idea, all else equal, to reduce your dependency on outside packages when writing code."
  },
  {
    "objectID": "13_data_wrangling_cleaning.html#working-with-columns",
    "href": "13_data_wrangling_cleaning.html#working-with-columns",
    "title": "4  Data Wrangling and Cleaning",
    "section": "\n4.3 Working with Columns",
    "text": "4.3 Working with Columns\nEach column in a data set typically represents a single variable, or attribute, relating to the observation in a particular row. In this section we will look at some of dplyr’s functions for working with columns.\n\n4.3.1 Select\nThe select() function is primarily used to remove unwanted columns from the data. Here is an example.\n\nun_roll_calls |> \n  select(rcid, date) |> # Keeping only two variables\n  head() # Print out first 6 rows\n\n# A tibble: 6 × 2\n   rcid date      \n  <int> <date>    \n1     3 1946-01-01\n2     4 1946-01-02\n3     5 1946-01-04\n4     6 1946-01-04\n5     7 1946-01-02\n6     8 1946-01-05\n\n\nThe head() function prints out the first few rows of a data set, and can be helpful to check if your cleaning function worked in the way you expected.\nNote that the code chunk above did not alter the data set object un_roll_calls. If we wanted to take this smaller data set and use it for something else, we will need to use the assignment operator <- to save our work.\n\n# This creates a new object called \"small_un_roll_calls\"\n# containly only rcid and date columns\nsmall_un_roll_calls <- un_roll_calls |> \n  select(rcid, date)\n\nThe select() function can be very versatile. Rather than typing every column name we want to keep, it is often faster to specify the columns we want to drop.\n\nun_roll_calls |> \n  select(-session) |> # Keep everything except session column\n  head()\n\n# A tibble: 6 × 8\n   rcid importantvote date       unres   amend  para short                 descr\n  <int>         <int> <date>     <chr>   <int> <int> <chr>                 <chr>\n1     3             0 1946-01-01 R/1/66      1     0 AMENDMENTS, RULES OF… \"TO …\n2     4             0 1946-01-02 R/1/79      0     0 SECURITY COUNCIL ELE… \"TO …\n3     5             0 1946-01-04 R/1/98      0     0 VOTING PROCEDURE      \"TO …\n4     6             0 1946-01-04 R/1/107     0     0 DECLARATION OF HUMAN… \"TO …\n5     7             0 1946-01-02 R/1/295     1     0 GENERAL ASSEMBLY ELE… \"TO …\n6     8             0 1946-01-05 R/1/297     1     0 ECOSOC POWERS         \"TO …\n\n\nThere are many other convenient ways to selection columns (e.g. by common names, by type of data, or by position in the data set). For a full list of ways to use select() see this link. Here is one example of selecting every column which is a “character” type.\n\nun_roll_calls |> \n  select(where(is.character)) |> \n  head()\n\n# A tibble: 6 × 3\n  unres   short                          descr                                  \n  <chr>   <chr>                          <chr>                                  \n1 R/1/66  AMENDMENTS, RULES OF PROCEDURE \"TO ADOPT A CUBAN AMENDMENT TO THE UK …\n2 R/1/79  SECURITY COUNCIL ELECTIONS     \"TO ADOPT A USSR PROPOSAL ADJOURNING D…\n3 R/1/98  VOTING PROCEDURE               \"TO ADOPT THE KOREAN PROPOSAL THAT INV…\n4 R/1/107 DECLARATION OF HUMAN RIGHTS    \"TO ADOPT A CUBAN PROPOSAL (A/3-C) THA…\n5 R/1/295 GENERAL ASSEMBLY ELECTIONS     \"TO ADOPT A 6TH COMMITTEE AMENDMENT (A…\n6 R/1/297 ECOSOC POWERS                  \"TO ADOPT A SECOND 6TH COMM. AMENDMENT…\n\n\nLastly, we can use select() to rename columns in our data. The chunk of code below selects the “unres” and date columns, and renames “unres” to “un_resolution” at the same time.\n\nun_roll_calls |> \n  select(un_resolution = unres, date) |> \n  head()\n\n# A tibble: 6 × 2\n  un_resolution date      \n  <chr>         <date>    \n1 R/1/66        1946-01-01\n2 R/1/79        1946-01-02\n3 R/1/98        1946-01-04\n4 R/1/107       1946-01-04\n5 R/1/295       1946-01-02\n6 R/1/297       1946-01-05\n\n\nIf you only want to rename columns—without specifying which to select—dplyr has a function rename() for this purpose. The syntax is similar to the code chunk above new_variable_name = original_variable_name. This code will keep all columns and change the names of the specified variables.\n\nun_roll_calls |> \n  rename(un_resolution = unres,\n         amendment = amend,\n         paragraph = para) |> \n  head()\n\n# A tibble: 6 × 9\n   rcid session importantvote date       un_resolu…¹ amend…² parag…³ short descr\n  <int>   <dbl>         <int> <date>     <chr>         <int>   <int> <chr> <chr>\n1     3       1             0 1946-01-01 R/1/66            1       0 AMEN… \"TO …\n2     4       1             0 1946-01-02 R/1/79            0       0 SECU… \"TO …\n3     5       1             0 1946-01-04 R/1/98            0       0 VOTI… \"TO …\n4     6       1             0 1946-01-04 R/1/107           0       0 DECL… \"TO …\n5     7       1             0 1946-01-02 R/1/295           1       0 GENE… \"TO …\n6     8       1             0 1946-01-05 R/1/297           1       0 ECOS… \"TO …\n# … with abbreviated variable names ¹​un_resolution, ²​amendment, ³​paragraph\n\n\n\n4.3.2 Mutate\nThe select() and rename() functions are great for tidying up your data sets, but they do not change the underlying variables. To change existing variables or to create new ones we use mutate().\nLet’s say we discovered that all the roll call IDs in the column “rcid” were supposed to be in multiples of 10. The code chunk below creates a new variable called “rcid_10” which is simply the value of the original “rcid” variable multiplied by 10.\n\nun_votes |> \n  mutate(rcid_10 = rcid * 10) |> \n  head()\n\n# A tibble: 6 × 5\n   rcid country            country_code vote  rcid_10\n  <dbl> <chr>              <chr>        <fct>   <dbl>\n1     3 United States      US           yes        30\n2     3 Canada             CA           no         30\n3     3 Cuba               CU           yes        30\n4     3 Haiti              HT           yes        30\n5     3 Dominican Republic DO           yes        30\n6     3 Mexico             MX           yes        30\n\n\nIf you didn’t want to create a brand new variable, and instead wanted to overwrite the original variable, you just need to put the original variable to the left of the = in mutate().\n\nun_votes |> \n  mutate(rcid = rcid * 10) |> \n  head()\n\n# A tibble: 6 × 4\n   rcid country            country_code vote \n  <dbl> <chr>              <chr>        <fct>\n1    30 United States      US           yes  \n2    30 Canada             CA           no   \n3    30 Cuba               CU           yes  \n4    30 Haiti              HT           yes  \n5    30 Dominican Republic DO           yes  \n6    30 Mexico             MX           yes  \n\n\nWe commonly need to create a new variable whose values depend on the values of one of the original variables. The function case_when() helps us do this inside mutate().\n\nun_votes |> \n  mutate(vote_dummy = case_when(vote == \"yes\" ~ 1,\n                                vote == \"no\" ~ 0)) |> \n  head()\n\n# A tibble: 6 × 5\n   rcid country            country_code vote  vote_dummy\n  <dbl> <chr>              <chr>        <fct>      <dbl>\n1     3 United States      US           yes            1\n2     3 Canada             CA           no             0\n3     3 Cuba               CU           yes            1\n4     3 Haiti              HT           yes            1\n5     3 Dominican Republic DO           yes            1\n6     3 Mexico             MX           yes            1\n\n\nAs you can see, the code chunk above creates a new variable called “vote_dummy” which takes the value 1 if “vote” equals \"yes\" and takes the values 0 if “vote” equals \"no\". Like other programming languages, R uses the == logical operator to check whether a value equals, or is equivalent, to some other value. This is different from the single = which is used to create entire new variables inside mutate().\nHere is one more example using case_when().\n\nun_votes |> \n  mutate(rcid_era = case_when(rcid < 2000 ~ \"old\",\n                              rcid >= 2000 & rcid < 6000 ~ \"middle\",\n                              rcid >= 6000 ~ \"recent\")) |> \n  head()\n\n# A tibble: 6 × 5\n   rcid country            country_code vote  rcid_era\n  <dbl> <chr>              <chr>        <fct> <chr>   \n1     3 United States      US           yes   old     \n2     3 Canada             CA           no    old     \n3     3 Cuba               CU           yes   old     \n4     3 Haiti              HT           yes   old     \n5     3 Dominican Republic DO           yes   old     \n6     3 Mexico             MX           yes   old     \n\n\nThe new variable “rcid_era” takes three values, \"old\", \"middle\", and \"recent\" based on what range the “rcid” variable falls under."
  },
  {
    "objectID": "13_data_wrangling_cleaning.html#working-with-rows",
    "href": "13_data_wrangling_cleaning.html#working-with-rows",
    "title": "4  Data Wrangling and Cleaning",
    "section": "\n4.4 Working with Rows",
    "text": "4.4 Working with Rows\n\n4.4.1 Filter\n\n4.4.2 Aggregation"
  },
  {
    "objectID": "13_data_wrangling_cleaning.html#merging-data",
    "href": "13_data_wrangling_cleaning.html#merging-data",
    "title": "4  Data Wrangling and Cleaning",
    "section": "\n4.5 Merging Data",
    "text": "4.5 Merging Data"
  },
  {
    "objectID": "13_data_wrangling_cleaning.html#reshaping-data",
    "href": "13_data_wrangling_cleaning.html#reshaping-data",
    "title": "4  Data Wrangling and Cleaning",
    "section": "\n4.6 Reshaping Data",
    "text": "4.6 Reshaping Data"
  },
  {
    "objectID": "14_simulation.html",
    "href": "14_simulation.html",
    "title": "5  Simulation",
    "section": "",
    "text": "Module originally written by Connor Jerzak and Shiro Kuriwaki"
  },
  {
    "objectID": "14_simulation.html#pick-a-sample-any-sample",
    "href": "14_simulation.html#pick-a-sample-any-sample",
    "title": "5  Simulation",
    "section": "\n5.1 Pick a sample, any sample",
    "text": "5.1 Pick a sample, any sample"
  },
  {
    "objectID": "14_simulation.html#the-sample-function",
    "href": "14_simulation.html#the-sample-function",
    "title": "5  Simulation",
    "section": "\n5.2 The sample() function",
    "text": "5.2 The sample() function\nThe core functions for coding up stochastic data revolves around several key functions, so we will simply review them here.\nSuppose you have a vector of values x and from it you want to randomly sample a sample of length size. For this, use the sample function\n\nsample(x = 1:10, size = 5)\n\n[1]  5 10  3  9  2\n\n\nThere are two subtypes of sampling – with and without replacement.\n\nSampling without replacement (replace = FALSE) means once an element of x is chosen, it will not be considered again:\n\n\nsample(x = 1:10, size = 10, replace = FALSE) ## no number appears more than once\n\n [1]  3  6  1  9  7  2  4  8 10  5\n\n\n\nSampling with replacement (replace = TRUE) means that even if an element of x is chosen, it is put back in the pool and may be chosen again.\n\n\nsample(x = 1:10, size = 10, replace = TRUE) ## any number can appear more than once\n\n [1]  9  9  2 10  2  8  6  3  1 10\n\n\nIt follows then that you cannot sample without replacement a sample that is larger than the pool.\n\nsample(x = 1:10, size = 100, replace = FALSE)\n\nError in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\nSo far, every element in x has had an equal probability of being chosen. In some application, we want a sampling scheme where some elements are more likely to be chosen than others. The argument prob handles this.\nFor example, this simulates 20 fair coin tosses (each outcome is equally likely to happen)\n\nsample(c(\"Head\", \"Tail\"), size = 20, prob = c(0.5, 0.5), replace = TRUE)\n\n [1] \"Head\" \"Tail\" \"Head\" \"Tail\" \"Head\" \"Head\" \"Tail\" \"Tail\" \"Tail\" \"Head\"\n[11] \"Tail\" \"Head\" \"Head\" \"Head\" \"Head\" \"Tail\" \"Head\" \"Head\" \"Head\" \"Tail\"\n\n\nBut this simulates 20 biased coin tosses, where say the probability of Tails is 4 times more likely than the number of Heads\n\nsample(c(\"Head\", \"Tail\"), size = 20, prob = c(0.2, 0.8), replace = TRUE)\n\n [1] \"Head\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Head\" \"Tail\" \"Tail\"\n[11] \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Tail\" \"Head\" \"Head\" \"Tail\"\n\n\n\n5.2.1 Sampling rows from a dataframe\nIn tidyverse, there is a convenience function to sample rows randomly: sample_n() and sample_frac().\nFor example, load the dataset on cars, mtcars, which has 32 observations.\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\nsample_n picks a user-specified number of rows from the dataset:\n\nsample_n(mtcars, 3)\n\n                mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMerc 450SL     17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nHonda Civic    30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n\n\nSometimes you want a X percent sample of your dataset. In this case use sample_frac()\n\nsample_frac(mtcars, 0.10)\n\n               mpg cyl  disp  hp drat   wt  qsec vs am gear carb\nMerc 280C     17.8   6 167.6 123 3.92 3.44 18.90  1  0    4    4\nMaserati Bora 15.0   8 301.0 335 3.54 3.57 14.60  0  1    5    8\nValiant       18.1   6 225.0 105 2.76 3.46 20.22  1  0    3    1\n\n\nAs a side-note, these functions have very practical uses for any type of data analysis:\n\nInspecting your dataset: using head() all the same time and looking over the first few rows might lead you to ignore any issues that end up in the bottom for whatever reason.\nTesting your analysis with a small sample: If running analyses on a dataset takes more than a handful of seconds, change your dataset upstream to a fraction of the size so the rest of the code runs in less than a second. Once verifying your analysis code runs, then re-do it with your full dataset (by simply removing the sample_n / sample_frac line of code in the beginning). While three seconds may not sound like much, they accumulate and eat up time."
  },
  {
    "objectID": "14_simulation.html#random-numbers-from-specific-distributions",
    "href": "14_simulation.html#random-numbers-from-specific-distributions",
    "title": "5  Simulation",
    "section": "\n5.3 Random numbers from specific distributions",
    "text": "5.3 Random numbers from specific distributions\nrbinom()\nrbinom builds upon sample as a tool to help you answer the question – what is the total number of successes I would get if I sampled a binary (Bernoulli) result from a test with size number of trials each, with a event-wise probability of prob. The first argument n asks me how many such numbers I want.\nFor example, I want to know how many Heads I would get if I flipped a fair coin 100 times.\n\nrbinom(n = 1, size = 100, prob = 0.5)\n\n[1] 62\n\n\nNow imagine this I wanted to do this experiment 10 times, which would require I flip the coin 10 x 100 = 1000 times! Helpfully, we can do this in one line\n\nrbinom(n = 10, size = 100, prob = 0.5)\n\n [1] 48 44 43 55 43 45 53 51 47 47\n\n\nrunif()\nrunif also simulates a stochastic scheme where each event has equal probability of getting chosen like sample, but is a continuous rather than discrete system. We will cover this more in the next math module.\nThe intuition to emphasize here is that one can generate potentially infinite amounts (size n) of noise that is a essentially random\n\nrunif(n = 5)\n\n[1] 0.89145134 0.55938334 0.81210151 0.16814926 0.05935487\n\n\nrnorm()\nrnorm is also a continuous distribution, but draws from a Normal distribution – perhaps the most important distribution in statistics. It runs the same way as runif\n\nrnorm(n = 5)\n\n[1] -0.3604897  0.4750575  0.3720823 -0.4473629 -1.6970241\n\n\nTo better visualize the difference between the output of runif and rnorm, let’s generate lots of each and plot a histogram.\n\nfrom_runif <- runif(n = 1000)\nfrom_rnorm <- rnorm(n = 1000)\n\npar(mfrow = c(1, 2)) ## base-R parameter for two plots at once\nhist(from_runif)\nhist(from_rnorm)"
  },
  {
    "objectID": "14_simulation.html#r-p-and-d",
    "href": "14_simulation.html#r-p-and-d",
    "title": "5  Simulation",
    "section": "\n5.4 r, p, and d",
    "text": "5.4 r, p, and d\nEach distribution can do more than generate random numbers (the prefix r). We can compute the cumulative probability by the function pbinom(), punif(), and pnorm(). Also the density – the value of the PDF – by dbinom(), dunif() and dnorm()."
  },
  {
    "objectID": "14_simulation.html#set.seed",
    "href": "14_simulation.html#set.seed",
    "title": "5  Simulation",
    "section": "\n5.5 set.seed()\n",
    "text": "5.5 set.seed()\n\nR doesn’t have the ability to generate truly random numbers! Random numbers are actually very hard to generate. (Think: flipping a coin –> can be perfectly predicted if I know wind speed, the angle the coin is flipped, etc.). Some people use random noise in the atmosphere or random behavior in quantum systems to generate “truly” (?) random numbers. Conversely, R uses deterministic algorithms which take as an input a “seed” and which then perform a series of operations to generate a sequence of random-seeming numbers (that is, numbers whose sequence is sufficiently hard to predict).\nLet’s think about this another way. Sampling is a stochastic process, so every time you run sample() or runif() you are bound to get a different output (because different random seeds are used). This is intentional in some cases but you might want to avoid it in others. For example, you might want to diagnose a coding discrepancy by setting the random number generator to give the same number each time. To do this, use the function set.seed().\nIn the function goes any number. When you run a sample function in the same command as a preceding set.seed(), the sampling function will always give you the same sequence of numbers. In a sense, the sampler is no longer random (in the sense of unpredictable to use; remember: it never was “truly” random in the first place)\n\nset.seed(02138)\nrunif(n = 10)\n\n [1] 0.51236144 0.61530551 0.37451441 0.43541258 0.21166530 0.17812129\n [7] 0.04420775 0.45567854 0.88718264 0.06970056\n\n\nThe random number generator should give you the exact same sequence of numbers if you precede the function by the same seed,\n\nset.seed(02138)\nrunif(n = 10)\n\n [1] 0.51236144 0.61530551 0.37451441 0.43541258 0.21166530 0.17812129\n [7] 0.04420775 0.45567854 0.88718264 0.06970056"
  },
  {
    "objectID": "14_simulation.html#exercises",
    "href": "14_simulation.html#exercises",
    "title": "5  Simulation",
    "section": "Exercises",
    "text": "Exercises\nCensus Sampling\nWhat can we learn from surveys of populations, and how wrong do we get if our sampling is biased?5 Suppose we want to estimate the proportion of U.S. residents who are non-white (race != \"White\"). In reality, we do not have any population dataset to utilize and so we only see the sample survey. Here, however, to understand how sampling works, let’s conveniently use the Census extract in some cases and pretend we didn’t in others.\n\nFirst, load usc2010_001percent.csv into your R session. After loading the library(tidyverse), browse it. Although this is only a 0.01 percent extract, treat this as your population for pedagogical purposes. What is the population proportion of non-White residents?\n\n\n\n\n\nSetting a seed to 1669482, sample 100 respondents from this sample. What is the proportion of non-White residents in this particular sample? By how many percentage points are you off from (what we labelled as) the true proportion?\n\n\n\n\n\nNow imagine what you did above was one survey. What would we get if we did 20 surveys?\n\nTo simulate this, write a loop that does the same exercise 20 times, each time computing a sample proportion. Use the same seed at the top, but be careful to position the set.seed function such that it generates the same sequence of 20 samples, rather than 20 of the same sample.\nTry doing this with a for loop and storing your sample proportions in a new length-20 vector. (Suggestion: make an empty vector first as a container). After running the loop, show a histogram of the 20 values. Also what is the average of the 20 sample estimates?\n\n\n\n\nNow, to make things more real, let’s introduce some response bias. The goal here is not to correct response bias but to induce it and see how it affects our estimates. Suppose that non-White residents are 10 percent less likely to respond to enter your survey than White respondents. This is plausible if you think that the Census is from 2010 but you are polling in 2018, and racial minorities are more geographically mobile than Whites. Repeat the same exercise in (c) by modeling this behavior.\n\nYou can do this by creating a variable, e.g. propensity, that is 0.9 for non-Whites and 1 otherwise. Then, you can refer to it in the propensity argument.\n\n\n\n\nFinally, we want to see if more data (“Big Data”) will improve our estimates. Using the same unequal response rates framework as (d), repeat the same exercise but instead of each poll collecting 100 responses, we collect 10,000.\n\n\n\n\n\nOptional - visualize your 2 pairs of 20 estimates, with a bar showing the “correct” population average.\n\n\n\n\nConditional Proportions\nThis example is not on simulation, but is meant to reinforce some of the probability discussion from math lecture.\nRead in the Upshot Siena poll from Fall 2016, data/input/upshot-siena-polls.csv.\nIn addition to some standard demographic questions, we will focus on one called vt_pres_2 in the csv. This is a two-way presidential vote question, asking respondents who they plan to vote for President if the election were held today – Donald Trump, the Republican, or Hilary Clinton, the Democrat, with options for Other candidates as well. For this problem, use the two-way vote question rather than the 4-way vote question.\n\nDrop the the respondents who answered the November poll (i.e. those for which poll == \"November\"). We do this in order to ignore this November population in all subsequent parts of this question because they were not asked the Presidential vote question.\n\n\n\n\n\nUsing the dataset after the procedure in (a), find the proportion of poll respondents (those who are in the sample) who support Donald Trump.\n\n\n\n\n\nAmong those who supported Donald Trump, what proportion of them has a Bachelor’s degree or higher (i.e. have a Bachelor’s, Graduate, or other Professional Degree)?\nAmong those who did not support Donald Trump (i.e. including supporters of Hilary Clinton, another candidate, or those who refused to answer the question), what proportion of them has a Bachelor’s degree or higher?\nExpress the numbers in the previous parts as probabilities of specified events. Define your own symbols: For example, we can let T be the event that a randomly selected respondent in the poll supports Donald Trump, then the proportion in part (b) is the probability P(T).\nSuppose we randomly sampled a person who participated in the survey and found that he/she had a Bachelor’s degree or higher. Given this evidence, what is the probability that the same person supports Donald Trump? Use Bayes Rule and show your work – that is, do not use data or R to compute the quantity directly. Then, verify this is the case via R.\nThe Birthday problem\nWrite code that will answer the well-known birthday problem via simulation.6\nThe problem is fairly simple: Suppose k people gather together in a room. What is the probability at least two people share the same birthday?\nTo simplify reality a bit, assume that (1) there are no leap years, and so there are always 365 days in a year, and (2) a given individual’s birthday is randomly assigned and independent from each other.\nStep 1: Set k to a concrete number. Pick a number from 1 to 365 randomly, k times to simulate birthdays (would this be with replacement or without?).\n\n# Your code\n\nStep 2: Write a line (or two) of code that gives a TRUE or FALSE statement of whether or not at least two people share the same birth date.\n\n# Your code\n\nStep 3: The above steps will generate a TRUE or FALSE answer for your event of interest, but only for one realization of an event in the sample space. In order to estimate the probability of your event happening, we need a “stochastic”, as opposed to “deterministic”, method. To do this, write a loop that does Steps 1 and 2 repeatedly for many times, call that number of times sims. For each of sims iteration, your code should give you a TRUE or FALSE answer. Code up a way to store these estimates.\n\n# Your code\n\nStep 4: Finally, generalize the function further by letting k be a user-defined number. You have now created a Monte Carlo simulation!\n\n# Your code\n\nStep 5: Generate a table or plot that shows how the probability of sharing a birthday changes by k (fixing sims at a large number like 1000). Also generate a similar plot that shows how the probability of sharing a birthday changes by sims (fixing k at some arbitrary number like 10).\n\n# Your code\n\nExtra credit: Give an “analytical” answer to this problem, that is an answer through deriving the mathematical expressions of the probability.\n\n# Your equations"
  },
  {
    "objectID": "15_non-wysiwyg.html",
    "href": "15_non-wysiwyg.html",
    "title": "6  LaTeX and Markdown",
    "section": "",
    "text": "Up till now, you should have covered:\n\nStatistical Programming in R\n\n\nThis is only the beginning of R – programming is like learning a language, so learn more as we use it. And yet R is of likely not the only programming language you will want to use. While we cannot introduce everything, we’ll pick out a few that we think are particularly helpful.\nHere will cover\n\nMarkdown\nLaTeX (and BibTeX)\n\nas examples of a non-WYSIWYG editor\ncommand-line are a basic set of tools that you may have to use from time to time. It also clarifies what more complicated programs are doing. Markdown is an example of compiling a plain text file. LaTeX is a typesetting program and git is a version control program – both are useful for non-quantitative work as well.\nPlease familiarize yourself closing with Markdown, and be sure you know how to open an .Rmd file as described below. In class, we will walk through an Rmd file together. LaTeX is included here for your future reference as this is a popular typesetting program among political scientists. This is not needed for Math Camp and is never required for any course. In fact, many prefer R Markdown’s integration rather than a separate typesetting program. This depends on your background and interests but exposure to the range of popular programs and techniques will be helpful moving forward."
  },
  {
    "objectID": "15_non-wysiwyg.html#motivation",
    "href": "15_non-wysiwyg.html#motivation",
    "title": "6  LaTeX and Markdown",
    "section": "\n6.1 Motivation",
    "text": "6.1 Motivation\nStatistical programming is a fast-moving field. The beta version of R was released in 2000, ggplot2 was released on 2005, and RStudio started around 2010. Of course, some programming technologies are quite “old”: (C in 1969, C++ around 1989, TeX in 1978, Linux in 1991, Mac OS in 1984). But it is easy to feel you are falling behind in the recent developments of programming. Today we will do a brief and rough overview of some fundamental and new tools other than R, with the general aim of having you break out of your comfort zone so you won’t be shut out from learning these tools in the future."
  },
  {
    "objectID": "15_non-wysiwyg.html#markdown",
    "href": "15_non-wysiwyg.html#markdown",
    "title": "6  LaTeX and Markdown",
    "section": "\n6.2 Markdown",
    "text": "6.2 Markdown\nAt its core markdown is just plain text. Plain text does not have any formatting embedded in it. Instead, the formatting is coded up as text. Markdown is not a WYSIWYG (What you see is what you get) text editor like Microsoft Word or Google Docs. This will mean that you need to explicitly code for bold{text} rather than hitting Command+B and making your text look bold on your own computer.\nMarkdown is known as a “light-weight” editor, which means that it is relatively easy to write code that will compile. It is quick and easy and satisfies most presentation purposes; you might want to try LaTeX for more involved papers.\n\n6.2.1 markdown commands\nFor italic and bold, use either the asterisks or the underlines,\n*italic*   **bold**\n_italic_   __bold__\nAnd for headers use the hash symbols,\n# Main Header\n## Sub-headers\n\n6.2.2 your own markdown\nRStudio makes it easy to compile your very first markdown file by giving you templates. Got to New > R Markdown, pick a document and click Ok. This will give you a skeleton of a document you can compile – or “knit”.\nRmd is actually a slight modification of real markdown. It is a type of file that R reads and turns into a proper md file. Then, it uses a document-conversion called pandoc to compile your md into documents like PDF or HTML.\n\n\nHow Rmds become PDFs or HTMLs\n\n\n\n6.2.3 A note on plain-text editors\nMultiple software exist where you can edit plain-text (roughly speaking, text that is not WYSIWYG).\n\nRStudio (especially for R-related links)\nTeXMaker, TeXShop (especially for TeX)\n\nemacs, aquamacs (general)\n\nvim (general)\n\nSublime Text (general)\n\nAtom (general)\n\nEach has their own keyboard shortcuts and special features. You can browse a couple and see which one(s) you like."
  },
  {
    "objectID": "15_non-wysiwyg.html#latex",
    "href": "15_non-wysiwyg.html#latex",
    "title": "6  LaTeX and Markdown",
    "section": "\n6.3 LaTeX",
    "text": "6.3 LaTeX\nLaTeX is a typesetting program. You’d engage with LaTeX much like you engage with your R code. You will interact with LaTeX in a text editor, and will writing code which will be interpreted by the LaTeX compiler and which will finally be parsed to form your final PDF.\n\n6.3.1 compile online\n\nGo to https://www.overleaf.com\n\nScroll down and go to “CREATE A NEW PAPER” if you don’t have an account.\nLet’s discuss the default template.\nMake a new document, and set it as your main document. Then type in the Minimal Working Example (MWE):\n\n\n\\documentclass{article}\n\\begin{document}\nHello World\n\\end{document}\n\n\n6.3.2 compile your first LaTeX document locally\nLaTeX is a very stable system, and few changes to it have been made since the 1990s. The main benefit: better control over how your papers will look; better methods for writing equations or making tables; overall pleasing aesthetic.\n\nOpen a plain text editor. Then type in the MWE\n\n\n\\documentclass{article}\n\\begin{document}\nHello World\n\\end{document}\n\n\nSave this as hello_world.tex. Make sure you get the file extension right.\nOpen this in your “LaTeX” editor. This can be TeXMaker, Aqumacs, etc..\nGo through the click/dropdown interface and click compile.\n\n6.3.3 main LaTeX commands\nLaTeX can cover most of your typesetting needs, to clean equations and intricate diagrams.\nSome main commands you’ll be using are below, and a very concise cheat sheet here: https://wch.github.io/latexsheet/latexsheet.pdf\nMost involved features require that you begin a specific “environment” for that feature, clearly demarcating them by the notation \\begin{figure} and then \\end{figure}, e.g. in the case of figures.\n\\begin{figure}\n\\includegraphics{histogram.pdf}\n\\end{figure}\nwhere histogram.pdf is a path to one of your files.\nNotice that each line starts with a backslash \\ – in LaTeX this is the symbol to run a command.\nThe following syntax at the endpoints are shorthand for math equations.\n\\[\\int x^2 dx\\]\nthese compile math symbols: \\displaystyle \\int x^2 dx.1\nThe align environment is useful to align your multi-line math, for example.\n\\begin{align}\nP(A \\mid B) &= \\frac{P(A \\cap B)}{P(B)}\\\\\n&= \\frac{P(B \\mid A)P(A)}{P(B)}\n\\end{align}\n\\begin{align}\nP(A \\mid B) &= \\frac{P(A \\cap B)}{P(B)}\\\\\n&= \\frac{P(B \\mid A)P(A)}{P(B)}\n\\end{align}\nRegression tables should be outputted as .tex files with packages like xtable and stargazer, and then called into LaTeX by \\input{regression_table.tex} where regression_table.tex is the path to your regression output.\nFigures and equations should be labelled with the tag (e.g. label{tab:regression} so that you can refer to them later with their tag Table \\ref{tab:regression}, instead of hard-coding Table 2).\nFor some LaTeX commands you might need to load a separate package that someone else has written. Do this in your preamble (i.e. before \\begin{document}):\n\\usepackage[options]{package}\nwhere package is the name of the package and options are options specific to the package.\nFurther Guides\nFor a more comprehensive listing of LaTeX commands, Mayya Komisarchik has a great tutorial set of folders: https://scholar.harvard.edu/mkomisarchik/tutorials-0\nThere is a version of LaTeX called Beamer, which is a popular way of making a slideshow. Slides in markdown is also a competitor. The language of Beamer is the same as LaTeX but has some special functions for slides."
  },
  {
    "objectID": "15_non-wysiwyg.html#bibtex",
    "href": "15_non-wysiwyg.html#bibtex",
    "title": "6  LaTeX and Markdown",
    "section": "\n6.4 BibTeX",
    "text": "6.4 BibTeX\nBibTeX is a reference system for bibliographical tests. We have a .bib file separately on our computer. This is also a plain text file, but it encodes bibliographical resources with special syntax so that a program can rearrange parts accordingly for different citation systems.\n\n6.4.1 what is a .bib file?\nFor example, here is the Nunn and Wantchekon article entry in .bib form.\n@article{nunn2011slave,\n  title={The Slave Trade and the Origins of Mistrust in Africa},\n  author={Nunn, Nathan and Wantchekon, Leonard},\n  journal={American Economic Review},\n  volume={101},\n  number={7},\n  pages={3221--3252},\n  year={2011}\n}\nThe first entry, nunn2011slave, is “pick your favorite” – pick your own name for your reference system. The other slots in this @article entry are entries that refer to specific bibliographical text.\n\n6.4.2 what does LaTeX do with .bib files?\nNow, in LaTeX, if you type\n  \\textcite{nunn2011slave} argue that current variation in the trust among citizens of African countries has historical roots in the European slave trade in the 1600s.\n  \nas part of your text, then when the .tex file is compiled the PDF shows something like\n\nin whatever citation style (APSA, APA, Chicago) you pre-specified!\nAlso at the end of your paper you will have a bibliography with entries ordered and formatted in the appropriate citation.\n\nThis is a much less frustrating way of keeping track of your references – no need to hand-edit formatting the bibliography to conform to citation rules (which biblatex already knows) and no need to update your bibliography as you add and drop references (biblatex will only show entries that are used in the main text).\n\n6.4.3 stocking up on your .bib files\nYou should keep your own .bib file that has all your bibliographical resources. Storing entries is cheap (does not take much memory), so it is fine to keep all your references in one place (but you’ll want to make a new one for collaborative projects where multiple people will compile a .tex file).\nFor example, Gary’s BibTeX file is here: https://github.com/iqss-research/gkbibtex/blob/master/gk.bib\nCitation management software (Mendeley or Zotero) automatically generates .bib entries from your library of PDFs for you, provided you have the bibliography attributes right."
  },
  {
    "objectID": "15_non-wysiwyg.html#extension-optional-exercise",
    "href": "15_non-wysiwyg.html#extension-optional-exercise",
    "title": "6  LaTeX and Markdown",
    "section": "Extension: Optional Exercise",
    "text": "Extension: Optional Exercise\nCreate a LaTeX document for a hypothetical research paper on your laptop and, once you’ve verified it compiles into a PDF, come show it to either one of the instructors.\nYou can also use overleaf if you have preference for a cloud-based system. But don’t swallow the built-in templates without understanding or testing them.\nEach student will have slightly different substantive interests, so we won’t impose much of a standard. But at a minimum, the LaTeX document should have:\n\nA title, author, date, and abstract\nSections\nItalics and boldface\nA figure with a caption and in-text reference to it.\n\nDepending on your subfield or interests, try to implement some of the following:\n\nA bibliographical reference drawing from a separate .bib file\nA table\nA math expression\nA different font\nDifferent page margins\nDifferent line spacing"
  },
  {
    "objectID": "21_linear-algebra.html",
    "href": "21_linear-algebra.html",
    "title": "7  Linear Algebra",
    "section": "",
    "text": "Vector: A vector in n-space is an ordered list of n numbers. These numbers can be represented as either a row vector or a column vector:\n{\\bf v} = \\begin{bmatrix} v_1 & v_2 & \\dots & v_n\\end{bmatrix}\n{\\bf v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix}\nWe can also think of a vector as defining a point in n-dimensional space, usually \\mathbb{R}^n; each element of the vector defines the coordinate of the point in a particular direction.\nVector Addition and Subtraction: If two vectors, {\\bf u} and {\\bf v}, have the same length (i.e. have the same number of elements), they can be added (subtracted) together:\n{\\bf u} + {\\bf v} = \\begin{bmatrix} u_1 + v_1 \\\\ u_2 + v_2 \\\\ \\vdots \\\\ u_k + v_n \\end{bmatrix}\n{\\bf u} - {\\bf v} = \\begin{bmatrix} u_1 - v_1 \\\\ u_2 - v_2 \\\\ \\vdots \\\\ u_k - v_n \\end{bmatrix}\nScalar Multiplication: The product of a scalar c (i.e. a constant) and vector {\\bf v} is:\n c{\\bf v} =  \\begin{bmatrix} cv_1 \\\\ cv_2 \\\\ \\dots \\\\ cv_n \\end{bmatrix} \nVector Inner Product: The inner product (also called the dot product or scalar product) of two vectors {\\bf u} and {\\bf v} is again defined if and only if they have the same number of elements\n {\\bf u} \\cdot {\\bf v} = u_1v_1 + u_2v_2 + \\cdots + u_nv_n = \\sum_{i = 1}^n u_iv_i\nIf {\\bf u} \\cdot {\\bf v} = 0, the two vectors are orthogonal (or perpendicular).\nVector Norm: The norm of a vector is a measure of its length. There are many different ways to calculate the norm, but the most common is the Euclidean norm (which corresponds to our usual conception of distance in three-dimensional space):\n ||{\\bf v}|| = \\sqrt{{\\bf v}\\cdot{\\bf v}} = \\sqrt{ v_1v_1 + v_2v_2 + \\cdots + v_nv_n}\n\nExample 7.1 Let a = \\begin{bmatrix} 2\\\\1\\\\2\\end{bmatrix}, b = \\begin{bmatrix} 3\\\\4\\\\5 \\end{bmatrix}. Calculate the following:\n\na - b\na \\cdot b\n\n\n\nExercise 7.1 Let u = \\begin{bmatrix} 7\\\\1\\\\-5\\\\3\\end{bmatrix}, v = \\begin{bmatrix} 9\\\\-3\\\\2\\\\8 \\end{bmatrix}, w = \\begin{bmatrix} 1\\\\13\\\\ -7\\\\2 \\\\15 \\end{bmatrix}, and c = 2. Calculate the following:\n\nu-v\ncw\nu \\cdot v\nw \\cdot v"
  },
  {
    "objectID": "21_linear-algebra.html#linearindependence",
    "href": "21_linear-algebra.html#linearindependence",
    "title": "7  Linear Algebra",
    "section": "\n7.2 Linear Independence",
    "text": "7.2 Linear Independence\nLinear combinations: The vector {\\bf u} is a linear combination of the vectors {\\bf v}_1, {\\bf v}_2, \\cdots , {\\bf v}_k if\n{\\bf u} = c_1{\\bf v}_1 + c_2{\\bf v}_2 +  \\cdots + c_k{\\bf v}_k\nFor example, \\begin{bmatrix}9 \\\\ 13 \\\\ 17 \\end{bmatrix} is a linear combination of the following three vectors: \\begin{bmatrix}1 \\\\ 2 \\\\ 3 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ 3\\\\ 4\\end{bmatrix}, and \\begin{bmatrix} 3 \\\\ 4 \\\\ 5 \\end{bmatrix}. This is because \\begin{bmatrix}9 \\\\ 13 \\\\ 17 \\end{bmatrix} = (2)\\begin{bmatrix}1 \\\\ 2 \\\\ 3 \\end{bmatrix} + (-1)\\begin{bmatrix} 2 \\\\ 3\\\\ 4\\end{bmatrix} + 3\\begin{bmatrix} 3 \\\\ 4 \\\\ 5 \\end{bmatrix}\nLinear independence: A set of vectors {\\bf v}_1, {\\bf v}_2, \\cdots , {\\bf v}_k is linearly independent if the only solution to the equation\nc_1{\\bf v}_1 + c_2{\\bf v}_2 +  \\cdots + c_k{\\bf v}_k = 0\nis c_1 = c_2 = \\cdots = c_k = 0. If another solution exists, the set of vectors is linearly dependent.\nA set S of vectors is linearly dependent if and only if at least one of the vectors in S can be written as a linear combination of the other vectors in S.\nLinear independence is only defined for sets of vectors with the same number of elements; any linearly independent set of vectors in n-space contains at most n vectors.\nSince \\begin{bmatrix}9 \\\\ 13 \\\\ 17 \\end{bmatrix} is a linear combination of \\begin{bmatrix}1 \\\\ 2 \\\\ 3 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ 3\\\\ 4\\end{bmatrix}, and \\begin{bmatrix} 3 \\\\ 4 \\\\ 5 \\end{bmatrix}, these 4 vectors constitute a linearly dependent set.\n\nExample 7.2 Are the following sets of vectors linearly independent?\n\n\n\\begin{bmatrix}2 \\\\ 3 \\\\ 1 \\end{bmatrix} and \\begin{bmatrix}4 \\\\ 6 \\\\ 1 \\end{bmatrix}\n\n\n\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix}0 \\\\ 5 \\\\ 0 \\end{bmatrix}, and \\begin{bmatrix}10 \\\\ 10 \\\\ 0 \\end{bmatrix}\n\n\n\n\nExercise 7.2 Are the following sets of vectors linearly independent?\n\n{\\bf v}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} , {\\bf v}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} , {\\bf v}_3 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} \n{\\bf v}_1 = \\begin{bmatrix} 2 \\\\ 2 \\\\ 1 \\end{bmatrix} , {\\bf v}_2 = \\begin{bmatrix} -4 \\\\ 6 \\\\ 5 \\end{bmatrix} , {\\bf v}_3 = \\begin{bmatrix} -2 \\\\ 8 \\\\ 6 \\end{bmatrix}"
  },
  {
    "objectID": "21_linear-algebra.html#matrixbasics",
    "href": "21_linear-algebra.html#matrixbasics",
    "title": "7  Linear Algebra",
    "section": "\n7.3 Basics of Matrix Algebra",
    "text": "7.3 Basics of Matrix Algebra\nMatrix: A matrix is an array of real numbers arranged in m rows by n columns. The dimensionality of the matrix is defined as the number of rows by the number of columns, m \\times n.\n{\\bf A}=\\begin{bmatrix}\n    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n    a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    a_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\nNote that you can think of vectors as special cases of matrices; a column vector of length k is a k \\times 1 matrix, while a row vector of the same length is a 1 \\times k matrix.\nIt’s also useful to think of matrices as being made up of a collection of row or column vectors. For example,\n\\bf A = \\begin{bmatrix} {\\bf a}_1 & {\\bf a}_2 &  \\cdots & {\\bf a}_m \\end{bmatrix}\nMatrix Addition: Let \\bf A and \\bf B be two m\\times n matrices.\n\\mathbf{A+B}=\\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} & \\cdots & a_{1n}+b_{1n} \\\\ a_{21}+b_{21} & a_{22}+b_{22} & \\cdots & a_{2n}+b_{2n} \\\\ \\vdots & \\vdots  & \\ddots & \\vdots \\\\ a_{m1}+b_{m1} & a_{m2}+b_{m2} & \\cdots & a_{mn}+b_{mn} \\end{bmatrix}\nNote that matrices {\\bf A} and {\\bf B} must have the same dimensionality, in which case they are conformable for addition.\n\nExample 7.3 {\\bf A}=\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}, \\qquad {\\bf B}=\\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 1 & 2 \\end{bmatrix}\nFind \\mathbf{A}+\\mathbf{B}\n\nScalar Multiplication: Given the scalar s, the scalar multiplication of s {\\bf A} is\n s {\\bf A}=  s \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix} = \\begin{bmatrix} s a_{11} & s a_{12} & \\cdots & s a_{1n} \\\\ s a_{21} & s a_{22} & \\cdots & s a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ s a_{m1} & s a_{m2} & \\cdots & s a_{mn} \\end{bmatrix}\n\nExample 7.4 s=2,\n{\\bf A}=\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix}\nFind s {\\bf A}\n\nMatrix Multiplication: If {\\bf A} is an m\\times k matrix and \\bf B is a k\\times n matrix, then their product \\bf C = A B is the m\\times n matrix where\nc_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\\cdots+a_{ik}b_{kj}\n\nExample 7.5 \n\nFind \\begin{bmatrix} a&b\\\\c&d\\\\e&f \\end{bmatrix} \\begin{bmatrix} A&B\\\\C&D \\end{bmatrix}\nFind \\begin{bmatrix} 1&2&-1\\\\3&1&4 \\end{bmatrix} \\begin{bmatrix} -2&5\\\\4&-3\\\\2&1\\end{bmatrix}\n\n\nNote that the number of columns of the first matrix must equal the number of rows of the second matrix, in which case they are conformable for multiplication. The sizes of the matrices (including the resulting product) must be (m\\times k)(k\\times n)=(m\\times n)\nAlso note that if AB exists, BA exists only if \\dim({\\bf A}) = m \\times n and \\dim({\\bf B}) = n \\times m.\nThis does not mean that AB = BA. AB = BA is true only in special circumstances, like when {\\bf A} or {\\bf B} is an identity matrix or {\\bf A} = {\\bf B}^{-1}.\n\n7.3.1 Laws of Matrix Algebra\n\nAssociative: \\bf (A+B)+C = A+(B+C)\n\n\\bf (AB)C = A(BC)\nCommutative: \\bf A+B=B+A\n\nDistributive: \\bf A(B+C)=AB+AC\n\n\\bf (A+B)C=AC+BC\n\nCommutative law for multiplication does not hold – the order of multiplication matters:\n\\bf AB \\ne BA\nFor example,\n{\\bf A}=\\begin{bmatrix} 1&2\\\\-1&3\\end{bmatrix}, \\qquad {\\bf B}=\\begin{bmatrix} 2&1\\\\0&1\\end{bmatrix}\n{\\bf AB}=\\begin{bmatrix} 2&3\\\\-2&2\\end{bmatrix}, \\qquad {\\bf BA}=\\begin{bmatrix} 1&7\\\\-1&3\\end{bmatrix}\nTranspose: The transpose of the m\\times n matrix \\bf A is the n\\times m matrix {\\bf A}^\\top (also written {\\bf A}') obtained by interchanging the rows and columns of \\bf A.\nFor example,\n{\\bf A}=\\begin{bmatrix} 4&-2&3\\\\0&5&-1\\end{bmatrix}, \\qquad {\\bf A}^\\top=\\begin{bmatrix} 4&0\\\\-2&5\\\\3&-1 \\end{bmatrix}\n{\\bf B}=\\begin{bmatrix} 2\\\\-1\\\\3 \\end{bmatrix}, \\qquad {\\bf B}^\\top=\\begin{bmatrix} 2&-1&3\\end{bmatrix}\nThe following rules apply for transposed matrices:\n\n({\\bf A+B})^\\top = {\\bf A}^\\top+{\\bf B}^\\top\n({\\bf A}^\\top)^\\top={\\bf A}\n(s{\\bf A})^\\top = s{\\bf A}^\\top\n\n({\\bf AB})^\\top = {\\bf B}^\\top{\\bf A}^\\top; and by induction ({\\bf ABC})^\\top = {\\bf C}^\\top{\\bf B}^\\top{\\bf A}^\\top\n\n\nExample of ({\\bf AB})^\\top = {\\bf B}^\\top{\\bf A}^\\top:\n{\\bf A}=\\begin{bmatrix} 1&3&2\\\\2&-1&3\\end{bmatrix}, \\qquad {\\bf B}=\\begin{bmatrix} 0&1\\\\2&2\\\\3&-1\\end{bmatrix}\n ({\\bf AB})^\\top = \\left[ \\begin{bmatrix} 1&3&2\\\\2&-1&3\\end{bmatrix} \\begin{bmatrix} 0&1\\\\2&2\\\\3&-1\\end{bmatrix} \\right]^\\top = \\begin{bmatrix} 12&7\\\\5&-3 \\end{bmatrix}\n {\\bf B}^\\top{\\bf A}^\\top= \\begin{bmatrix} 0&2&3\\\\1&2&-1 \\end{bmatrix}  \\begin{bmatrix} 1&2\\\\3&-1\\\\2&3 \\end{bmatrix} = \\begin{bmatrix} 12&7\\\\5&-3 \\end{bmatrix}\n\nExercise 7.3 Let\nA =  \\begin{bmatrix} 2&0&-1&1\\\\1&2&0&1 \\end{bmatrix}\nB = \\begin{bmatrix} 1&5&-7\\\\1&1&0\\\\0&-1&1\\\\2&0&0\\end{bmatrix}\nC =  \\begin{bmatrix} 3&2&-1\\\\0&4&6 \\end{bmatrix}\nCalculate the following:\n\nAB\nBA\n(BC)^\\top\nBC^\\top"
  },
  {
    "objectID": "21_linear-algebra.html#systems-of-linear-equations",
    "href": "21_linear-algebra.html#systems-of-linear-equations",
    "title": "7  Linear Algebra",
    "section": "\n7.4 Systems of Linear Equations",
    "text": "7.4 Systems of Linear Equations\n\n7.4.1 Linear Equation\nLinear equations take form of a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n = b\na_i are parameters or coefficients. x_i are variables or unknowns.\nLinear because only one variable per term and degree is at most 1.\nWe are often interested in solving linear systems like\n\\left\\{\\begin{array}{ll} x-3y &= -3\\\\ 2x +y &= 8 \\end{array}\\right.\nMore generally, we might have a system of m equations in n unknowns \\begin{matrix}\n        a_{11}x_1  & + & a_{12}x_2 & + & \\cdots & + & a_{1n}x_n & = & b_1\\\\\n        a_{21}x_1  & + & a_{22}x_2 & + & \\cdots & + & a_{2n}x_n & = & b_2\\\\\n        \\vdots     &   &     &   & \\vdots &   &     & \\vdots & \\\\\n        a_{m1}x_1  & + & a_{m2}x_2 & + & \\cdots & + & a_{mn}x_n & = & b_m\n        \\end{matrix}\nA solution to a linear system of m equations in n unknowns is a set of n numbers x_1, x_2, \\cdots, x_n that satisfy each of the m equations.\nExample: x=3 and y=2 is the solution to the above 2\\times 2 linear system. If you graph the two lines, you will find that they intersect at (3,2).\nDoes a linear system have one, no, or multiple solutions? For a system of 2 equations with 2 unknowns (i.e., two lines):\n\n\nOne solution: The lines intersect at exactly one point.\n\nNo solution: The lines are parallel.\n\nInfinite solutions: The lines coincide.\n\nMethods to solve linear systems:\n\nSubstitution\nElimination of variables\nMatrix methods\n\n\nExercise 7.4 Provide a system of 2 equations with 2 unknowns that has\n\none solution\nno solution\ninfinite solutions"
  },
  {
    "objectID": "21_linear-algebra.html#systems-of-equations-as-matrices",
    "href": "21_linear-algebra.html#systems-of-equations-as-matrices",
    "title": "7  Linear Algebra",
    "section": "\n7.5 Systems of Equations as Matrices",
    "text": "7.5 Systems of Equations as Matrices\nMatrices provide an easy and efficient way to represent linear systems such as \\begin{matrix}\n        a_{11}x_1  & + & a_{12}x_2 & + & \\cdots & + & a_{1n}x_n & = & b_1\\\\\n        a_{21}x_1  & + & a_{22}x_2 & + & \\cdots & + & a_{2n}x_n & = & b_2\\\\\n        \\vdots     &   &     &   & \\vdots &   &     & \\vdots & \\\\\n        a_{m1}x_1  & + & a_{m2}x_2 & + & \\cdots & + & a_{mn}x_n & = & b_m\n        \\end{matrix}\nas {\\bf A x = b} where\nThe m \\times n {\\bf A} is an array of m n real numbers arranged in m rows by n columns: {\\bf A}=\\begin{bmatrix}\n    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n    a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n    \\vdots &  & \\ddots & \\vdots \\\\\n    a_{m1} & a_{m2} & \\cdots & a_{mn}\n    \\end{bmatrix}\nThe unknown quantities are represented by the vector {\\bf x}=\\begin{bmatrix} x_1\\\\x_2\\\\\\vdots\\\\x_n \\end{bmatrix}.\nThe right hand side of the linear system is represented by the vector {\\bf b}=\\begin{bmatrix} b_1\\\\b_2\\\\\\vdots\\\\b_m \\end{bmatrix}.\nAugmented Matrix: When we append \\bf b to the coefficient matrix \\bf A, we get the augmented matrix \\widehat{\\bf A}=[\\bf A | b] \\begin{bmatrix}\n    a_{11} & a_{12} & \\cdots & a_{1n} & | & b_1\\\\\n    a_{21} & a_{22} & \\cdots & a_{2n} & | & b_2\\\\\n    \\vdots &  & \\ddots & \\vdots & | & \\vdots\\\\\n    a_{m1} & a_{m2} & \\cdots & a_{mn} & | & b_m\n    \\end{bmatrix}\n\nExercise 7.5 Create an augmented matrix that represent the following system of equations:\n2x_1 -7x_2 + 9x_3 -4x_4 = 8\n41x_2 + 9x_3 -5x_6 = 11\nx_1 -15x_2 -11x_5 = 9"
  },
  {
    "objectID": "21_linear-algebra.html#finding-solutions-to-augmented-matrices-and-systems-of-equations",
    "href": "21_linear-algebra.html#finding-solutions-to-augmented-matrices-and-systems-of-equations",
    "title": "7  Linear Algebra",
    "section": "\n7.6 Finding Solutions to Augmented Matrices and Systems of Equations",
    "text": "7.6 Finding Solutions to Augmented Matrices and Systems of Equations\nRow Echelon Form: Our goal is to translate our augmented matrix or system of equations into row echelon form. This will provide us with the values of the vector x which solve the system. We use the row operations to change coefficients in the lower triangle of the augmented matrix to 0. An augmented matrix of the form \\begin{bmatrix}\n    \\fbox{$a'_{11}$}& a'_{12} & a'_{13}& \\cdots & a'_{1n} & | & b'_1\\\\\n    0 & \\fbox{$a'_{22}$} & a'_{23}& \\cdots & a'_{2n} & | & b'_2\\\\\n    0 & 0 & \\fbox{$a'_{33}$}& \\cdots & a'_{3n} & | & b'_3\\\\\n    0 & 0 &0 & \\ddots & \\vdots  & | & \\vdots \\\\\n    0 & 0 &0 &0 & \\fbox{$a'_{mn}$} & | & b'_m\n    \\end{bmatrix}\nis said to be in row echelon form — each row has more leading zeros than the row preceding it.\nReduced Row Echelon Form: We can go one step further and put the matrix into reduced row echelon form. Reduced row echelon form makes the value of x which solves the system very obvious. For a system of m equations in m unknowns, with no all-zero rows, the reduced row echelon form would be\n\\begin{bmatrix}\n    \\fbox{$1$}  &  0 &   0 &    0  &   0 & | & b^*_1\\\\\n    0  &  \\fbox{$1$} &   0 &    0  &   0 & | & b^*_2\\\\\n    0  &  0 &   \\fbox{$1$} &    0  &   0 & | & b^*_3\\\\\n    0  &  0 &   0 &\\ddots &   0 & | &\\vdots\\\\\n    0  &  0 &   0 &    0  &   \\fbox{$1$} & | & b^*_m\n    \\end{bmatrix}\nGaussian and Gauss-Jordan elimination: We can conduct elementary row operations to get our augmented matrix into row echelon or reduced row echelon form. The methods of transforming a matrix or system into row echelon and reduced row echelon form are referred to as Gaussian elimination and Gauss-Jordan elimination, respectively.\nElementary Row Operations: To do Gaussian and Gauss-Jordan elimination, we use three basic operations to transform the augmented matrix into another augmented matrix that represents an equivalent linear system – equivalent in the sense that the same values of x_j solve both the original and transformed matrix/system:\nInterchanging Rows: Suppose we have the augmented matrix {\\widehat{\\bf A}}=\\begin{bmatrix} a_{11} & a_{12} & | & b_1\\\\\n        a_{21} & a_{22} & | & b_2\n        \\end{bmatrix} If we interchange the two rows, we get the augmented matrix \\begin{bmatrix}\n        a_{21} & a_{22} & | & b_2\\\\\n        a_{11} & a_{12} & | & b_1\n        \\end{bmatrix} which represents a linear system equivalent to that represented by matrix \\widehat{\\bf A}.\nMultiplying by a Constant: If we multiply the second row of matrix \\widehat{\\bf A} by a constant c, we get the augmented matrix \\begin{bmatrix}\n        a_{11} & a_{12} & | & b_1\\\\\n        c a_{21} & c a_{22} & | & c b_2\n        \\end{bmatrix} which represents a linear system equivalent to that represented by matrix \\widehat{\\bf A}.\nAdding (subtracting) Rows: If we add (subtract) the first row of matrix \\widehat{\\bf A} to the second, we obtain the augmented matrix \\begin{bmatrix}\n        a_{11} & a_{12} & | & b_1\\\\\n        a_{11}+a_{21} & a_{12}+a_{22} & | & b_1+b_2\n        \\end{bmatrix} which represents a linear system equivalent to that represented by matrix \\widehat{\\bf A}.\n\nExample 7.6 \nSolve the following system of equations by using elementary row operations: \\begin{matrix}\n    x  & - & 3y & = & -3\\\\\n    2x & + &  y & = &  8\n    \\end{matrix}\n\n\nExercise 7.6 Put the following system of equations into augmented matrix form. Then, using Gaussian or Gauss-Jordan elimination, solve the system of equations by putting the matrix into row echelon or reduced row echelon form.\n\n \\begin{cases}\n    x + y + 2z = 2\\\\\n    3x - 2y + z = 1\\\\\n    y - z = 3\n\\end{cases}\n \\begin{cases}\n    2x + 3y - z = -8\\\\\n    x + 2y - z = 12\\\\\n  -x -4y + z = -6\n\\end{cases}"
  },
  {
    "objectID": "21_linear-algebra.html#rank-of-a-matrix",
    "href": "21_linear-algebra.html#rank-of-a-matrix",
    "title": "7  Linear Algebra",
    "section": "\n7.7 Rank of a Matrix",
    "text": "7.7 Rank of a Matrix\nTo determine how many solutions exist, we can use information about (1) the number of equations m, (2) the number of unknowns n, and (3) the rank of the matrix representing the linear system.\nRank: The maximum number of linearly independent row or column vectors in the matrix. This is equivalent to the number of nonzero rows of a matrix in row echelon form. For any matrix A, the row rank always equals column rank, and we refer to this number as the rank of A.\nFor example \\begin{bmatrix} 1 & 2 & 3 \\\\\n            0 & 4 & 5 \\\\\n            0 & 0 & 6 \\end{bmatrix}\nRank = 3\n\\begin{bmatrix} 1 & 2 & 3 \\\\\n    0 & 4 & 5 \\\\\n    0 & 0 & 0 \\end{bmatrix}\nRank = 2\n\nExercise 7.7 Find the rank of each matrix below:\n(Hint: transform the matrices into row echelon form. Remember that the number of nonzero rows of a matrix in row echelon form is the rank of that matrix)\n\n\\begin{bmatrix} 1 & 1 & 2 \\\\\n  2 & 1 & 3 \\\\\n  1 & 2 & 3 \\end{bmatrix}\n\\begin{bmatrix} 1 & 3 & 3 & -3 & 3\\\\\n1 & 3 & 1 & 1 & 3 \\\\\n1 & 3 & 2 & -1 & -2 \\\\\n1 & 3 & 0 & 3 & -2 \\end{bmatrix}\n\n\nAnswer to Exercise 7.7:\n\nrank is 2\nrank is 3"
  },
  {
    "objectID": "21_linear-algebra.html#the-inverse-of-a-matrix",
    "href": "21_linear-algebra.html#the-inverse-of-a-matrix",
    "title": "7  Linear Algebra",
    "section": "\n7.8 The Inverse of a Matrix",
    "text": "7.8 The Inverse of a Matrix\nIdentity Matrix: The n\\times n identity matrix {\\bf I}_n is the matrix whose diagonal elements are 1 and all off-diagonal elements are 0. Examples:  {\\bf I}_2=\\begin{bmatrix} 1&0\\\\0&1 \\end{bmatrix}, \\qquad {\\bf I}_3=\\begin{bmatrix} 1&0&0\\\\ 0&1&0\\\\\n            0&0&1 \\end{bmatrix}\nInverse Matrix: An n\\times n matrix {\\bf A} is nonsingular or invertible if there exists an n\\times n matrix {\\bf A}^{-1} such that {\\bf A} {\\bf A}^{-1} = {\\bf A}^{-1} {\\bf A} = {\\bf I}_n where {\\bf A}^{-1} is the inverse of {\\bf A}. If there is no such {\\bf A}^{-1}, then {\\bf A} is singular or not invertible.\nExample: Let {\\bf A} = \\begin{bmatrix} 2&3\\\\2&2 \\end{bmatrix}, \\qquad {\\bf B}=\\begin{bmatrix} -1&\\frac{3}{2}\\\\ 1&-1\n        \\end{bmatrix} Since {\\bf A} {\\bf B} = {\\bf B} {\\bf A} = {\\bf I}_n we conclude that {\\bf B} is the inverse, {\\bf A}^{-1}, of {\\bf A} and that {\\bf A} is nonsingular.\nProperties of the Inverse:\n\nIf the inverse exists, it is unique.\nIf {\\bf A} is nonsingular, then {\\bf A}^{-1} is nonsingular.\n({\\bf A}^{-1})^{-1} = {\\bf A}\nIf {\\bf A} and {\\bf B} are nonsingular, then {\\bf A}{\\bf B} is nonsingular\n({\\bf A}{\\bf B})^{-1} = {\\bf B}^{-1}{\\bf A}^{-1}\nIf {\\bf A} is nonsingular, then ({\\bf A}^\\top)^{-1}=({\\bf A}^{-1})^\\top\n\nProcedure to Find {\\bf A}^{-1}: We know that if {\\bf B} is the inverse of {\\bf A}, then {\\bf A} {\\bf B} = {\\bf B} {\\bf A} = {\\bf I}_n Looking only at the first and last parts of this {\\bf A} {\\bf B} = {\\bf I}_n Solving for {\\bf B} is equivalent to solving for n linear systems, where each column of {\\bf B} is solved for the corresponding column in {\\bf I}_n. We can solve the systems simultaneously by augmenting {\\bf A} with {\\bf I}_n and performing Gauss-Jordan elimination on {\\bf A}. If Gauss-Jordan elimination on [{\\bf A} | {\\bf I}_n] results in [{\\bf I}_n | {\\bf B} ], then {\\bf B} is the inverse of {\\bf A}. Otherwise, {\\bf A} is singular.\nTo summarize: To calculate the inverse of {\\bf A}\n\nForm the augmented matrix [ {\\bf A} | {\\bf I}_n]\nUsing elementary row operations, transform the augmented matrix to reduced row echelon form.\n\nThe result of step 2 is an augmented matrix [ {\\bf C} | {\\bf B} ].\n\nIf {\\bf C}={\\bf I}_n, then {\\bf B}={\\bf A}^{-1}.\nIf {\\bf C}\\ne{\\bf I}_n, then \\bf C has a row of zeros. This means {\\bf A} is singular and {\\bf A}^{-1} does not exist.\n\n\n\n\nExample 7.7 Find the inverse of the following matrix:\n{\\bf A}=\\begin{bmatrix} 1&1&1\\\\0&2&3\\\\5&5&1 \\end{bmatrix}\n\n\nExercise 7.8 Find the inverse of the following matrix:\n{\\bf A}=\\begin{bmatrix} 1&0&4\\\\0&2&0\\\\0&0&1 \\end{bmatrix}"
  },
  {
    "objectID": "21_linear-algebra.html#linear-systems-and-inverses",
    "href": "21_linear-algebra.html#linear-systems-and-inverses",
    "title": "7  Linear Algebra",
    "section": "\n7.9 Linear Systems and Inverses",
    "text": "7.9 Linear Systems and Inverses\nLet’s return to the matrix representation of a linear system\n\\bf{Ax} = \\bf{b}\nIf \\bf{A} is an n\\times n matrix,then \\bf{Ax}=\\bf{b} is a system of n equations in n unknowns. Suppose \\bf{A} is nonsingular. Then \\bf{A}^{-1} exists. To solve this system, we can multiply each side by \\bf{A}^{-1} and reduce it as follows:\n\\begin{align*} \\bf{A}^{-1} (\\bf{A} \\bf{x}) & =  \\bf{A}^{-1} \\bf{b} \\\\ (\\bf{A}^{-1} \\bf{A})\\bf{x} & =  \\bf{A}^{-1} \\bf{b}\\\\ \\bf{I}_n \\bf{x}     & =  \\bf{A}^{-1} \\bf{b}\\\\ \\bf{x} & =  \\bf{A}^{-1} \\bf{b} \\end{align*} \nHence, given \\bf{A} and \\bf{b} and given that \\bf{A} is nonsingular, then \\bf{x} = \\bf{A}^{-1} \\bf{b} is a unique solution to this system.\n\nExercise 7.9 Use the inverse matrix to solve the following linear system:\n \\begin{align*}\n  -3x + 4y &= 5 \\\\\n  2x - y &= -10\n  \\end{align*} \nHint: the linear system above can be written in the matrix form\n\\textbf{A}\\textbf{z} = \\textbf{b}\ngiven\n\\textbf{A} = \\begin{bmatrix} -3&4\\\\2&-1 \\end{bmatrix},\n\\textbf{z} = \\begin{bmatrix} x\\\\y \\end{bmatrix},\nand\n\\textbf{b} = \\begin{bmatrix} 5\\\\-10 \\end{bmatrix}"
  },
  {
    "objectID": "21_linear-algebra.html#determinants",
    "href": "21_linear-algebra.html#determinants",
    "title": "7  Linear Algebra",
    "section": "\n7.10 Determinants",
    "text": "7.10 Determinants\nSingularity: Determinants can be used to determine whether a square matrix is nonsingular.\nA square matrix is nonsingular if and only if its determinant is not zero.\nDeterminant of a 1 \\times 1 matrix, equals |\\mathbf{A}|=|a_{11}|=a_{11}\nDeterminant of a 2 \\times 2 matrix,\n\\mathbf{A}=\\begin{vmatrix} a_{11}&a_{12}\\\\ a_{21}&a_{22} \\end{vmatrix}\n\\begin{align*}\\det({\\bf A}) &= |{\\bf A}|\\\\\n            &= a_{11}|a_{22}| - a_{12}|a_{21}|\\\\\n            &= a_{11}a_{22} - a_{12}a_{21}\n  \\end{align*}\nWe can extend the second to last equation above to get the definition of the determinant of a 3 \\times 3 matrix: \\begin{align*}\n            \\begin{vmatrix} a_{11}&a_{12}&a_{13}\\\\  a_{21} & a_{22}&a_{23}\\\\ a_{31}&a_{32}&a_{33} \\end{vmatrix}\n                &=\n                a_{11} \\begin{vmatrix} a_{22}&a_{23}\\\\ a_{32}&a_{33} \\end{vmatrix}\n                - a_{12} \\begin{vmatrix} a_{21}&a_{23}\\\\ a_{31}&a_{33} \\end{vmatrix}\n                + a_{13} \\begin{vmatrix} a_{21}&a_{22}\\\\ a_{31}&a_{32}\n                \\end{vmatrix}\\\\\n                &= a_{11}(a_{22}a_{33} - a_{23}a_{32}) - a_{12}(a_{21}a_{33} - a_{23}a_{31}) + a_{13}(a_{21}a_{32} - a_{22}a_{31})\n  \\end{align*} \nLet’s extend this now to any n\\times n matrix. Let’s define \\mathbf{A}_{ij} as the (n-1)\\times (n-1) submatrix of \\mathbf{A} obtained by deleting row i and column j. Let the (i,j)th minor of \\mathbf{A} be the determinant of \\mathbf{A}_{ij}:\nM_{ij} = \\left|\\mathbf{A}_{ij}\\right|\nThen for any n\\times n matrix \\mathbf{A}\n|\\mathbf{A}| = a_{11}M_{11} - a_{12}M_{12} + \\cdots + (-1)^{n+1} a_{1n} M_{1n}\nFor example, in figuring out whether the following matrix has an inverse?\n\\mathbf{A}=\\begin{bmatrix} 1&1&1\\\\0&2&3\\\\5&5&1 \\end{bmatrix}\n\nCalculate its determinant. \\begin{align*}\n|\\mathbf{A}| &= 1(2-15) - 1(0-15) + 1(0-10) \\nonumber\\\\\n&= -13+15-10 \\nonumber\\\\\n&= -8\\nonumber\n\\end{align*}\nSince |{\\bf A}|\\ne 0, we conclude that {\\bf A} has an inverse.\n\n\nExercise 7.10 Determine whether the following matrices are nonsingular:\n\n\\begin{bmatrix}\n  1 & 0 & 1\\\\\n  2 & 1 & 2\\\\\n  1 & 0 & -1\n  \\end{bmatrix}\n\\begin{bmatrix}\n     2 & 1 & 2\\\\\n     1 & 0 & 1\\\\\n     4 & 1 & 4\n\\end{bmatrix}"
  },
  {
    "objectID": "21_linear-algebra.html#getting-inverse-of-a-matrix-using-its-determinant",
    "href": "21_linear-algebra.html#getting-inverse-of-a-matrix-using-its-determinant",
    "title": "7  Linear Algebra",
    "section": "\n7.11 Getting Inverse of a Matrix using its Determinant",
    "text": "7.11 Getting Inverse of a Matrix using its Determinant\nThus far, we have a number of algorithms to\n\nFind the solution of a linear system,\nFind the inverse of a matrix\n\nbut these remain just that — algorithms. At this point, we have no way of telling how the solutions x_j change as the parameters a_{ij} and b_i change, except by changing the values and “rerunning” the algorithms.\nWith determinants, we can provide an explicit formula for the inverse and therefore provide an explicit formula for the solution of an n\\times n linear system.\nHence, we can examine how changes in the parameters and b_i affect the solutions x_j.\nDeterminant Formula for the Inverse of a 2 \\times 2:\nThe determinant of a 2 \\times 2 matrix \\mathbf{A}=\\begin{bmatrix} a & b\\\\ c & d\\\\ \\end{bmatrix} is defined as: \\frac{1}{\\det({\\bf A})} \\begin{bmatrix}\n            d & -b\\\\\n            -c & a\\\\\n        \\end{bmatrix}\nFor example, Let’s calculate the inverse of matrix A from Exercise 7.9 using the determinant formula.\nRecall,\n\\mathbf{A} = \\begin{bmatrix}\n            -3 & 4\\\\\n            2 & -1\\\\\n        \\end{bmatrix}\n\\det(\\mathbf{A}) = (-3)(-1) - (4)(2) = 3 - 8  = -5\n\\frac{1}{\\det(\\mathbf{A})} \\begin{bmatrix}\n            -1 & -4\\\\\n            -2 & -3\\\\\n        \\end{bmatrix}\n\\frac{1}{-5} \\begin{bmatrix}\n            -1 & -4\\\\\n            -2 & -3\\\\\n        \\end{bmatrix}\n\\begin{bmatrix}\n            \\frac{1}{5} & \\frac{4}{5}\\\\\n            \\frac{2}{5} & \\frac{3}{5}\\\\\n        \\end{bmatrix}\n\nExercise 7.11 \nCaculate the inverse of \\mathbf{A} \\mathbf{A} = \\begin{bmatrix}\n            3 & 5\\\\\n            -7 & 2\\\\\n        \\end{bmatrix}"
  },
  {
    "objectID": "21_linear-algebra.html#answers-to-examples-and-exercises",
    "href": "21_linear-algebra.html#answers-to-examples-and-exercises",
    "title": "7  Linear Algebra",
    "section": "Answers to Examples and Exercises",
    "text": "Answers to Examples and Exercises\nAnswer to Example 7.1:\n\n\\begin{bmatrix} -1 &-3&-3 \\end{bmatrix}\n6 + 4 + 10 = 20\n\nAnswer to Exercise 7.1:\n\n\\begin{bmatrix} -2 &4&-7&-5 \\end{bmatrix}\n\\begin{bmatrix} 2 &26&-14&4&30 \\end{bmatrix}\n63 -3 -10 + 24 = 74\nundefined\n\nAnswer to Example 7.2:\n\nyes\nno\n\nAnswer to Exercise 7.2:\n\nyes\nno (-v_1 -v_2 + v_3 = 0)\n\nAnswer to Example 7.3:\n{\\bf A+B}=\\begin{bmatrix} 2 & 4 & 4 \\\\ 6 & 6 & 8 \\end{bmatrix}\nAnswer to Example 7.4:\ns {\\bf A} = \\begin{bmatrix} 2 & 4 & 6 \\\\ 8 & 10 & 12 \\end{bmatrix}\nAnswer to Example 7.5:\n\n\\begin{bmatrix} aA+bC&aB+bD\\\\cA+dC&cB+dD\\\\eA+fC&eB+fD \\end{bmatrix}\n\\begin{bmatrix} 1(-2)+2(4)-1(2)&1(5)+2(-3)-1(1)\\\\  3(-2)+1(4)+4(2)&3(5)+1(-3)+4(1)\\end{bmatrix} =  \\begin{bmatrix} 4&-2\\\\6&16\\end{bmatrix}\n\nAnswer to Exercise 7.3:\n\nAB = \\begin{bmatrix} 4 & 11 & -15 \\\\ 5 & 7 & -7 \\end{bmatrix}\nBA = undefined\n(BC)^\\top = undefined\nBC^\\top = \\begin{bmatrix} 1&5&-7\\\\1&1&0\\\\0&-1&1\\\\2&0&0\\end{bmatrix}\\begin{bmatrix} 3&0\\\\2&4\\\\-1&6 \\end{bmatrix} =\\begin{bmatrix}20 & -22 \\\\ 5 & 4 \\\\ -3 &2 \\\\6 & 0\\end{bmatrix}\n\nAnswer to Exercise 7.4:\nThere are many answers to this. Some possible simple ones are as follows:\n\nOne solution: \\begin{matrix}\n         -x  & + & y & = & 0\\\\\n         x & + &  y & = &  2\n         \\end{matrix}\nNo solution: \\begin{matrix}\n         -x  & + & y & = & 0\\\\\n         x & - &  y & = &  2\n         \\end{matrix}\nInfinite solutions: \\begin{matrix}\n         -x  & + & y & = & 0\\\\\n         2x & - &  2y & = &  0\n         \\end{matrix}\n\nAnswer to Exercise 7.5:\n\\begin{bmatrix}  2 & -7 & 9 & -4 & 0 & 0| & 8\\\\  0 & 41 & 9 & 0 & 0 & 5 | & 11\\\\  1 & -15 & 0 & 0 & -11 & 0 | & 9  \\end{bmatrix}\nAnswer to Example 7.6:\n\\begin{matrix}\n    x  & - & 3y & = & -3\\\\\n    2x & + &  y & = &  8\n    \\end{matrix}\n\\begin{matrix}\n    x  & - & 3y & = & -3\\\\\n       &   & 7y & = & 14\\\\          \n    \\end{matrix}\n\\begin{matrix}\n    x  & - & 3y & = & -3\\\\\n       &   & y & = & 2\\\\            \n    \\end{matrix}\n\\begin{matrix}\n    x & = & 3\\\\\n    y & = & 2\\\\         \n    \\end{matrix}\nAnswer to Exercise 7.6:\n\nx = 2, y = 2, z = -1\nx = -17, y = -3, z = -35\n\nAnswer to Exercise 7.7:\n\nrank is 2\nrank is 3\n\nAnswer to Example 7.7:\n\\left(\\begin{array}{ccc|ccc}  1&1&1&1&0&0\\\\  0&2&3&0&1&0\\\\  5&5&1&0&0&1 \\end{array} \\right)\n\\left(\\begin{array}{ccc|ccc}  1&1&1 &1 &0&0\\\\  0&2&3 &0 &1&0\\\\  0&0&-4&-5&0&1 \\end{array} \\right)\n\\left(\\begin{array}{ccc|ccc}  1&1&1&1 &0&0\\\\  0&2&3&0 &1&0\\\\  0&0&1&5/4&0&-1/4 \\end{array} \\right)\n\\left(\\begin{array}{ccc|ccc}  1&1&0&-1/4 &0&1/4\\\\  0&2&0&-15/4&1&3/4\\\\  0&0&1&5/4 &0&-1/4 \\end{array} \\right)\n\\left(\\begin{array}{ccc|ccc}  1&1&0&-1/4 &0 &1/4\\\\  0&1&0&-15/8&1/2&3/8\\\\  0&0&1&5/4 &0 &-1/4 \\end{array} \\right)\n\\left(\\begin{array}{ccc|ccc}  1&0&0&13/8 &-1/2&-1/8\\\\  0&1&0&-15/8&1/2 &3/8\\\\  0&0&1&5/4 &0 &-1/4 \\end{array} \\right)\n{\\bf A}^{-1} = \\left(\\begin{array}{ccc}  13/8 &-1/2&-1/8\\\\  -15/8&1/2 &3/8\\\\  5/4 &0 &-1/4 \\end{array} \\right)\nAnswer to Exercise 7.8:\n\n{\\bf A}^{-1}=\\begin{bmatrix} 1&0&-4\\\\0&\\frac{1}{2}&0\\\\0&0&1 \\end{bmatrix}\n\nAnswer to Exercise 7.9:\n\\textbf{z} = \\bf{A}^{-1} \\bf{b} = \\begin{bmatrix}  1/5 &4/5\\\\  2/5&3/5 \\end{bmatrix} \\begin{bmatrix}  5 \\\\  -10 \\end{bmatrix}= \\begin{bmatrix}  -7 \\\\  -4 \\end{bmatrix} = \\begin{bmatrix}  x \\\\  y \\end{bmatrix}\nAnswer to Exercise 7.10:\n\nnonsingular\nsingular\n\nAnswer to Exercise 7.11:\n\\begin{bmatrix}  \\frac{2}{41} & \\frac{-5}{41}\\\\  \\frac{7}{41} & \\frac{3}{41}\\\\  \\end{bmatrix}"
  },
  {
    "objectID": "22_matrices.html",
    "href": "22_matrices.html",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "",
    "text": "Nunn and Wantchekon (2011) – “The Slave Trade and the Origins of Mistrust in Africa”1 – argues that across African countries, the distrust of co-ethnics fueled by the slave trade has had long-lasting effects on modern day trust in these territories. They argued that the slave trade created distrust in these societies in part because as some African groups were employed by European traders to capture their neighbors and bring them to the slave ships.\nNunn and Wantchekon use a variety of statistical tools to make their case (adding controls, ordered logit, instrumental variables, falsification tests, causal mechanisms), many of which will be covered in future courses. In this module we will only touch on their first set of analysis that use Ordinary Least Squares (OLS). OLS is likely the most common application of linear algebra in the social sciences. We will cover some linear algebra, matrix manipulation, and vector manipulation from this data."
  },
  {
    "objectID": "22_matrices.html#read-data",
    "href": "22_matrices.html#read-data",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.1 Read Data",
    "text": "8.1 Read Data\n\nlibrary(haven)\nnunn_full <- read_dta(\"data/input/Nunn_Wantchekon_AER_2011.dta\")\n\nNunn and Wantchekon’s main dataset has more than 20,000 observations. Each observation is a respondent from the Afrobarometer survey.\n\nhead(nunn_full)\n\n# A tibble: 6 × 59\n  respno  ethni…¹ murdo…² isocode region distr…³ townv…⁴ locat…⁵ trust…⁶ trust…⁷\n  <chr>   <chr>   <chr>   <chr>   <chr>  <chr>   <chr>     <dbl>   <dbl>   <dbl>\n1 BEN0001 fon     FON     BEN     atlna… KPOMAS… TOKPA-…      30       3       3\n2 BEN0002 fon     FON     BEN     atlna… KPOMAS… TOKPA-…      30       3       3\n3 BEN0003 fon     FON     BEN     atlna… OUIDAH  3ARROND      31       0       0\n4 BEN0004 fon     FON     BEN     atlna… OUIDAH  3ARROND      31       0       0\n5 BEN0005 fon     FON     BEN     atlna… OUIDAH  PAHOU        32       1       1\n6 BEN0006 fon     FON     BEN     atlna… OUIDAH  PAHOU        32       1       1\n# … with 49 more variables: intra_group_trust <dbl>, inter_group_trust <dbl>,\n#   trust_local_council <dbl>, ln_export_area <dbl>, export_area <dbl>,\n#   export_pop <dbl>, ln_export_pop <dbl>, age <dbl>, age2 <dbl>, male <dbl>,\n#   urban_dum <dbl>, occupation <dbl>, religion <dbl>, living_conditions <dbl>,\n#   education <dbl>, near_dist <dbl>, distsea <dbl>, loc_murdock_name <chr>,\n#   loc_ln_export_area <dbl>, local_council_performance <dbl>,\n#   council_listen <dbl>, corrupt_local_council <dbl>, school_present <dbl>, …\n# ℹ Use `colnames()` to see all variable names\n\ncolnames(nunn_full)\n\n [1] \"respno\"                          \"ethnicity\"                      \n [3] \"murdock_name\"                    \"isocode\"                        \n [5] \"region\"                          \"district\"                       \n [7] \"townvill\"                        \"location_id\"                    \n [9] \"trust_relatives\"                 \"trust_neighbors\"                \n[11] \"intra_group_trust\"               \"inter_group_trust\"              \n[13] \"trust_local_council\"             \"ln_export_area\"                 \n[15] \"export_area\"                     \"export_pop\"                     \n[17] \"ln_export_pop\"                   \"age\"                            \n[19] \"age2\"                            \"male\"                           \n[21] \"urban_dum\"                       \"occupation\"                     \n[23] \"religion\"                        \"living_conditions\"              \n[25] \"education\"                       \"near_dist\"                      \n[27] \"distsea\"                         \"loc_murdock_name\"               \n[29] \"loc_ln_export_area\"              \"local_council_performance\"      \n[31] \"council_listen\"                  \"corrupt_local_council\"          \n[33] \"school_present\"                  \"electricity_present\"            \n[35] \"piped_water_present\"             \"sewage_present\"                 \n[37] \"health_clinic_present\"           \"district_ethnic_frac\"           \n[39] \"frac_ethnicity_in_district\"      \"townvill_nonethnic_mean_exports\"\n[41] \"district_nonethnic_mean_exports\" \"region_nonethnic_mean_exports\"  \n[43] \"country_nonethnic_mean_exports\"  \"murdock_centr_dist_coast\"       \n[45] \"centroid_lat\"                    \"centroid_long\"                  \n[47] \"explorer_contact\"                \"railway_contact\"                \n[49] \"dist_Saharan_node\"               \"dist_Saharan_line\"              \n[51] \"malaria_ecology\"                 \"v30\"                            \n[53] \"v33\"                             \"fishing\"                        \n[55] \"exports\"                         \"ln_exports\"                     \n[57] \"total_missions_area\"             \"ln_init_pop_density\"            \n[59] \"cities_1400_dum\"                \n\n\nFirst, let’s consider a small subset of this dataset.\n\nnunn <- read_dta(\"data/input/Nunn_Wantchekon_sample.dta\")\n\n\nnunn\n\n# A tibble: 10 × 5\n   trust_neighbors exports ln_exports export_area ln_export_area\n             <dbl>   <dbl>      <dbl>       <dbl>          <dbl>\n 1               3   0.388      0.328     0.00407        0.00406\n 2               3   0.631      0.489     0.0971         0.0926 \n 3               3   0.994      0.690     0.0125         0.0124 \n 4               0 183.         5.21      1.82           1.04   \n 5               3   0          0         0              0      \n 6               2   0          0         0              0      \n 7               2 666.         6.50     14.0            2.71   \n 8               0   0.348      0.298     0.00608        0.00606\n 9               3   0.435      0.361     0.0383         0.0376 \n10               3   0          0         0              0"
  },
  {
    "objectID": "22_matrices.html#data.frame-vs.-matricies",
    "href": "22_matrices.html#data.frame-vs.-matricies",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.2 data.frame vs. matricies",
    "text": "8.2 data.frame vs. matricies\nThis is a data.frame object.\n\nclass(nunn)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nBut it can be also consider a matrix in the linear algebra sense. What are the dimensions of this matrix?\n\nnrow(nunn)\n\n[1] 10\n\n\ndata.frames and matrices have much overlap in R, but to explicitly treat an object as a matrix, you’d need to coerce its class. Let’s call this matrix X.\n\nX <- as.matrix(nunn)\n\nWhat is the difference between a data.frame and a matrix? A data.frame can have columns that are of different types, whereas — in a matrix — all columns must be of the same type (usually either “numeric” or “character”).\nYou can think of data frames maybe as matrices-plus, because a column can take on characters as well as numbers. As we just saw, this is often useful for real data analyses.\nAnother way to think about data frames is that it is a type of list. Try the str() code below and notice how it is organized in slots. Each slot is a vector. They can be vectors of numbers or characters.\n\n# enter this on your console\nstr(cen10)"
  },
  {
    "objectID": "22_matrices.html#handling-matricies-in-r",
    "href": "22_matrices.html#handling-matricies-in-r",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.3 Handling matricies in R\n",
    "text": "8.3 Handling matricies in R\n\nYou can easily transpose a matrix\n\nX\n\n      trust_neighbors     exports ln_exports  export_area ln_export_area\n [1,]               3   0.3883497  0.3281158  0.004067405    0.004059155\n [2,]               3   0.6311236  0.4892691  0.097059444    0.092633367\n [3,]               3   0.9941893  0.6902376  0.012524694    0.012446908\n [4,]               0 182.5891266  5.2127004  1.824284434    1.038255095\n [5,]               3   0.0000000  0.0000000  0.000000000    0.000000000\n [6,]               2   0.0000000  0.0000000  0.000000000    0.000000000\n [7,]               2 665.9652100  6.5027380 13.975566864    2.706419945\n [8,]               0   0.3476418  0.2983562  0.006082553    0.006064130\n [9,]               3   0.4349871  0.3611559  0.038332380    0.037615947\n[10,]               3   0.0000000  0.0000000  0.000000000    0.000000000\n\nt(X)\n\n                       [,1]       [,2]       [,3]       [,4] [,5] [,6]\ntrust_neighbors 3.000000000 3.00000000 3.00000000   0.000000    3    2\nexports         0.388349682 0.63112360 0.99418926 182.589127    0    0\nln_exports      0.328115761 0.48926911 0.69023758   5.212700    0    0\nexport_area     0.004067405 0.09705944 0.01252469   1.824284    0    0\nln_export_area  0.004059155 0.09263337 0.01244691   1.038255    0    0\n                      [,7]        [,8]       [,9] [,10]\ntrust_neighbors   2.000000 0.000000000 3.00000000     3\nexports         665.965210 0.347641766 0.43498713     0\nln_exports        6.502738 0.298356235 0.36115587     0\nexport_area      13.975567 0.006082553 0.03833238     0\nln_export_area    2.706420 0.006064130 0.03761595     0\n\n\nWhat are the values of all rows in the first column?\n\nX[, 1]\n\n [1] 3 3 3 0 3 2 2 0 3 3\n\n\nWhat are all the values of “exports”? (i.e. return the whole “exports” column)\n\nX[, \"exports\"]\n\n [1]   0.3883497   0.6311236   0.9941893 182.5891266   0.0000000   0.0000000\n [7] 665.9652100   0.3476418   0.4349871   0.0000000\n\n\nWhat is the first observation (i.e. first row)?\n\nX[1, ]\n\ntrust_neighbors         exports      ln_exports     export_area  ln_export_area \n    3.000000000     0.388349682     0.328115761     0.004067405     0.004059155 \n\n\nWhat is the value of the first variable of the first observation?\n\nX[1, 1]\n\ntrust_neighbors \n              3 \n\n\nPause and consider the following problem on your own. What is the following code doing?\n\nX[X[, \"trust_neighbors\"] == 0, \"export_area\"]\n\n[1] 1.824284434 0.006082553\n\n\nWhy does it give the same output as the following?\n\nX[which(X[, \"trust_neighbors\"] == 0), \"export_area\"]\n\n[1] 1.824284434 0.006082553\n\n\nSome more manipulation\n\nX + X\n\n      trust_neighbors      exports ln_exports  export_area ln_export_area\n [1,]               6    0.7766994  0.6562315  0.008134809     0.00811831\n [2,]               6    1.2622472  0.9785382  0.194118887     0.18526673\n [3,]               6    1.9883785  1.3804752  0.025049388     0.02489382\n [4,]               0  365.1782532 10.4254007  3.648568869     2.07651019\n [5,]               6    0.0000000  0.0000000  0.000000000     0.00000000\n [6,]               4    0.0000000  0.0000000  0.000000000     0.00000000\n [7,]               4 1331.9304199 13.0054760 27.951133728     5.41283989\n [8,]               0    0.6952835  0.5967125  0.012165107     0.01212826\n [9,]               6    0.8699743  0.7223117  0.076664761     0.07523189\n[10,]               6    0.0000000  0.0000000  0.000000000     0.00000000\n\n\n\nX - X\n\n      trust_neighbors exports ln_exports export_area ln_export_area\n [1,]               0       0          0           0              0\n [2,]               0       0          0           0              0\n [3,]               0       0          0           0              0\n [4,]               0       0          0           0              0\n [5,]               0       0          0           0              0\n [6,]               0       0          0           0              0\n [7,]               0       0          0           0              0\n [8,]               0       0          0           0              0\n [9,]               0       0          0           0              0\n[10,]               0       0          0           0              0\n\n\n\nt(X) %*% X\n\n                trust_neighbors    exports ln_exports export_area\ntrust_neighbors       62.000000   1339.276   18.61181    28.40709\nexports             1339.276369 476850.298 5283.76294  9640.42990\nln_exports            18.611811   5283.763   70.50077   100.46202\nexport_area           28.407085   9640.430  100.46202   198.65558\nln_export_area         5.853106   1992.047   23.08189    39.72847\n                ln_export_area\ntrust_neighbors       5.853106\nexports            1992.046502\nln_exports           23.081893\nexport_area          39.728468\nln_export_area        8.412887\n\n\n\ncbind(X, 1:10)\n\n      trust_neighbors     exports ln_exports  export_area ln_export_area   \n [1,]               3   0.3883497  0.3281158  0.004067405    0.004059155  1\n [2,]               3   0.6311236  0.4892691  0.097059444    0.092633367  2\n [3,]               3   0.9941893  0.6902376  0.012524694    0.012446908  3\n [4,]               0 182.5891266  5.2127004  1.824284434    1.038255095  4\n [5,]               3   0.0000000  0.0000000  0.000000000    0.000000000  5\n [6,]               2   0.0000000  0.0000000  0.000000000    0.000000000  6\n [7,]               2 665.9652100  6.5027380 13.975566864    2.706419945  7\n [8,]               0   0.3476418  0.2983562  0.006082553    0.006064130  8\n [9,]               3   0.4349871  0.3611559  0.038332380    0.037615947  9\n[10,]               3   0.0000000  0.0000000  0.000000000    0.000000000 10\n\n\n\ncbind(X, 1)\n\n      trust_neighbors     exports ln_exports  export_area ln_export_area  \n [1,]               3   0.3883497  0.3281158  0.004067405    0.004059155 1\n [2,]               3   0.6311236  0.4892691  0.097059444    0.092633367 1\n [3,]               3   0.9941893  0.6902376  0.012524694    0.012446908 1\n [4,]               0 182.5891266  5.2127004  1.824284434    1.038255095 1\n [5,]               3   0.0000000  0.0000000  0.000000000    0.000000000 1\n [6,]               2   0.0000000  0.0000000  0.000000000    0.000000000 1\n [7,]               2 665.9652100  6.5027380 13.975566864    2.706419945 1\n [8,]               0   0.3476418  0.2983562  0.006082553    0.006064130 1\n [9,]               3   0.4349871  0.3611559  0.038332380    0.037615947 1\n[10,]               3   0.0000000  0.0000000  0.000000000    0.000000000 1\n\n\n\ncolnames(X)\n\n[1] \"trust_neighbors\" \"exports\"         \"ln_exports\"      \"export_area\"    \n[5] \"ln_export_area\""
  },
  {
    "objectID": "22_matrices.html#variable-transformations",
    "href": "22_matrices.html#variable-transformations",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.4 Variable Transformations",
    "text": "8.4 Variable Transformations\nexports is the total number of slaves that were taken from the individual’s ethnic group between Africa’s four slave trades between 1400-1900.\nWhat is ln_exports? The article describes this as the natural log of one plus the exports. This is a transformation of one column by a particular function\n\nlog(1 + X[, \"exports\"])\n\n [1] 0.3281158 0.4892691 0.6902376 5.2127003 0.0000000 0.0000000 6.5027379\n [8] 0.2983562 0.3611559 0.0000000\n\n\nQuestion for you: why add the 1?\nVerify that this is the same as X[, \"ln_exports\"]"
  },
  {
    "objectID": "22_matrices.html#linear-combinations",
    "href": "22_matrices.html#linear-combinations",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.5 Linear Combinations",
    "text": "8.5 Linear Combinations\nIn Table 1 we see “OLS Estimates”. These are estimates of OLS coefficients and standard errors. You do not need to know what these are for now, but it doesn’t hurt to getting used to seeing them.\n\nA very crude way to describe regression is through linear combinations. The simplest linear combination is a one-to-one transformation.\nTake the first number in Table 1, which is -0.00068. Now, multiply this by exports\n\n-0.00068 * X[, \"exports\"]\n\n [1] -0.0002640778 -0.0004291640 -0.0006760487 -0.1241606061  0.0000000000\n [6]  0.0000000000 -0.4528563428 -0.0002363964 -0.0002957912  0.0000000000\n\n\nNow, just one more step. Make a new matrix with just exports and the value 1\n\nX2 <- cbind(1, X[, \"exports\"])\n\nname this new column “intercept”\n\ncolnames(X2)\n\nNULL\n\n\n\ncolnames(X2) <- c(\"intercept\", \"exports\")\n\nWhat are the dimensions of the matrix X2?\n\ndim(X2)\n\n[1] 10  2\n\n\nNow consider a new matrix, called B.\n\nB <- matrix(c(1.62, -0.00068))\n\nWhat are the dimensions of B?\n\ndim(B)\n\n[1] 2 1\n\n\nWhat is the product of X2 and B? From the dimensions, can you tell if it will be conformable?\n\nX2 %*% B\n\n          [,1]\n [1,] 1.619736\n [2,] 1.619571\n [3,] 1.619324\n [4,] 1.495839\n [5,] 1.620000\n [6,] 1.620000\n [7,] 1.167144\n [8,] 1.619764\n [9,] 1.619704\n[10,] 1.620000\n\n\nWhat is this multiplication doing in terms of equations?"
  },
  {
    "objectID": "22_matrices.html#matrix-basics",
    "href": "22_matrices.html#matrix-basics",
    "title": "8  Manipulating Vectors and Matrices",
    "section": "\n8.6 Matrix Basics",
    "text": "8.6 Matrix Basics\nLet’s take a look at Matrices in the context of R\n\ncen10 <- read_csv(\"data/input/usc2010_001percent.csv\")\nhead(cen10)\n\n# A tibble: 6 × 4\n  state         sex      age race       \n  <chr>         <chr>  <dbl> <chr>      \n1 New York      Female     8 White      \n2 Ohio          Male      24 White      \n3 Nevada        Male      37 White      \n4 Michigan      Female    12 White      \n5 Maryland      Female    18 Black/Negro\n6 New Hampshire Male      50 White      \n\n\nWhat is the dimension of this dataframe? What does the number of rows represent? What does the number of columns represent?\n\ndim(cen10)\n\n[1] 30871     4\n\nnrow(cen10)\n\n[1] 30871\n\nncol(cen10)\n\n[1] 4\n\n\nWhat variables does this dataset hold? What kind of information does it have?\n\ncolnames(cen10)\n\n[1] \"state\" \"sex\"   \"age\"   \"race\" \n\n\nWe can access column vectors, or vectors that contain values of variables by using the $ sign\n\nhead(cen10$state)\n\n[1] \"New York\"      \"Ohio\"          \"Nevada\"        \"Michigan\"     \n[5] \"Maryland\"      \"New Hampshire\"\n\nhead(cen10$race)\n\n[1] \"White\"       \"White\"       \"White\"       \"White\"       \"Black/Negro\"\n[6] \"White\"      \n\n\nWe can look at a unique set of variable values by calling the unique function\n\nunique(cen10$state)\n\n [1] \"New York\"             \"Ohio\"                 \"Nevada\"              \n [4] \"Michigan\"             \"Maryland\"             \"New Hampshire\"       \n [7] \"Iowa\"                 \"Missouri\"             \"New Jersey\"          \n[10] \"California\"           \"Texas\"                \"Pennsylvania\"        \n[13] \"Washington\"           \"West Virginia\"        \"Idaho\"               \n[16] \"North Carolina\"       \"Massachusetts\"        \"Connecticut\"         \n[19] \"Arkansas\"             \"Indiana\"              \"Wisconsin\"           \n[22] \"Maine\"                \"Tennessee\"            \"Minnesota\"           \n[25] \"Florida\"              \"Oklahoma\"             \"Montana\"             \n[28] \"Georgia\"              \"Arizona\"              \"Colorado\"            \n[31] \"Virginia\"             \"Illinois\"             \"Oregon\"              \n[34] \"Kentucky\"             \"South Carolina\"       \"Kansas\"              \n[37] \"Louisiana\"            \"Alabama\"              \"District of Columbia\"\n[40] \"Mississippi\"          \"Utah\"                 \"Delaware\"            \n[43] \"Nebraska\"             \"Alaska\"               \"New Mexico\"          \n[46] \"South Dakota\"         \"Hawaii\"               \"Vermont\"             \n[49] \"Rhode Island\"         \"Wyoming\"              \"North Dakota\"        \n\n\nHow many different states are represented (this dataset includes DC as a state)?\n\nlength(unique(cen10$state))\n\n[1] 51\n\n\nMatrices are rectangular structures of numbers (they have to be numbers, and they can’t be characters).\nA cross-tab can be considered a matrix:\n\ntable(cen10$race, cen10$sex)\n\n                                  \n                                   Female  Male\n  American Indian or Alaska Native    142   153\n  Black/Negro                        2070  1943\n  Chinese                             192   162\n  Japanese                             51    26\n  Other Asian or Pacific Islander     587   542\n  Other race, nec                     877   962\n  Three or more major races            37    51\n  Two major races                     443   426\n  White                             11252 10955\n\n\n\ncross_tab <- table(cen10$race, cen10$sex)\ndim(cross_tab)\n\n[1] 9 2\n\ncross_tab[6, 2]\n\n[1] 962\n\n\nBut a subset of your data – individual values– can be considered a matrix too.\n\n# First 20 rows of the entire data\n# Below two lines of code do the same thing\ncen10[1:20, ]\n\n# A tibble: 20 × 4\n   state         sex      age race           \n   <chr>         <chr>  <dbl> <chr>          \n 1 New York      Female     8 White          \n 2 Ohio          Male      24 White          \n 3 Nevada        Male      37 White          \n 4 Michigan      Female    12 White          \n 5 Maryland      Female    18 Black/Negro    \n 6 New Hampshire Male      50 White          \n 7 Iowa          Female    51 White          \n 8 Missouri      Female    41 White          \n 9 New Jersey    Male      62 White          \n10 California    Male      25 White          \n11 Texas         Female    23 White          \n12 Pennsylvania  Female    66 White          \n13 California    Female    57 White          \n14 Texas         Female    73 Other race, nec\n15 California    Male      43 White          \n16 Washington    Male      29 White          \n17 Texas         Male       8 White          \n18 Missouri      Male      78 White          \n19 West Virginia Male      10 White          \n20 Idaho         Female     9 White          \n\ncen10 %>% slice(1:20)\n\n# A tibble: 20 × 4\n   state         sex      age race           \n   <chr>         <chr>  <dbl> <chr>          \n 1 New York      Female     8 White          \n 2 Ohio          Male      24 White          \n 3 Nevada        Male      37 White          \n 4 Michigan      Female    12 White          \n 5 Maryland      Female    18 Black/Negro    \n 6 New Hampshire Male      50 White          \n 7 Iowa          Female    51 White          \n 8 Missouri      Female    41 White          \n 9 New Jersey    Male      62 White          \n10 California    Male      25 White          \n11 Texas         Female    23 White          \n12 Pennsylvania  Female    66 White          \n13 California    Female    57 White          \n14 Texas         Female    73 Other race, nec\n15 California    Male      43 White          \n16 Washington    Male      29 White          \n17 Texas         Male       8 White          \n18 Missouri      Male      78 White          \n19 West Virginia Male      10 White          \n20 Idaho         Female     9 White          \n\n# Of the first 20 rows of the entire data, look at values of just race and age\n# Below two lines of code do the same thing\ncen10[1:20, c(\"race\", \"age\")]\n\n# A tibble: 20 × 2\n   race              age\n   <chr>           <dbl>\n 1 White               8\n 2 White              24\n 3 White              37\n 4 White              12\n 5 Black/Negro        18\n 6 White              50\n 7 White              51\n 8 White              41\n 9 White              62\n10 White              25\n11 White              23\n12 White              66\n13 White              57\n14 Other race, nec    73\n15 White              43\n16 White              29\n17 White               8\n18 White              78\n19 White              10\n20 White               9\n\ncen10 %>% slice(1:20) %>% select(race, age)\n\n# A tibble: 20 × 2\n   race              age\n   <chr>           <dbl>\n 1 White               8\n 2 White              24\n 3 White              37\n 4 White              12\n 5 Black/Negro        18\n 6 White              50\n 7 White              51\n 8 White              41\n 9 White              62\n10 White              25\n11 White              23\n12 White              66\n13 White              57\n14 Other race, nec    73\n15 White              43\n16 White              29\n17 White               8\n18 White              78\n19 White              10\n20 White               9\n\n\nA vector is a special type of matrix with only one column or only one row\n\n# One column\ncen10[1:10, c(\"age\")]\n\n# A tibble: 10 × 1\n     age\n   <dbl>\n 1     8\n 2    24\n 3    37\n 4    12\n 5    18\n 6    50\n 7    51\n 8    41\n 9    62\n10    25\n\ncen10 %>% slice(1:10) %>% select(c(\"age\"))\n\n# A tibble: 10 × 1\n     age\n   <dbl>\n 1     8\n 2    24\n 3    37\n 4    12\n 5    18\n 6    50\n 7    51\n 8    41\n 9    62\n10    25\n\n# One row\ncen10[2, ]\n\n# A tibble: 1 × 4\n  state sex     age race \n  <chr> <chr> <dbl> <chr>\n1 Ohio  Male     24 White\n\ncen10 %>% slice(2)\n\n# A tibble: 1 × 4\n  state sex     age race \n  <chr> <chr> <dbl> <chr>\n1 Ohio  Male     24 White\n\n\nWhat if we want a special subset of the data? For example, what if I only want the records of individuals in California? What if I just want the age and race of individuals in California?\n\n# subset for CA rows\nca_subset <- cen10[cen10$state == \"California\", ]\n\nca_subset_tidy <- cen10 %>% filter(state == \"California\")\n\nall_equal(ca_subset, ca_subset_tidy)\n\n[1] TRUE\n\n# subset for CA rows and select age and race\nca_subset_age_race <- cen10[cen10$state == \"California\", c(\"age\", \"race\")]\n\nca_subset_age_race_tidy <- cen10 %>% filter(state == \"California\") %>% select(age, race)\n\nall_equal(ca_subset_age_race, ca_subset_age_race_tidy)\n\n[1] TRUE\n\n\nSome common operators that can be used to filter or to use as a condition. Remember, you can use the unique function to look at the set of all values a variable holds in the dataset.\n\n# all individuals older than 30 and younger than 70\ns1 <- cen10[cen10$age > 30 & cen10$age < 70, ]\ns2 <- cen10 %>% filter(age > 30 & age < 70)\nall_equal(s1, s2)\n\n[1] TRUE\n\n# all individuals in either New York or California\ns3 <- cen10[cen10$state == \"New York\" | cen10$state == \"California\", ]\ns4 <- cen10 %>% filter(state == \"New York\" | state == \"California\")\nall_equal(s3, s4)\n\n[1] TRUE\n\n# all individuals in any of the following states: California, Ohio, Nevada, Michigan\ns5 <- cen10[cen10$state %in% c(\"California\", \"Ohio\", \"Nevada\", \"Michigan\"), ]\ns6 <- cen10 %>% filter(state %in% c(\"California\", \"Ohio\", \"Nevada\", \"Michigan\"))\nall_equal(s5, s6)\n\n[1] TRUE\n\n# all individuals NOT in any of the following states: California, Ohio, Nevada, Michigan\ns7 <- cen10[!(cen10$state %in% c(\"California\", \"Ohio\", \"Nevada\", \"Michigan\")), ]\ns8 <- cen10 %>% filter(!state %in% c(\"California\", \"Ohio\", \"Nevada\", \"Michigan\"))\nall_equal(s7, s8)\n\n[1] TRUE"
  },
  {
    "objectID": "31_limits.html",
    "href": "31_limits.html",
    "title": "9  Limits",
    "section": "",
    "text": "Solving limits, i.e. finding out the value of functions as its input moves closer to some value, is important for the social scientist’s mathematical toolkit for two related tasks. The first is for the study of calculus, which will be in turn useful to show where certain functions are maximized or minimized. The second is for the study of statistical inference, which is the study of inferring things about things you cannot see by using things you can see."
  },
  {
    "objectID": "31_limits.html#example-the-central-limit-theorem",
    "href": "31_limits.html#example-the-central-limit-theorem",
    "title": "9  Limits",
    "section": "Example: The Central Limit Theorem",
    "text": "Example: The Central Limit Theorem\nPerhaps the most important theorem in statistics is the Central Limit Theorem,\n\nTheorem 9.1 (Central Limit Theorem (i.i.d. case)) For any series of independent and identically distributed random variables X_1, X_2, \\cdots, we know the distribution of its sum even if we do not know the distribution of X. The distribution of the sum is a Normal distribution.\n\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\text{Normal}(0, 1),\nwhere \\mu is the mean of X and \\sigma is the standard deviation of X. The arrow is read as “converges in distribution to”. \\text{Normal}(0, 1) indicates a Normal Distribution with mean 0 and variance 1.\nThat is, the limit of the distribution of the lefthand side is the distribution of the righthand side.\n\nThe sign of a limit is the arrow “\\rightarrow”. Although we have not yet covered probability so we have not described what distributions and random variables are, it is worth foreshadowing the Central Limit Theorem. The Central Limit Theorem is powerful because it gives us a guarantee of what would happen if n \\rightarrow \\infty, which in this case means we collected more data."
  },
  {
    "objectID": "31_limits.html#example-the-law-of-large-numbers",
    "href": "31_limits.html#example-the-law-of-large-numbers",
    "title": "9  Limits",
    "section": "Example: The Law of Large Numbers",
    "text": "Example: The Law of Large Numbers\nA finding that perhaps rivals the Central Limit Theorem is the Law of Large Numbers:\n\nTheorem 9.2 ((Weak) Law of Large Numbers) For any draw of identically distributed independent variables with mean \\mu, the sample average after n draws, \\bar{X}_n, converges in probability to the true mean as n \\rightarrow \\infty:\n\\lim\\limits_{n\\to \\infty} P(|\\bar{X}_n - \\mu | > \\varepsilon) = 0\nA shorthand of which is \\bar{X}_n \\xrightarrow{p} \\mu, where the arrow is read as “converges in probability to”.\n\nIntuitively, the more data, the more accurate is your guess. For example, Figure 9.1 shows how the sample average from many coin tosses converges to the true value : 0.5.\n\n\n\n\nFigure 9.1: As the number of coin tosses goes to infinity, the average probabiity of heads converges to 0.5"
  },
  {
    "objectID": "31_limits.html#sequences",
    "href": "31_limits.html#sequences",
    "title": "9  Limits",
    "section": "\n9.1 Sequences",
    "text": "9.1 Sequences\nWe need a couple of steps until we get to limit theorems in probability. First we will introduce a “sequence”, then we will think about the limit of a sequence, then we will think about the limit of a function.\nA sequence \\{x_n\\}=\\{x_1, x_2, x_3, \\ldots, x_n\\} is an ordered set of real numbers, where x_1 is the first term in the sequence and y_n is the nth term. Generally, a sequence is infinite, that is it extends to n=\\infty. We can also write the sequence as \\{x_n\\}^\\infty_{n=1}\nwhere the subscript and superscript are read together as “from 1 to infinity.”\n\nExample 9.1 How do these sequences behave?\n\n\\{A_n\\}=\\left\\{ 2-\\frac{1}{n^2} \\right\\}\n\\{B_n\\}=\\left\\{\\frac{n^2+1}{n} \\right\\}\n\\{C_n\\}=\\left\\{(-1)^n \\left(1-\\frac{1}{n}\\right) \\right\\}\n\n\nWe find the sequence by simply “plugging in” the integers into each n. The important thing is to get a sense of how these numbers are going to change. Example 1’s numbers seem to come closer and closer to 2, but will it ever surpass 2? Example 2’s numbers are also increasing each time, but will it hit a limit? What is the pattern in Example 3? Graphing helps you make this point more clearly. See the sequence of n = 1, ...20 for each of the three examples in Figure 9.2.\n\n\n\n\nFigure 9.2: Behavior of Some Sequences"
  },
  {
    "objectID": "31_limits.html#the-limit-of-a-sequence",
    "href": "31_limits.html#the-limit-of-a-sequence",
    "title": "9  Limits",
    "section": "\n9.2 The Limit of a Sequence",
    "text": "9.2 The Limit of a Sequence\nThe notion of “converging to a limit” is the behavior of the points in Example 9.1. In some sense, that’s the counterfactual we want to know. What happens as n\\rightarrow \\infty?\n\nSequences like 1 above that converge to a limit.\nSequences like 2 above that increase without bound.\nSequences like 3 above that neither converge nor increase without bound — alternating over the number line.\n\n\nDefinition 9.1 (Limit of a Sequence) \nThe sequence \\{y_n\\} has the limit L, which we write as \\lim\\limits_{n \\to \\infty} y_n =L, if for any \\epsilon>0 there is an integer N (which depends on \\epsilon) with the property that |y_n -L|<\\epsilon for each n>N. \\{y_n\\} is said to converge to L. If the above does not hold, then \\{y_n\\} diverges.\n\nWe can also express the behavior of a sequence as bounded or not:\n\nBounded: if |y_n|\\le K for all n\n\nMonotonically Increasing: y_{n+1}>y_n for all n\n\nMonotonically Decreasing: y_{n+1}<y_n for all n\n\n\nA limit is unique: If \\{y_n\\} converges, then the limit L is unique.\nIf a sequence converges, then the sum of such sequences also converges. Let \\lim\\limits_{n \\to \\infty} y_n = y and \\lim\\limits_{n \\to \\infty} z_n =z. Then\n\n\\lim\\limits_{n \\to \\infty} [k y_n + \\ell z_n]= k y + \\ell z\n\\lim\\limits_{n \\to \\infty} y_n z_n = yz\n\n\\lim\\limits_{n \\to \\infty} \\frac{y_n}{z_n} = \\frac{y}{z}, provided z\\neq 0\n\n\nThis looks reasonable enough. The harder question, obviously is when the parts of the fraction don’t converge. If \\lim_{n\\to\\infty} y_n = \\infty and \\lim_{n\\to\\infty} z_n = \\infty, What is \\lim_{n\\to\\infty} y_n - z_n? What is \\lim_{n\\to\\infty} \\frac{y_n}{z_n}?\nIt is nice for a sequence to converge in limit. We want to know if complex-looking sequences converge or not. The name of the game here is to break that complex sequence up into sums of simple fractions where n only appears in the denominator: \\frac{1}{n}, \\frac{1}{n^2}, and so on. Each of these will converge to 0, because the denominator gets larger and larger. Then, because of the properties above, we can then find the final sequence.\n\nExample 9.2 Find the limit of\n\\lim_{n\\to \\infty} \\frac{n + 3}{n}.\nAt first glance, n + 3 and n both grow to \\infty, so it looks like we need to divide infinity by infinity. However, we can express this fraction as a sum, then the limits apply separately:\n\\lim_{n\\to \\infty} \\frac{n + 3}{n} = \\lim_{n\\to \\infty} \\left(1 + \\frac{3}{n}\\right) =  \\underbrace{\\lim_{n\\to \\infty}1}_{1} +  \\underbrace{\\lim_{n\\to \\infty}\\left(\\frac{3}{n}\\right)}_{0}\nso, the limit is actually 1.\n\nAfter some practice, the key to intuition is whether one part of the fraction grows “faster” than another. If the denominator grows faster to infinity than the numerator, then the fraction will converge to 0, even if the numerator will also increase to infinity. In a sense, limits show how not all infinities are the same.\n\nExercise 9.1 Find the following limits of sequences, then explain in English the intuition for why that is the case.\n\n\\lim\\limits_{n\\to\\infty} \\frac{2n}{n^2 + 1}\n\\lim\\limits_{n\\to\\infty} (n^3 - 100n^2)"
  },
  {
    "objectID": "31_limits.html#limitsfun",
    "href": "31_limits.html#limitsfun",
    "title": "9  Limits",
    "section": "\n9.3 Limits of a Function",
    "text": "9.3 Limits of a Function\nWe’ve now covered functions and just covered limits of sequences, so now is the time to combine the two.\nA function f is a compact representation of some behavior we care about. Like for sequences, we often want to know if f(x) approaches some number L as its independent variable x moves to some number c (which is usually 0 or \\pm\\infty). If it does, we say that the limit of f(x), as x approaches c, is L: \\lim\\limits_{x \\to c} f(x)=L. Unlike a sequence, x is a continuous number, and we can move in decreasing order as well as increasing.\nFor a limit L to exist, the function f(x) must approach L from both the left (increasing) and the right (decreasing).\n\nDefinition 9.2 (Limit of a function) \nLet f(x) be defined at each point in some open interval containing the point c. Then L equals \\lim\\limits_{x \\to c} f(x) if for any (small positive) number \\epsilon, there exists a corresponding number \\delta>0 such that if 0<|x-c|<\\delta, then |f(x)-L|<\\epsilon.\n\nA neat, if subtle result is that f(x) does not necessarily have to be defined at c for \\lim\\limits_{x \\to c} to exist.\n\nProposition 9.1 Let f and g be functions with \\lim\\limits_{x \\to c} f(x)=k and \\lim\\limits_{x \\to c} g(x)=\\ell.\n\n\\lim\\limits_{x \\to c}[f(x)+g(x)]=\\lim\\limits_{x \\to c} f(x)+ \\lim\\limits_{x \\to c} g(x)\n\\lim\\limits_{x \\to c} kf(x) = k\\lim\\limits_{x \\to c} f(x)\n\\lim\\limits_{x \\to c} f(x) g(x) = \\left[\\lim\\limits_{x \\to c} f(x)\\right]\\cdot \\left[\\lim\\limits_{x \\to c} g(x)\\right]\n\n\\lim\\limits_{x \\to c} \\frac{f(x)}{g(x)} = \\frac{\\lim\\limits_{x \\to c} f(x)}{\\lim\\limits_{x \\to c} g(x)}, provided \\lim\\limits_{x \\to c} g(x)\\ne 0.\n\n\nSimple limits of functions can be solved as we did limits of sequences. Just be careful which part of the function is changing.\n\nExample 9.3 Find the limit of the following functions.\n\n\\lim_{x \\to c} k\n\\lim_{x \\to c} x\n\\lim_{x\\to 2} (2x-3)\n\\lim_{x \\to c} x^n\n\n\nLimits can get more complex in roughly two ways. First, the functions may become large polynomials with many moving pieces. Second,the functions may become discontinuous.\nThe function can be thought of as a more general or “smooth” version of sequences. For example,\n\nExercise 9.2 Find the limit of\n\\lim_{x\\to\\infty} \\frac{(x^4 +3x−99)(2−x^5)}{(18x^7 +9x^6 −3x^2 −1)(x+1)}\n\nNow, the functions will become a bit more complex:\n\nExercise 9.3 Solve the following limits of functions\n\n\\lim\\limits_{x\\to 0} |x|\n\\lim\\limits_{x\\to 0} \\left(1+\\frac{1}{x^2}\\right)\n\n\nSo there are a few more alternatives about what a limit of a function could be:\n\nRight-hand limit: The value approached by f(x) when you move from right to left.\nLeft-hand limit: The value approached by f(x) when you move from left to right.\nInfinity: The value approached by f(x) as x grows infinitely large. Sometimes this may be a number; sometimes it might be \\infty or -\\infty.\nNegative infinity: The value approached by f(x) as x grows infinitely negative. Sometimes this may be a number; sometimes it might be \\infty or -\\infty.\n\nThe distinction between left and right becomes important when the function is not determined for some values of x. What are those cases in the examples below?\n\n\n\n\nFunctions which are not defined in some areas"
  },
  {
    "objectID": "31_limits.html#continuity",
    "href": "31_limits.html#continuity",
    "title": "9  Limits",
    "section": "\n9.4 Continuity",
    "text": "9.4 Continuity\nTo repeat a finding from the limits of functions: f(x) does not necessarily have to be defined at c for \\lim\\limits_{x \\to c} to exist. Functions that have breaks in their lines are called discontinuous. Functions that have no breaks are called continuous. Continuity is a concept that is more fundamental to, but related to that of “differentiability”, which we will cover next in calculus.\n\nDefinition 9.3 (Continuity”) \nSuppose that the domain of the function f includes an open interval containing the point c. Then f is continuous at c if \\lim\\limits_{x \\to c} f(x) exists and if \\lim\\limits_{x \\to c} f(x)=f(c). Further, f is continuous on an open interval (a,b) if it is continuous at each point in the interval.\n\nTo prove that a function is continuous for all points is beyond this practical introduction to math, but the general intuition can be grasped by graphing.\n\nExample 9.4 For each function, determine if it is continuous or discontinuous.\n\nf(x) = \\sqrt{x}\nf(x) = e^x\nf(x) = 1 + \\frac{1}{x^2}\n\nf(x) = \\text{floor}(x).\n\nThe floor is the smaller of the two integers bounding a number. So \\text{floor}(x = 2.999) = 2, \\text{floor}(x = 2.0001) = 2, and \\text{floor}(x = 2) = 2.\n\n\nSolution. In Figure Figure 9.3, we can see that the first two functions are continuous, and the next two are discontinuous. f(x) = 1 + \\frac{1}{x^2} is discontinuous at x= 0, and f(x) = \\text{floor}(x) is discontinuous at each whole number.\n\n\n\n\n\nFigure 9.3: Continuous and Discontinuous Functions\n\n\n\n\nSome properties of continuous functions:\n\n\nIf f and g are continuous at point c, then f+g, f-g, f \\cdot g, |f|, and \\alpha f are continuous at point c also. f/g is continuous, provided g(c)\\ne 0.\nBoundedness: If f is continuous on the closed bounded interval [a,b], then there is a number K such that |f(x)|\\le K for each x in [a,b].\nMax/Min: If f is continuous on the closed bounded interval [a,b], then f has a maximum and a minimum on [a,b]. They may be located at the end points.\n\n\n\nExercise 9.4 Let f(x) = \\frac{x^2 + 2x}{x}.\n\nGraph the function. Is it defined everywhere?\nWhat is the functions limit at x \\rightarrow 0?"
  },
  {
    "objectID": "31_limits.html#answers-to-examples",
    "href": "31_limits.html#answers-to-examples",
    "title": "9  Limits",
    "section": "Answers to Examples",
    "text": "Answers to Examples\nExample 9.1\nSolution.\n\n\\{A_n\\}=\\left\\{ 2-\\frac{1}{n^2} \\right\\} = \\left\\{1, \\frac{7}{4}, \\frac{17}{9}, \\frac{31}{16}, \\frac{49}{25}, \\ldots\\right\\} = 2\n\\{B_n\\}=\\left\\{\\frac{n^2+1}{n} \\right\\} = \\left\\{2, \\frac{5}{2}, \\frac{10}{3}, \\frac{17}{4}..., \\right\\}\n\\{C_n\\}=\\left\\{(-1)^n \\left(1-\\frac{1}{n}\\right) \\right\\} = \\left\\{0, \\frac{1}{2}, -\\frac{2}{3}, \\frac{3}{4}, -\\frac{4}{5}\\right\\}\n\nExercise 9.1\n\nSolution. Plot the function and you’ll see the following limits:\n\n0\n\\infty\n\n\nExample 9.3\nSolution.\n\nk\nc\n\\lim_{x\\to 2} (2x-3) = 2\\lim\\limits_{x\\to 2} x - 3\\lim\\limits_{x\\to 2} 1 = 1\n\\lim_{x \\to c} x^n = \\lim\\limits_{x \\to c} x \\cdots[\\lim\\limits_{x \\to c} x] = c\\cdots c =c^n\n\nExercise 9.2\n\nSolution. Although this function seems large, the thing our eyes should focus on is where the highest order polynomial remains. That will grow the fastest, so if the highest order term is on the denominator, the fraction will converge to 0, if it is on the numerator it will converge to negative infinity. Previewing the multiplication by hand, we can see that the -x^9 on the numerator will be the largest power. So the answer will be -\\infty. We can also confirm this by writing out fractions:\n\\begin{align*}  \n& \\lim_{x\\to\\infty}\\frac{\\left(1 + \\frac{3}{x^3} - \\frac{99}{4x^4}\\right)\\left(-\\frac{2}{x^5} + 1\\right)}{\\left(1 + \\frac{9}{18x} - \\frac{3}{18x^5} - \\frac{1}{18x^7} \\right)\\left(1 + \\frac{1}{x}\\right)} \\\\\n&\\times \\frac{x^4}{1} \\times -\\frac{x^5}{1} \\times \\frac{1}{18x^7}\\times \\frac{1}{x}\\\\\n=& 1 \\times \\lim_{-x\\to\\infty} \\frac{x}{18}\n\\end{align*}\n\nExercise 9.4\n\nSolution. See Figure 9.4. We can say \\lim_{x\\to 0}f(x) = 2. Note that we can express f(x) =\n    \\left\\{\n    \\begin{array}{ll}\n        x+2 & x \\neq 2; \\\\\n        \\textrm{undefined} & x = 2 \\\\\n    \\end{array}\n    \\right.\n\n\n\n\n\nFigure 9.4: A function undedefined at x = 0"
  },
  {
    "objectID": "32_derivatives.html",
    "href": "32_derivatives.html",
    "title": "10  Differential Calculus",
    "section": "",
    "text": "Calculus is a fundamental part of any type of statistics exercise. Although you may not be taking derivatives and integral in your daily work as an analyst, calculus undergirds many concepts we use: maximization, expectation, and cumulative probability."
  },
  {
    "objectID": "32_derivatives.html#sec-derivintro",
    "href": "32_derivatives.html#sec-derivintro",
    "title": "10  Differential Calculus",
    "section": "\n10.1 Derivatives",
    "text": "10.1 Derivatives\nThe derivative of f at x is its rate of change at x: how much f(x) changes with a change in x. The rate of change is a fraction — rise over run — but because not all lines are straight and the rise over run formula will give us different values depending on the range we examine, we need to take a limit.\n\nDefinition 10.1 (Derivative) Let f be a function whose domain includes an open interval containing the point x. The derivative of f at x is given by\n\\frac{d}{dx}f(x) =\\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{(x+h)-x} = \\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{h}\nThere are a two main ways to denote a derivate:\n\nLeibniz Notation: \\frac{d}{dx}(f(x))\n\nPrime or Lagrange Notation: f'(x)\n\n\n\nIf f(x) is a straight line, the derivative is the slope. For a curve, the slope changes by the values of x, so the derivative is the slope of the line tangent to the curve at x. See, For example, Figure 10.1.\n\n\n\n\nFigure 10.1: The Derivative as a Slope\n\n\n\n\nIf f'(x) exists at a point x_0, then f is said to be differentiable at x_0. That also implies that f(x) is continuous at x_0.\nProperties of derivatives\nSuppose that f and g are differentiable at x and that \\alpha is a constant. Then the functions f\\pm g, \\alpha f, f g, and f/g (provided g(x)\\ne 0) are also differentiable at x. Additionally,\nConstant rule: \\left[k f(x)\\right]' = k f'(x)\nSum rule: \\left[f(x)\\pm g(x)\\right]' = f'(x)\\pm g'(x)\nWith a bit more algebra, we can apply the definition of derivatives to get a formula for of the derivative of a product and a derivative of a quotient.\nProduct rule: \\left[f(x)g(x)\\right]^\\prime = f^\\prime(x)g(x)+f(x)g^\\prime(x)\nQuotient rule: \\left[f(x)/g(x)\\right]^\\prime = \\frac{f^\\prime(x)g(x) - f(x)g^\\prime(x)}{[g(x)]^2}, ~g(x)\\neq 0\nFinally, one way to think of the power of derivatives is that it takes a function a notch down in complexity. The power rule applies to any higher-order function:\nPower rule: \\left[x^k\\right]^\\prime = k x^{k-1}\nFor any real number k (that is, both whole numbers and fractions). The power rule is proved by induction, a neat method of proof used in many fundamental applications to prove that a general statement holds for every possible case, even if there are countably infinite cases. We’ll show a simple case where k is an integer here.\n\nProof. We would like to prove that\n\\left[x^k\\right]^\\prime = k x^{k-1}\nfor any integer k.\nFirst, consider the first case (the base case) of k = 1. We can show by the definition of derivatives (setting f(x) = x^1 = 1) that\n[x^1]^\\prime = \\lim_{h \\rightarrow 0}\\frac{(x + h) - x}{(x + h) - x}= 1.\nBecause 1 is also expressed as 1 x^{1- 1}, the statement we want to prove holds for the case k =1.\nNow, that the statement holds for some integer m. That is, assume\n\\left[x^m\\right]^\\prime = m x^{m-1}\nThen, for the case m + 1, using the product rule above, we can simplify\n\\begin{align*}\n  \\left[x^{m + 1}\\right]^\\prime &= [x^{m}\\cdot x]^\\prime\\\\\n  &= (x^m)^\\prime\\cdot x + (x^m)\\cdot (x)^\\prime\\\\\n  &= m x^{m - 1}\\cdot x + x^m ~~\\because \\text{by previous assumption}\\\\\n  &= mx^m + x^m\\\\\n  &= (m + 1)x^m\\\\\n  &= (m + 1)x^{(m + 1) - 1}\n  \\end{align*}\nTherefore, the rule holds for the case k = m + 1 once we have assumed it holds for k = m. Combined with the first case, this completes proof by induction – we have now proved that the statement holds for all integers k = 1, 2, 3, \\cdots.\nTo show that it holds for real fractions as well, we can prove expressing that exponent by a fraction of two integers.\n\nThese “rules” become apparent by applying the definition of the derivative above to each of the things to be “derived”, but these come up so frequently that it is best to repeat until it is muscle memory.\n\nExercise 10.1 For each of the following functions, find the first-order derivative f^\\prime(x).\n\nf(x)=c\nf(x)=x\nf(x)=x^2\nf(x)=x^3\nf(x)=\\frac{1}{x^2}\nf(x)=(x^3)(2x^4)\nf(x) = x^4 - x^3 + x^2 - x + 1\nf(x) = (x^2 + 1)(x^3 - 1)\nf(x) = 3x^2 + 2x^{1/3}\nf(x)=\\frac{x^2+1}{x^2-1}"
  },
  {
    "objectID": "32_derivatives.html#derivpoly",
    "href": "32_derivatives.html#derivpoly",
    "title": "10  Differential Calculus",
    "section": "\n10.2 Higher-Order Derivatives",
    "text": "10.2 Higher-Order Derivatives\nThe first derivative is applying the definition of derivatives on the function, and it can be expressed as\nf'(x),  ~~ y',  ~~ \\frac{d}{dx}f(x), ~~ \\frac{dy}{dx}\nWe can keep applying the differentiation process to functions that are themselves derivatives. The derivative of f'(x) with respect to x, would then be f''(x)=\\lim\\limits_{h\\to 0}\\frac{f'(x+h)-f'(x)}{h} and we can therefore call it the Second derivative:\nf''(x), ~~ y'', ~~ \\frac{d^2}{dx^2}f(x), ~~ \\frac{d^2y}{dx^2}\nSimilarly, the derivative of f''(x) would be called the third derivative and is denoted f'''(x). And by extension, the nth derivative is expressed as \\frac{d^n}{dx^n}f(x), \\frac{d^ny}{dx^n}.\n\nExample 10.1 \n\\begin{align*}\nf(x) &=x^3\\\\\nf^{\\prime}(x) &=3x^2\\\\\nf^{\\prime\\prime}(x) &=6x \\\\\nf^{\\prime\\prime\\prime}(x) &=6\\\\\nf^{\\prime\\prime\\prime\\prime}(x) &=0\\\\\n\\end{align*}\n\nEarlier, in Section 10.1, we said that if a function differentiable at a given point, then it must be continuous. Further, if f'(x) is itself continuous, then f(x) is called continuously differentiable. All of this matters because many of our findings about optimization rely on differentiation, and so we want our function to be differentiable in as many layers. A function that is continuously differentiable infinitly is called “smooth”. Some examples: f(x) = x^2, f(x) = e^x."
  },
  {
    "objectID": "32_derivatives.html#the-chain-rule",
    "href": "32_derivatives.html#the-chain-rule",
    "title": "10  Differential Calculus",
    "section": "\n10.3 The Chain Rule",
    "text": "10.3 The Chain Rule\nAs useful as the above rules are, many functions you’ll see won’t fit neatly in each case immediately. Instead, they will be functions of functions. For example, the difference between x^2 + 1^2 and (x^2 + 1)^2 may look trivial, but the sum rule can be easily applied to the former, while it’s actually not obvious what do with the latter.\nComposite functions are formed by substituting one function into another and are denoted by (f\\circ g)(x)=f[g(x)]. To form f[g(x)], the range of g must be contained (at least in part) within the domain of f. The domain of f\\circ g consists of all the points in the domain of g for which g(x) is in the domain of f.\n\nExample 10.2 Let f(x)=\\ln x for 0<x<\\infty and g(x)=x^2 for -\\infty<x<\\infty.\nThen\n(f\\circ g)(x)=\\ln x^2, -\\infty<x<\\infty - \\{0\\}\nAlso\n(g\\circ f)(x)=[\\ln x]^2, 0<x<\\infty\nNotice that f\\circ g and g\\circ f are not the same functions.\n\nWith the notation of composite functions in place, now we can introduce a helpful additional rule that will deal with a derivative of composite functions as a chain of concentric derivatives.\nChain Rule:\nLet y=(f\\circ g)(x)= f[g(x)]. The derivative of y with respect to x is \\frac{d}{dx} \\{ f[g(x)] \\} = f'[g(x)] g'(x)\nWe can read this as: “the derivative of the composite function y is the derivative of f evaluated at g(x), times the derivative of g.”\nThe chain rule can be thought of as the derivative of the “outside” times the derivative of the “inside”, remembering that the derivative of the outside function is evaluated at the value of the inside function.\n\nThe chain rule can also be written as \\frac{dy}{dx}=\\frac{dy}{dg(x)} \\frac{dg(x)}{dx} This expression does not imply that the dg(x)’s cancel out, as in fractions. They are part of the derivative notation and you can’t separate them out or cancel them.)\n\n\nExample 10.3 \nFind f^\\prime(x) for f(x) = (3x^2+5x-7)^6.\n\nThe direct use of a chain rule is when the exponent of is itself a function, so the power rule could not have applied generaly:\nGeneralized Power Rule:\nIf f(x)=[g(x)]^p for any rational number p, f^\\prime(x) =p[g(x)]^{p-1}g^\\prime(x)"
  },
  {
    "objectID": "32_derivatives.html#derivatives-of-logs-and-exponents",
    "href": "32_derivatives.html#derivatives-of-logs-and-exponents",
    "title": "10  Differential Calculus",
    "section": "\n10.4 Derivatives of logs and exponents",
    "text": "10.4 Derivatives of logs and exponents\nNatural logs and exponents (they are inverses of each other; see Prerequisites) crop up everywhere in statistics. Their derivative is a special case from the above, but quite elegant.\n\nTheorem 10.1 The functions e^x and the natural logarithm \\ln(x) are continuous and differentiable in their domains, and their first derivate is\n(e^x)^\\prime = e^x\n\\ln(x)^\\prime = \\frac{1}{x}\nAlso, when these are composite functions, it follows by the generalized power rule that\n\\left(e^{g(x)}\\right)^\\prime = e^{g(x)} \\cdot g^\\prime(x)\n\\left(\\ln g(x)\\right)^\\prime = \\frac{g^\\prime(x)}{g(x)}, ~~\\text{if}~~ g(x) > 0\n\nWe will relegate the proofs to small excerpts.\nDerivatives of exponents\nTo repeat the main rule in Theorem 10.1, the intuition is that\n\nDerivative of e^x is itself: \\frac{d}{dx}e^x = e^x (See Figure 10.2)\nSame thing if there were a constant in front: \\frac{d}{dx}\\alpha e^x = \\alpha e^x\n\nSame thing no matter how many derivatives there are in front: \\frac{d^n}{dx^n} \\alpha e^x = \\alpha e^x\n\nChain Rule: When the exponent is a function of x, remember to take derivative of that function and add to product. \\frac{d}{dx}e^{g(x)}= e^{g(x)} g^\\prime(x)\n\n\n\n\n\n\nFigure 10.2: Derivative of the Exponential Function\n\n\n\n\n\nExample 10.4 Find the derivative for the following.\n\nf(x)=e^{-3x}\nf(x)=e^{x^2}\nf(x)=(x-1)e^x\n\n\nDerivatives of logs\nThe natural log is the mirror image of the natural exponent and has mirroring properties, again, to repeat the theorem,\n\nlog prime x is one over x (Figure 10.3):\n\n\\frac{d}{dx} \\ln x = \\frac{1}{x}\n\nExponents become multiplicative constants:\n\n\\frac{d}{dx} \\ln x^k = \\frac{d}{dx} k \\ln x = \\frac{k}{x}\n\nChain rule again:\n\n\\frac{d}{dx} \\ln u(x) = \\frac{u'(x)}{u(x)}\\quad\n\nFor any positive base b,\n\n\\frac{d}{dx} b^x = (\\ln b)\\left(b^x\\right)\n\n\n\n\nFigure 10.3: Derivative of the Natural Log\n\n\n\n\n\nExample 10.5 Find dy/dx for the following.\n\nf(x)=\\ln(x^2+9)\nf(x)=\\ln(\\ln x)\nf(x)=(\\ln x)^2\nf(x)=\\ln e^x\n\n\nOutline of Proof\nWe actually show the derivative of the log first, and then the derivative of the exponential naturally follows.\nThe general derivative of the log at any base a is solvable by the definition of derivatives.\n\\begin{align*}\n(\\ln_a x)^\\prime = \\lim\\limits_{h\\to 0} \\frac{1}{h}\\ln_{a}\\left(1 + \\frac{h}{x}\\right)\n\\end{align*}\nRe-express g = \\frac{h}{x} and get \\begin{align*}\n(\\ln_a x)^\\prime &= \\frac{1}{x}\\lim_{g\\to 0}\\ln_{a} (1 + g)^{\\frac{1}{g}}\\\\\n&= \\frac{1}{x}\\ln_a e\n\\end{align*}\nBy definition of e. As a special case, when a = e, then (\\ln x)^\\prime = \\frac{1}{x}.\nNow let’s think about the inverse, taking the derivative of y = a^x.\n\\begin{align*}\ny &= a^x \\\\\n\\Rightarrow \\ln y &= x \\ln a\\\\\n\\Rightarrow \\frac{y^\\prime}{y} &= \\ln a\\\\\n\\Rightarrow  y^\\prime = y \\ln a\\\\\n\\end{align*}\nThen in the special case where a = e,\n(e^x)^\\prime = (e^x)"
  },
  {
    "objectID": "32_derivatives.html#partial-derivatives",
    "href": "32_derivatives.html#partial-derivatives",
    "title": "10  Differential Calculus",
    "section": "\n10.5 Partial Derivatives",
    "text": "10.5 Partial Derivatives\nWhat happens when there’s more than variable that is changing?\n\nIf you can do ordinary derivatives, you can do partial derivatives: just hold all the other input variables constant except for the one you’re differentiating with respect to. (Joe Blitzstein’s Math Notes)\n\nSuppose we have a function f now of two (or more) variables and we want to determine the rate of change relative to one of the variables. To do so, we would find its partial derivative, which is defined similar to the derivative of a function of one variable.\nPartial Derivative: Let f be a function of the variables (x_1,\\ldots,x_n). The partial derivative of f with respect to x_i is\n\\frac{\\partial f}{\\partial x_i} (x_1,\\ldots,x_n) = \\lim\\limits_{h\\to 0} \\frac{f(x_1,\\ldots,x_i+h,\\ldots,x_n)-f(x_1,\\ldots,x_i,\\ldots,x_n)}{h}\nOnly the ith variable changes — the others are treated as constants.\nWe can take higher-order partial derivatives, like we did with functions of a single variable, except now the higher-order partials can be with respect to multiple variables.\n\nExample 10.6 Notice that you can take partials with regard to different variables.\nSuppose f(x,y)=x^2+y^2. Then\n\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}\n\n\nExercise 10.2 Let f(x,y)=x^3 y^4 +e^x -\\ln y. What are the following partial derivaitves?\n\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}"
  },
  {
    "objectID": "32_derivatives.html#taylorapprox",
    "href": "32_derivatives.html#taylorapprox",
    "title": "10  Differential Calculus",
    "section": "\n10.6 Taylor Approximation",
    "text": "10.6 Taylor Approximation\nA common form of approximation used in statistics involves derivatives. A Taylor series is a way to represent common functions as infinite series (a sum of infinite elements) of the function’s derivatives at some point a.\nFor example, Taylor series are very helpful in representing nonlinear (read: difficult) functions as linear (read: manageable) functions. One can thus approximate functions by using lower-order, finite series known as Taylor polynomials. If a=0, the series is called a Maclaurin series.\nSpecifically, a Taylor series of a real or complex function f(x) that is infinitely differentiable in the neighborhood of point a is:\n\\begin{align*}\n    f(x) &= f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2 + \\cdots\\\\\n     &= \\sum_{n=0}^\\infty \\frac{f^{(n)} (a)}{n!} (x-a)^n\n\\end{align*}\nTaylor Approximation: We can often approximate the curvature of a function f(x) at point a using a 2nd order Taylor polynomial around point a:\nf(x) = f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2 + R_2\nR_2 is the remainder (R for remainder, 2 for the fact that we took two derivatives) and often treated as negligible, giving us:\nf(x) \\approx f(a) + f'(a)(x-a) +  \\dfrac{f''(a)}{2} (x-a)^2\nThe more derivatives that are added, the smaller the remainder R and the more accurate the approximation. Proofs involving limits guarantee that the remainder converges to 0 as the order of derivation increases."
  },
  {
    "objectID": "33_optimization.html",
    "href": "33_optimization.html",
    "title": "11  Optimization",
    "section": "",
    "text": "To optimize, we use derivatives and calculus. Optimization is to find the maximum or minimum of a functon, and to find what value of an input gives that extremum. This has obvious uses in engineering. Many tools in the statistical toolkit use optimization. One of the most common ways of estimating a model is through “Maximum Likelihood Estimation”, done via optimizing a function (the likelihood).\nOptimization also comes up in Economics, Formal Theory, and Political Economy all the time. A go-to model of human behavior is that they optimize a certain utility function. Humans are not pure utility maximizers, of course, but nuanced models of optimization – for example, adding constraints and adding uncertainty – will prove to be quite useful."
  },
  {
    "objectID": "33_optimization.html#maxima-and-minima",
    "href": "33_optimization.html#maxima-and-minima",
    "title": "11  Optimization",
    "section": "\n11.1 Maxima and Minima",
    "text": "11.1 Maxima and Minima\nThe first derivative, f'(x), quantifies the slope of a function. Therefore, it can be used to check whether the function f(x) at the point x is increasing or decreasing at x.\n\n\nIncreasing: f'(x)>0\n\n\nDecreasing: f'(x)<0\n\n\nNeither increasing nor decreasing: f'(x)=0 i.e. a maximum, minimum, or saddle point\n\nSo for example, f(x) = x^2 + 2 and f^\\prime(x) = 2x\n\n\n\n\nMaxima and Minima\n\n\n\n\n\nExercise 11.1 (Plotting a mazimum and minimum) \nPlot f(x)=x^3+ x^2 + 2, plot its derivative, and identifiy where the derivative is zero. Is there a maximum or minimum?\n\n\n\n\nThe second derivative f''(x) identifies whether the function f(x) at the point x is\n\nConcave / concave down: f''(x)<0\n\nConvex / Concave up: f''(x)>0\n\n\nMaximum (Minimum): x_0 is a local maximum (minimum) if f(x_0)>f(x) (f(x_0)<f(x)) for all x within some open interval containing x_0. x_0 is a global maximum (minimum) if f(x_0)>f(x) (f(x_0)<f(x)) for all x in the domain of f.\nGiven the function f defined over domain D, all of the following are defined as critical points:\n\nAny interior point of D where f'(x)=0.\nAny interior point of D where f'(x) does not exist.\nAny endpoint that is in D.\n\nThe maxima and minima will be a subset of the critical points.\nSecond Derivative Test of Maxima/Minima: We can use the second derivative to tell us whether a point is a maximum or minimum of f(x).\n\nLocal Maximum: f'(x)=0 and f''(x)<0\n\nLocal Minimum: f'(x)=0 and f''(x)>0\n\nNeed more info: f'(x)=0 and f''(x)=0\n\n\nGlobal Maxima and Minima Sometimes no global max or min exists — e.g., f(x) not bounded above or below. However, there are three situations where we can fairly easily identify global max or min.\n\n\nFunctions with only one critical point. If x_0 is a local max or min of f and it is the only critical point, then it is the global max or min.\n\nGlobally concave up or concave down functions. If f''(x) is never zero, then there is at most one critical point. That critical point is a global maximum if f''<0 and a global minimum if f''>0.\n\nFunctions over closed and bounded intervals must have both a global maximum and a global minimum.\n\n\nExample 11.1 (Maxima and Minima by drawing) Find any critical points and identify whether they are a max, min, or saddle point:\n\nf(x)=x^2+2\nf(x)=x^3+2\n\nf(x)=|x^2-1|, x\\in [-2,2]"
  },
  {
    "objectID": "33_optimization.html#concavity-of-a-function",
    "href": "33_optimization.html#concavity-of-a-function",
    "title": "11  Optimization",
    "section": "\n11.2 Concavity of a Function",
    "text": "11.2 Concavity of a Function\nConcavity helps identify the curvature of a function, f(x), in 2 dimensional space.\n\nDefinition 11.1 (Concave Function) \nA function f is strictly concave over the set S \\forall x_1,x_2 \\in S and \\forall a \\in (0,1), f(ax_1 + (1-a)x_2) > af(x_1) + (1-a)f(x_2) line connecting two points on a concave function will lie the function.\n\n\n\n\n\n\n\nDefinition 11.2 (Convex Function) Convex: A function f is strictly convex over the set S \\forall x_1,x_2 \\in S and \\forall a \\in (0,1), f(ax_1 + (1-a)x_2) < af(x_1) + (1-a)f(x_2)\nAny line connecting two points on a convex function will lie above the function.\n\nSecond Derivative Test of Concavity: The second derivative can be used to understand concavity.\nIf\n\\left\\{\\begin{array}{lll}\nf''(x) < 0 & \\Rightarrow & \\text{Concave}\\\\\nf''(x) > 0 & \\Rightarrow & \\text{Convex}\n\\end{array}\\right.\nQuadratic Forms\nQuadratic forms is shorthand for a way to summarize a function. This is important for finding concavity because\n\nApproximates local curvature around a point — e.g., used to identify max vs min vs saddle point.\nThey are simple to express even in n dimensions:\nHave a matrix representation.\n\nQuadratic Form: A polynomial where each term is a monomial of degree 2 in any number of variables:\n\\begin{align*}\n\\text{One variable: }& Q(x_1) = a_{11}x_1^2\\\\\n\\text{Two variables: }& Q(x_1,x_2) = a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\\\\\n\\text{N variables: }& Q(x_1,\\cdots,x_n)=\\sum\\limits_{i\\le j} a_{ij}x_i x_j\n\\end{align*}\nwhich can be written in matrix terms:\nOne variable\nQ(\\mathbf{x}) = x_1^\\top a_{11} x_1\nN variables: \\begin{align*}\nQ(\\mathbf{x}) &=\\begin{bmatrix} x_1 & x_2 & \\cdots & x_n \\end{bmatrix}\\begin{bmatrix}\na_{11}&\\frac{1}{2}a_{12}&\\cdots&\\frac{1}{2}a_{1n}\\\\\n\\frac{1}{2}a_{12}&a_{22}&\\cdots&\\frac{1}{2}a_{2n}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots\\\\\n\\frac{1}{2}a_{1n}&\\frac{1}{2}a_{2n}&\\cdots&a_{nn}\n\\end{bmatrix}\n\\begin{bmatrix} x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{bmatrix}\\\\\n&= \\mathbf{x}^\\top\\mathbf{Ax}\n\\end{align*}\nFor example, the Quadratic on \\mathbb{R}^2: \\begin{align*}\n  Q(x_1,x_2)&=\\begin{bmatrix} x_1& x_2 \\end{bmatrix} \\begin{bmatrix} a_{11}&\\frac{1}{2} a_{12}\\\\\n  \\frac{1}{2}a_{12}&a_{22}\\end{bmatrix} \\begin{bmatrix} x_1\\\\x_2 \\end{bmatrix} \\\\\n  &= a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\n\\end{align*}\nDefiniteness of Quadratic Forms\nWhen the function f(\\mathbf{x}) has more than two inputs, determining whether it has a maxima and minima (remember, functions may have many inputs but they have only one output) is a bit more tedious. Definiteness helps identify the curvature of a function, Q(\\textbf{x}), in n dimensional space.\nDefiniteness: By definition, a quadratic form always takes on the value of zero when x = 0, Q(\\textbf{x})=0 at \\textbf{x}=0. The definiteness of the matrix \\textbf{A} is determined by whether the quadratic form Q(\\textbf{x})=\\textbf{x}^\\top\\textbf{A}\\textbf{x} is greater than zero, less than zero, or sometimes both over all \\mathbf{x}\\ne 0."
  },
  {
    "objectID": "33_optimization.html#gradient-and-foc",
    "href": "33_optimization.html#gradient-and-foc",
    "title": "11  Optimization",
    "section": "\n11.3 Gradient and FOC",
    "text": "11.3 Gradient and FOC\nWe can see from a graphical representation that if a point is a local maxima or minima, it must meet certain conditions regarding its derivative. These are so commonly used that we refer these to “First Order Conditions” (FOCs) and “Second Order Conditions” (SOCs) in the economic tradition.\nWhen we examined functions of one variable x, we found critical points by taking the first derivative, setting it to zero, and solving for x. For functions of n variables, the critical points are found in much the same way, except now we set the partial derivatives equal to zero. Note: We will only consider critical points on the interior of a function’s domain.\nIn a derivative, we only took the derivative with respect to one variable at a time. When we take the derivative separately with respect to all variables in the elements of \\mathbf{x} and then express the result as a vector, we use the term Gradient and Hessian.\n\nDefinition 11.3 (Gradient) Given a function f(\\textbf{x}) in n variables, the gradient \\nabla f(\\mathbf{x}) (the greek letter nabla ) is a row vector, where the ith element is the partial derivative of f(\\textbf{x}) with respect to x_i:\n\\nabla f(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} &  \\frac{\\partial f(\\mathbf{x})}{\\partial x_2} & \\cdots & \\frac{\\partial f(\\mathbf{x})}{\\partial x_n} \\end{bmatrix}\n\nThe gradient points in the direction of the steepest rate of increase at each point \\mathbf{x}.\nBefore we know whether a point is a maxima or minima, if it meets the FOC it is a “Critical Point”.\n\nDefinition 11.4 (Critical Point) \n\\mathbf{x}^* is a critical point if and only if \\nabla f(\\mathbf{x}^*)=\\mathbf{0} (the vector of zeros). If the partial derivative of f(x) with respect to x^* is 0, then \\mathbf{x}^* is a critical point. To solve for \\mathbf{x}^*, find the gradient, set each element equal to 0, and solve the system of equations. \\mathbf{x}^* = \\begin{bmatrix} x_1^*\\\\x_2^*\\\\ \\vdots \\\\ x_n^*\\end{bmatrix}\n\n\nExample 11.2 \nExample: Given a function f(\\mathbf{x})=(x_1-1)^2+x_2^2+1, find the (1) Gradient and (2) Critical point of f(\\mathbf{x}).\n\n\nSolution. Gradient\n\\begin{align*}\n\\nabla f(\\mathbf{x}) &=\n  \\begin{bmatrix}\n  \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} &\n  \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix} 2(x_1-1) &\n  2x_2\n  \\end{bmatrix}\n\\end{align*}\nCritical Point \\mathbf{x}^*:\n\\begin{align*}\n&\\frac{\\partial f(\\mathbf{x})}{\\partial x_1} = 2(x_1-1) = 0 & \\Rightarrow x_1^* = 1\\\\\n&\\frac{\\partial f(\\mathbf{x})}{\\partial x_2} = 2x_2 = 0 & \\Rightarrow   x_2^* = 0\\\\\n\\end{align*}\nSo \\mathbf{x}^* = (1,0)"
  },
  {
    "objectID": "33_optimization.html#hessian-and-soc",
    "href": "33_optimization.html#hessian-and-soc",
    "title": "11  Optimization",
    "section": "\n11.4 Hessian and SOC",
    "text": "11.4 Hessian and SOC\nWhen we found a critical point for a function of one variable, we used the second derivative as a indicator of the curvature at the point in order to determine whether the point was a min, max, or saddle (second derivative test of concavity). For functions of n variables, we use second order partial derivatives as an indicator of curvature.\n\nDefinition 11.5 (Hessian) Given a function f(\\mathbf{x}) in n variables, the hessian \\mathbf{H(x)} is an n\\times n matrix, where the (i,j)th element is the second order partial derivative of f(\\mathbf{x}) with respect to x_i and x_j:\n\\mathbf{H(x)}=\\begin{bmatrix} \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1^2}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_1 \\partial x_2}& \\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 \\partial x_n}\\\\ \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2 \\partial x_1}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_2^2}& \\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2 \\partial x_n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n \\partial x_1}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_n \\partial x_2}& \\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n^2} \\end{bmatrix}\n\nNote that the hessian will be a symmetric matrix because \\frac{\\partial f(\\mathbf{x})}{\\partial x_1\\partial x_2} = \\frac{\\partial f(\\mathbf{x})}{\\partial x_2\\partial x_1}.\nAlso note that given that f(\\mathbf{x}) is of quadratic form, each element of the hessian will be a constant.\nThese definitions will be employed when we determine the Second Order Conditions of a function:\nGiven a function f(\\mathbf{x}) and a point \\mathbf{x}^* such that \\nabla f(\\mathbf{x}^*)=0,\n\nHessian is Positive Definite around \\mathbf{x}^* \\quad \\Longrightarrow \\quad Local Min\nHessian is Negative Definite around \\mathbf{x}^* \\quad \\Longrightarrow \\quad Local Max\nHessian is Indefinite around \\mathbf{x}^* \\quad \\Longrightarrow \\quad Saddle Point\n\nFurthermore, there’s an easier way to check whether a 2\\times 2 matrix is positive or negative definite.\nDefiniteness of 2 \\times 2 Matrix: For a 2 \\times 2 matrix $$=\n\\begin{bmatrix}\nA_{11} & A_{12}\\\\\nA_{21} & A_{22}\n\\end{bmatrix}\n$$\n\nIf \\mathrm{det}(\\mathbf{A}) > 0 and A_{11}>0, then \\mathbf{A} is positive definite\nIf \\mathrm{det}(\\mathbf{A}) > 0 and A_{11}<0, then \\mathbf{A} is negative definite\nIf \\mathrm{det}(\\mathbf{A}) < 0, then \\mathbf{A} is indefinite\n\n\nExample 11.3 (Max and min with two dimensions) \nWe found that the only critical point of f(\\mathbf{x})=(x_1-1)^2+x_2^2+1 is at \\mathbf{x}^*=(1,0). Is it a min, max, or saddle point?\n\n\nSolution. The Hessian is \\begin{align*}\n\\mathbf{H(x)} &= \\begin{bmatrix} 2&0\\\\0&2 \\end{bmatrix}\n\\end{align*} Since \\mathrm{det}(\\mathbf{H}(x)) = 4 > 0 and H_{11}=2>0, the Hessian is positive definite.\nMaxima, Minima, or Saddle Point? Since the Hessian is positive definite and the gradient equals 0, x^\\star = (1,0) is a local minimum.\nNote: Alternate check of definiteness. Is \\mathbf{H(x^*)} \\geq \\leq 0 \\quad \\forall \\quad \\mathbf{x}\\ne 0\n\\begin{align*}\n\\mathbf{x}^\\top H(\\mathbf{x}^*) \\mathbf{x} &= \\begin{bmatrix} x_1 & x_2 \\end{bmatrix}\\\\\n&= \\begin{bmatrix} 2&0\\\\0&2 \\end{bmatrix}\\\\\n\\begin{bmatrix} x_1\\\\x_2\\end{bmatrix} &= 2x_1^2+2x_2^2\n\\end{align*}\nFor any \\mathbf{x}\\ne 0, 2(x_1^2+x_2^2)>0, so the Hessian is positive definite and \\mathbf{x}^* is a strict local minimum.\n\nDefiniteness and Concavity\nAlthough definiteness helps us to understand the curvature of an n-dimensional function, it does not necessarily tell us whether the function is globally concave or convex.\nWe need to know whether a function is globally concave or convex to determine whether a critical point is a global min or max. We can use the definiteness of the Hessian to determine whether a function is globally concave or convex:\n\nHessian is Positive Semidefinite \\forall \\mathbf{x} \\quad \\Longrightarrow \\quad Globally Convex\nHessian is Negative Semidefinite \\forall \\mathbf{x} \\quad \\Longrightarrow \\quad Globally Concave\n\nNotice that the definiteness conditions must be satisfied over the entire domain."
  },
  {
    "objectID": "33_optimization.html#global-maxima-and-minima",
    "href": "33_optimization.html#global-maxima-and-minima",
    "title": "11  Optimization",
    "section": "\n11.5 Global Maxima and Minima",
    "text": "11.5 Global Maxima and Minima\nGlobal Max/Min Conditions: Given a function f(\\mathbf{x}) and a point \\mathbf{x}^* such that \\nabla f(\\mathbf{x}^*)=0,\n\n\nf(\\mathbf{x}) Globally Convex \\quad \\Longrightarrow \\quad Global Min\n\nf(\\mathbf{x}) Globally Concave \\quad \\Longrightarrow \\quad Global Max\n\nNote that showing that \\mathbf{H(x^*)} is negative semidefinite is not enough to guarantee \\mathbf{x}^* is a local max. However, showing that \\mathbf{H(x)} is negative semidefinite for all \\mathbf{x} guarantees that x^* is a global max. (The same goes for positive semidefinite and minima.)\n\nExample 11.4 Take f_1(x)=x^4 and f_2(x)=-x^4.\n\nBoth have x=0 as a critical point.\n\nUnfortunately, f''_1(0)=0 and f''_2(0)=0, so we can’t tell whether x=0 is a min or max for either. However, f''_1(x)=12x^2 and f''_2(x)=-12x^2.\n\nFor all x, f''_1(x)\\ge 0 and f''_2(x)\\le 0 — i.e., f_1(x) is globally convex and f_2(x) is globally concave.\nSo x=0 is a global min of f_1(x) and a global max of f_2(x).\n\n\n\nExercise 11.2 \nGiven f(\\mathbf{x})=x_1^3-x_2^3+9x_1x_2, find any maxima or minima.\n\nSolution.\n\nFirst order conditions\n\nGradient \\nabla f(\\mathbf{x}) \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2}\\end{bmatrix} =\n\\begin{bmatrix} 3x_1^2+9x_2 \\\\ -3x_2^2+9x_1 \\end{bmatrix}\n\nCritical Points \\mathbf{x^*}\n\nSet the gradient equal to zero and solve for x_1 and x_2. We have two equations and two unknowns. Solving for x_1 and x_2, we get two critical points: \\mathbf{x}_1^*=(0,0) and \\mathbf{x}_2^*=(3,-3).\n3x_1^2 + 9x_2 = 0 \\quad \\Rightarrow \\quad 9x_2 = -3x_1^2 \\quad \\Rightarrow \\quad x_2 = -\\frac{1}{3}x_1^2\n-3x_2^2 + 9x_1 = 0 \\quad \\Rightarrow \\quad -3(-\\frac{1} {3}x_1^2)^2 + 9x_1 = 0\n\\Rightarrow \\quad -\\frac{1}{3}x_1^4 + 9x_1 = 0 \\quad \\Rightarrow \\quad x_1^3 = 27x_1 \\quad \\Rightarrow \\quad x_1 = 3\n3(3)^2 + 9x_2 = 0 \\quad \\Rightarrow \\quad x_2 = -3\n\n\n\n\nSecond order conditions.\n\n\nHessian \\mathbf{H(x)}\n\\begin{bmatrix} 6x_1&9\\\\9&-6x_2 \\end{bmatrix}\n\n\nHessian \\mathbf{H(x_1^*)}\n\\begin{bmatrix} 0&9\\\\9&0\\end{bmatrix}\n\n\nLeading principal minors of \\mathbf{H(x_1^*)}\nM_1=0; M_2=-81\n\n\nDefiniteness of \\mathbf{H(x_1^*)}?\n\n\n\\mathbf{H(x_1^*)} is indefinite\n\n\n\nMaxima, Minima, or Saddle Point for \\mathbf{x_1^*}?\n\nSince \\mathbf{H(x_1^*)} is indefinite, \\mathbf{x}_1^*=(0,0) is a saddle point.\n\n\n\nHessian\n\\mathbf{H(x_2^*)}=\\begin{bmatrix} 18&9\\\\9&18\\end{bmatrix}\n\n\nLeading principal minors of \\mathbf{H(x_2^*)}\nM_1=18; M_2=243\n\n\nDefiniteness of \\mathbf{H(x_2^*)}?\n\n\n\\mathbf{H(x_2^*)} is positive definite\n\n\n\nMaxima, Minima, or Saddle Point for \\mathbf{x}_2^*?\n\nSince \\mathbf{H(x_2^*)} is positive definite, \\mathbf{x}_1^*=(3,-3) is a strict local minimum\n\n\n\n\nGlobal concavity/convexity.\n\nIs f(x) globally concave/convex?\n\nNo. In evaluating the Hessians for \\mathbf{x}_1^* and \\mathbf{x}_2^* we saw that the Hessian is not positive semidefinite at x = (0,0).\n\n\nAre any \\mathbf{x^*} global minima or maxima?\n\nNo. Since the function is not globally concave/convex, we can’t infer that \\mathbf{x}_2^*=(3,-3) is a global minimum. In fact, if we set x_1=0, the f(\\mathbf{x})=-x_2^3, which will go to -\\infty as x_2\\to \\infty."
  },
  {
    "objectID": "34_intergrals.html",
    "href": "34_intergrals.html",
    "title": "12  Integral Calculus",
    "section": "",
    "text": "So far, we’ve been interested in finding the derivative f=F' of a function F. However, sometimes we’re interested in exactly the reverse: finding the function F for which f is its derivative. We refer to F as the antiderivative of f.\n\nDefinition 12.1 (Antiderivative) The antiverivative of a function f(x) is a differentiable function F whose derivative is f.\nF^\\prime = f.\n\nAnother way to describe is through the inverse formula. Let DF be the derivative of F. And let DF(x) be the derivative of F evaluated at x. Then the antiderivative is denoted by D^{-1} (i.e., the inverse derivative). If DF=f, then F=D^{-1}f.\nThis definition bolsters the main takeaway about integrals and derivatives: They are inverses of each other.\n\nExercise 12.1 (Antiderivative) Find the antiderivative of the following:\n\nf(x) = \\frac{1}{x^2}\nf(x) = 3e^{3x}\n\n\nWe know from derivatives how to manipulate F to get f. But how do you express the procedure to manipulate f to get F? For that, we need a new symbol, which we will call indefinite integration.\n\nDefinition 12.2 (Indefinite Integral) The indefinite integral of f(x) is written\n\\int f(x) dx \nand is equal to the antiderivative of f.\n\n\nExample 12.1 Draw the function f(x) and its indefinite integral, \\int\\limits f(x) dx\nf(x) = (x^2-4)\n\n\nSolution. The Indefinite Integral of the function f(x) = (x^2-4) can, for example, be F(x) = \\frac{1}{3}x^3 - 4x. But it can also be F(x) = \\frac{1}{3}x^3 - 4x + 1, because the constant 1 disappears when taking the derivative.\n\nSome of these functions are plotted in the bottom panel of Figure 12.1 as dotted lines.\n\n\n\n\nFigure 12.1: The Many Indefinite Integrals of a Function\n\n\n\n\nNotice from these examples that while there is only a single derivative for any function, there are multiple antiderivatives: one for any arbitrary constant c. c just shifts the curve up or down on the y-axis. If more information is present about the antiderivative — e.g., that it passes through a particular point — then we can solve for a specific value of c.\n\nSome useful properties of integrals follow by virtue of being the inverse of a derivative.\n\n\n\nConstants are allowed to slip out: \\int a f(x)dx = a\\int f(x)dx\n\nIntegration of the sum is sum of integrations: \\int [f(x)+g(x)]dx=\\int f(x)dx + \\int g(x)dx\n\nReverse Power-rule: \\int x^n dx = \\frac{1}{n+1} x^{n+1} + c\n\nExponents are still exponents: \\int e^x dx = e^x +c\n\nRecall the derivative of \\ln(x) is one over x, and so: \\int \\frac{1}{x} dx = \\ln x + c\n\nReverse chain-rule: \\int e^{f(x)}f^\\prime(x)dx = e^{f(x)}+c\n\nMore generally: \\int [f(x)]^n f'(x)dx = \\frac{1}{n+1}[f(x)]^{n+1}+c\n\nRemember the derivative of a log of a function: \\int \\frac{f^\\prime(x)}{f(x)}dx=\\ln f(x) + c\n\n\n\n\nExample 12.2 (Common Integration) Simplify the following indefinite integrals:\n\n\\int 3x^2 dx\n\\int (2x+1)dx\n\\int e^x e^{e^x} dx"
  },
  {
    "objectID": "34_intergrals.html#the-definite-integral",
    "href": "34_intergrals.html#the-definite-integral",
    "title": "12  Integral Calculus",
    "section": "\n12.2 The Definite Integral",
    "text": "12.2 The Definite Integral\nIf there is a indefinite integral, there must be a definite integral. Indeed there is, but the notion of definite integrals comes from a different objective: finding the are a under a function. We will find, perhaps remarkably, that the formula we find to get the sum turns out to be expressible by the anti-derivative.\nSuppose we want to determine the area A(R) of a region R defined by a curve f(x) and some interval a\\le x \\le b.\n\n\n\n\nFigure 12.2: The Riemann Integral as a Sum of Evaluations\n\n\n\n\nOne way to calculate the area would be to divide the interval a\\le x\\le b into n subintervals of length \\Delta x and then approximate the region with a series of rectangles, where the base of each rectangle is \\Delta x and the height is f(x) at the midpoint of that interval. A(R) would then be approximated by the area of the union of the rectangles, which is given by S(f,\\Delta x)=\\sum\\limits_{i=1}^n f(x_i)\\Delta x and is called a Riemann sum.\nAs we decrease the size of the subintervals \\Delta x, making the rectangles “thinner,” we would expect our approximation of the area of the region to become closer to the true area. This allows us to express the area as a limit of a series:\nA(R)=\\lim\\limits_{\\Delta x\\to 0}\\sum\\limits_{i=1}^n f(x_i)\\Delta x\nFigure 12.2 shows that illustration. The curve depicted is f(x) = -15(x - 5) + (x - 5)^3 + 50. We want approximate the area under the curve between the x values of 0 and 10. We can do this in blocks of arbitrary width, where the sum of rectangles (the area of which is width times f(x) evaluated at the midpoint of the bar) shows the Riemann Sum. As the width of the bars \\Delta x becomes smaller, the better the estimate of A(R).\nThis is how we define the “Definite” Integral:\n\nDefinition 12.3 (The Definite Integral (Riemann)) If for a given function f the Riemann sum approaches a limit as \\Delta x \\to 0, then that limit is called the Riemann integral of f from a to b. We express this with the \\int, symbol, and write \\int\\limits_a^b f(x) dx= \\lim\\limits_{\\Delta x\\to 0} \\sum\\limits_{i=1}^n f(x_i)\\Delta x\nThe most straightforward of a definite integral is the definite integral. That is, we read\n\\int\\limits_a^b f(x) dx as the definite integral of f from a to b and we defined as the area under the “curve” f(x) from point x=a to x=b.\n\nThe fundamental theorem of calculus shows us that this sum is, in fact, the antiderivative.\n\nTheorem 12.1 (First Fundamental Theorem of Calculus) Let the function f be bounded on [a,b] and continuous on (a,b). Then, suggestively, use the symbol F(x) to denote the definite integral from a to x\nF(x)=\\int\\limits_a^x f(t)dt, \\quad a\\le x\\le b\nThen F(x) has a derivative at each point in (a,b) and F^\\prime(x)=f(x), \\quad a<x<b That is, the definite integral function of f is the one of the antiderivatives of some f.\n\nThis is again a long way of saying that that differentiation is the inverse of integration. But now, we’ve covered definite integrals.\nThe second theorem gives us a simple way of computing a definite integral as a function of indefinite integrals.\n\n\n12.2.1 Second Fundamental Theorem of Calculus\nLet the function f be bounded on [a,b] and continuous on (a,b). Let F be any function that is continuous on [a,b] such that F^\\prime(x)=f(x) on (a,b). Then \\int\\limits_a^bf(x)dx = F(b)-F(a)\n\n\nSo the procedure to calculate a simple definite integral \\int\\limits_a^b f(x)dx is then\n\nFind the indefinite integral F(x).\nEvaluate F(b)-F(a).\n\n\nExample 12.3 (Definite Integral of a monomial) \nSolve \\int\\limits_1^3 3x^2 dx. Let f(x) = 3x^2.\n\n\nExercise 12.2 \nWhat is the value of \\int\\limits_{-2}^2 e^x e^{e^x} dx?\n\nProperties for Definite Integrals\nThe area-interpretation of the definite integral provides some useful properties for definite integrals\n\n\nThere is no area below a point: \\int\\limits_a^a f(x)dx=0\n\nReversing the limits changes the sign of the integral: \\int\\limits_a^b f(x)dx=-\\int\\limits_b^a f(x)dx\n\nSums can be separated into their own integrals: \\int\\limits_a^b [\\alpha f(x)+\\beta g(x)]dx = \\alpha \\int\\limits_a^b f(x)dx + \\beta \\int\\limits_a^b g(x)dx\n\nAreas can be combined as long as limits are linked: \\int\\limits_a^b f(x) dx +\\int\\limits_b^c f(x)dx = \\int\\limits_a^c f(x)dx\n\n\n\n\nExercise 12.3 Simplify the following definite intergrals.\n\n\\int\\limits_1^1 3x^2 dx =\n\\int\\limits_0^4 (2x+1)dx=\n\\int\\limits_{-2}^0 e^x e^{e^x} dx + \\int\\limits_0^2 e^x e^{e^x} dx ="
  },
  {
    "objectID": "34_intergrals.html#integration-by-substitution",
    "href": "34_intergrals.html#integration-by-substitution",
    "title": "12  Integral Calculus",
    "section": "\n12.3 Integration by Substitution",
    "text": "12.3 Integration by Substitution\nFrom the second fundamental theorem of calculus, we now that a quick way to get a definite integral is to first find the indefinite integral, and then just plug in the bounds.\nSometimes the integrand (the thing that we are trying to take an integral of) doesn’t appear integrable using common rules and antiderivatives. A method one might try is integration by substitution, which is related to the Chain Rule.\nSuppose we want to find the indefinite integral \\int g(x)dx but g(x) is complex and none of the formulas we have seen so far seem to apply immediately. The trick is to come up with a new function u(x) such that g(x)=f[u(x)]u'(x).\nWhy does an introduction of yet another function end of simplifying things? Let’s refer to the antiderivative of f as F. Then the chain rule tells us that \\frac{d}{dx} F[u(x)]=f[u(x)]u'(x). So, F[u(x)] is the antiderivative of g. We can then write \\int g(x) dx= \\int f[u(x)]u'(x)dx = \\int \\frac{d}{dx} F[u(x)]dx = F[u(x)]+c\nTo summarize, the procedure to determine the indefinite integral \\int g(x)dx by the method of substitution:\n\nIdentify some part of g(x) that might be simplified by substituting in a single variable u (which will then be a function of x).\nDetermine if g(x)dx can be reformulated in terms of u and du.\nSolve the indefinite integral.\nSubstitute back in for x\n\n\nSubstitution can also be used to calculate a definite integral. Using the same procedure as above, \\int\\limits_a^b g(x)dx=\\int\\limits_c^d f(u)du = F(d)-F(c) where c=u(a) and d=u(b).\n\nExample 12.4 (Integration by Substitution I) \nSolve the indefinite integral \\int x^2 \\sqrt{x+1}dx.\n\nFor the above problem, we could have also used the substitution u=\\sqrt{x+1}. Then x=u^2-1 and dx=2u du. Substituting these in, we get \\int x^2\\sqrt{x+1}dx=\\int (u^2-1)^2 u 2u du which when expanded is again a polynomial and gives the same result as above.\nAnother case in which integration by substitution is is useful is with a fraction.\n\nExample 12.5 (Integration by Substitutiton II) \nSimplify \\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx."
  },
  {
    "objectID": "34_intergrals.html#integration-by-parts",
    "href": "34_intergrals.html#integration-by-parts",
    "title": "12  Integral Calculus",
    "section": "\n12.4 Integration by Parts",
    "text": "12.4 Integration by Parts\nAnother useful integration technique is integration by parts, which is related to the Product Rule of differentiation. The product rule states that \\frac{d}{dx}(uv)=u\\frac{dv}{dx}+v\\frac{du}{dx} Integrating this and rearranging, we get \\int u\\frac{dv}{dx}dx= u v - \\int v \\frac{du}{dx}dx or \\int u(x) v'(x)dx=u(x)v(x) - \\int v(x)u'(x)dx\nMore easily remembered with the mnemonic “Ultraviolet Voodoo”: \\int u dv = u v - \\int v du where du=u'(x)dx and dv=v'(x)dx.\nFor definite integrals, this is simply\n\\int\\limits_a^b u\\frac{dv}{dx}dx = \\left. u v \\right|_a^b - \\int\\limits_a^b v \\frac{du}{dx}dx\nOur goal here is to find expressions for u and dv that, when substituted into the above equation, yield an expression that’s more easily evaluated.\n\nExample 12.6 (Integration by Parts I) Simplify the following integrals. These seemingly obscure forms of integrals come up often when integrating distributions.\n\\int x e^{ax} dx\n\n\nSolution. Let u=x and \\frac{dv}{dx} = e^{ax}. Then du=dx and v=(1/a)e^{ax}. Substituting this into the integration by parts formula, we obtain\\begin{align*}\n\\int x e^{ax} dx &= u v - \\int v du\\nonumber\\\\\n                &=x\\left( \\frac{1}{a}e^{ax}\\right) -\\int\\frac{1}{a}e^{ax}dx\\nonumber\\\\\n                &=\\frac{1}{a}xe^{ax}-\\frac{1}{a^2}e^{ax}+c\\nonumber\n\\end{align*}\n\n\n\nExercise 12.4 (Integration by Parts II) \nIntegrate\n\n\\int x^n e^{ax} dx\n\nIntegrate\n\n\\int x^3 e^{-x^2} dx"
  },
  {
    "objectID": "34_intergrals.html#answers-to-examples-and-exercises",
    "href": "34_intergrals.html#answers-to-examples-and-exercises",
    "title": "12  Integral Calculus",
    "section": "Answers to Examples and Exercises",
    "text": "Answers to Examples and Exercises\nExercise 10.1\nSolution.\n\nf^\\prime(x)= 0\nf^\\prime(x)= 1\nf^\\prime(x)= 2x^3\nf\\prime(x)= 3x^2\nf\\prime(x)= -2x^{-3}\nf\\prime(x)= 14x^6\nf\\prime(x) = 4x^3 - 3x^2 + 2x -1\nf\\prime(x) = 5x^4 + 3x^2 - 2x\nf\\prime(x) = 6x + \\frac{2}{3}x^{\\frac{-2}{3}}\nf\\prime(x)= \\frac{-4x}{x^4 - 2x^2 + 1}\n\nExample 10.3\n\nSolution. For convenience, define f(z) = z^6 and z = g(x) = 3x^2+5x-7. Then, y=f[g(x)] and\n\\begin{align*}\n\\frac{d}{dx}y&= f^\\prime(z) g^\\prime(x) \\\\\n&= 6(3x^2+5x-7)^5 (6x + 5)\n\\end{align*}\n\nExample 10.4\nSolution.\n\nLet u(x)=-3x. Then u^\\prime(x)=-3 and f^\\prime(x)=-3e^{-3x}.\nLet u(x)=x^2. Then u^\\prime(x)=2x and f^\\prime(x)=2xe^{x^2}.\n\nExample 10.5\nSolution.\n\nLet u(x)=x^2+9. Then u^\\prime(x)=2x and \\frac{dy}{dx}= \\frac{u^\\prime(x)}{u(x)} = \\frac{2x}{(x^2+9)}\n\nLet u(x)=\\ln x. Then u^\\prime(x)=1/x and \\frac{dy}{dx} = \\frac{1}{(x\\ln x)}.\nUse the generalized power rule. \\frac{dy}{dx} = \\frac{(2 \\ln x)}{x}\n\nWe know that \\ln e^x=x and that dx/dx=1, but we can double check. Let u(x)=e^x. Then u^\\prime(x)=e^x and \\frac{dy}{dx} = \\frac{u^\\prime(x)}{u(x)} = \\frac{e^x}{e^x} = 1.\n\n\nExample 12.3\n\nSolution. What is F(x)? From the power rule, recognize \\frac{d}{dx}x^3 = 3x^2 so\n\\begin{align*}\nF(x) &= x^3\\\\\n\\int\\limits_1^3 f(x) dx &= F(x = 3) - F(x  - 1)\\\\\n&= 3^3 - 1^3\\\\\n&=26\n\\end{align*}\n\nExample 12.4\n\nSolution. The problem here is the \\sqrt{x+1} term. However, if the integrand had \\sqrt{x} times some polynomial, then we’d be in business. Let’s try u=x+1. Then x=u-1 and dx=du. Substituting these into the above equation, we get\n\\begin{align*}\n            \\int x^2\\sqrt{x+1}dx&= \\int (u-1)^2\\sqrt{u}du\\\\\n            &= \\int (u^2-2u+1)u^{1/2}du\\\\\n            &= \\int (u^{5/2}-2u^{3/2}+u^{1/2})du\n\\end{align*}\nWe can easily integrate this, since it is just a polynomial. Doing so and substituting u=x+1 back in, we get \\int x^2\\sqrt{x+1}dx=2(x+1)^{3/2}\\left[\\frac{1}{7}(x+1)^2 -\n\\frac{2}{5}(x+1)+\\frac{1}{3}\\right]+c\n\nExample 12.5\n\nSolution. When an expression is raised to a power, it is often helpful to use this expression as the basis for a substitution. So, let u=1+e^{2x}. Then du=2e^{2x}dx and we can set 5e^{2x}dx=5du/2. Additionally, u=2 when x=0 and u=1+e^2 when x=1. Substituting all of this in, we get\n\\begin{align*}\n\\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx\n            &= \\frac{5}{2}\\int\\limits_2^{1+e^2}\\frac{du}{u^{1/3}}\\\\\n            &= \\frac{5}{2}\\int\\limits_2^{1+e^2} u^{-1/3}du\\\\\n            &= \\left. \\frac{15}{4} u^{2/3} \\right|_2^{1+e^2}\\\\\n            &= 9.53\n\\end{align*}\n\nExercise 12.4\nSolution.\n\n\\int x^n e^{ax} dx\n\nAs in the first problem, let\nu=x^n, dv=e^{ax}dx\nThen du=n x^{n-1}dx and v=(1/a)e^{ax}.\nSubstituting these into the integration by parts formula gives \\begin{align*}\n    \\int x^n e^{ax} dx &= u v - \\int v du\\nonumber\\\\\n    &=x^n\\left( \\frac{1}{a}e^{ax}\\right) - \\int\\frac{1}{a}e^{ax} n x^{n-1} dx\\nonumber\\\\\n    &=\\frac{1}{a}x^n e^{ax} - \\frac{n}{a}\\int x^{n-1}e^{ax}dx\\nonumber\n\\end{align*}\nNotice that we now have an integral similar to the previous one, but with x^{n-1} instead of x^n.\nFor a given n, we would repeat the integration by parts procedure until the integrand was directly integratable — e.g., when the integral became \\int e^{ax}dx.\n\n\\int x^3 e^{-x^2} dx\n\nWe could, as before, choose u=x^3 and dv=e^{-x^2}dx. But we can’t then find v — i.e., integrating e^{-x^2}dx isn’t possible. Instead, notice that \\frac{d}{dx}e^{-x^2} = -2xe^{-x^2}, which can be factored out of the original integrand \\int x^3 e^{-x^2} dx = \\int x^2 (xe^{-x^2})dx.\nWe can then let u=x^2 and dv=x e^{-x^2}dx. Thedu=2x dx and v=-\\frac{1}{2}e^{-x^2}. Substituting these in, we have \\begin{align*}\n    \\int x^3 e^{-x^2} dx &= u v - \\int v du\\nonumber\\\\\n    &= x^2 \\left( -\\frac{1}{2}e^{-x^2}\\right) -\\int \\left(-\\frac{1}{2}e^{-x^2}\\right)2x dx\\nonumber\\\\\n    &= -\\frac{1}{2}x^2 e^{-x^2}+\\int x e^{-x^2}dx\\nonumber\\\\\n    &= -\\frac{1}{2}x^2 e^{-x^2}-\\frac{1}{2}e^{-x^2}+c\\nonumber\n\\end{align*}"
  },
  {
    "objectID": "41_probability.html",
    "href": "41_probability.html",
    "title": "13  Probability Theory",
    "section": "",
    "text": "Probability and Inferences are mirror images of each other, and both are integral to social science. Probability quantifies uncertainty, which is important because many things in the social world are at first uncertain. Inference is then the study of how to learn about facts you don’t observe from facts you do observe."
  },
  {
    "objectID": "41_probability.html#counting-rules",
    "href": "41_probability.html#counting-rules",
    "title": "13  Probability Theory",
    "section": "\n13.1 Counting Rules",
    "text": "13.1 Counting Rules\nProbability in high school is usually really about combinatorics: the probability of event A is the number of ways in which A can occur divided by the number of all other possibilities. This is a very simplified version of probability, which we can call the “counting definition of probability”, essentially because each possible event to count is often equally likely and discrete. But it is still good to review the underlying rules here.\nFundamental Theorem of Counting: If an object has j different characteristics that are independent of each other, and each characteristic i has n_i ways of being expressed, then there are \\prod_{i = 1}^j n_i possible unique objects.\n\nExample 13.1 Suppose we are given a stack of cards. Cards can be either red or black and can take on any of 13 values. There is only one of each color-number combination. In this case,\n\nj =\nn_{\\text{color}} =\nn_{\\text{number}} =\nNumber of Outcomes =\n\n\nWe often need to count the number of ways to choose a subset from some set of possibilities. The number of outcomes depends on two characteristics of the process: does the order matter and is replacement allowed?\nIt is useful to think of any problem concretely, e.g. through a sampling table: If there are n objects which are numbered 1 to n and we select k < n of them, how many different outcomes are possible?\nIf the order in which a given object is selected matters, selecting 4 numbered objects in the following order (1, 3, 7, 2) and selecting the same four objects but in a different order such as (7, 2, 1, 3) will be counted as different outcomes.\nIf replacement is allowed, there are always the same n objects to select from. However, if replacement is not allowed, there is always one less option than the previous round when making a selection. For example, if replacement is not allowed and I am selecting 3 elements from the following set {1, 2, 3, 4, 5, 6}, I will have 6 options at first, 5 options as I make my second selection, and 4 options as I make my third.\n\nSo if order matters AND we are sampling with replacement, the number of different outcomes is n^k.\nIf order matters AND we are sampling without replacement, the number of different outcomes is n(n-1)(n-2)...(n-k+1)=\\frac{n!}{(n-k)!}.\nIf order doesn’t matter AND we are sampling without replacement, the number of different outcomes is \\binom{n}{k} = \\frac{n!}{(n-k)!k!}.\n\nExpression \\binom{n}{k} is read as “n choose k” and denotes \\frac{n!}{(n-k)!k!}. Also, note that 0! = 1.\n\nExample 13.2 (Counting) There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there?\n\nOrdered, with replacement =\nOrdered, without replacement =\nUnordered, without replacement =\n\n\n\nExercise 13.1 (Counting) \nFour cards are selected from a deck of 52 cards. Once a card has been drawn, it is not reshuffled back into the deck. Moreover, we care only about the complete hand that we get (i.e. we care about the set of selected cards, not the sequence in which it was drawn). How many possible outcomes are there?"
  },
  {
    "objectID": "41_probability.html#setoper",
    "href": "41_probability.html#setoper",
    "title": "13  Probability Theory",
    "section": "\n13.2 Sets",
    "text": "13.2 Sets\nProbability is about quantifying the uncertainty of events. Sets (set theory) are the mathematical way we choose to formalize those events. Events are not inherently numerical: the onset of war or the stock market crashing is not inherently a number. Sets can define such events, and we wrap math around so that we have a transparent language to communicate about those events. Measure theory might sound mysterious or hard, but it is also just a mathematical way to quantify things like length, volume, and mass. Probability can be thought of as a particular application of measure theory where we want to quantify the measure of a set.\nSet : A set is any well defined collection of elements. If x is an element of S, x \\in S.\nSample Space (S): A set or collection of all possible outcomes from some process. Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable).\nExamples:\n\nDiscrete: the numbers on a die, whether a vote cast is republican or democrat.\nContinuous: GNP, arms spending, age.\n\nEvent: Any collection of possible outcomes of an experiment. Any subset of the full set of possibilities, including the full set itself. Event A \\subset S.\nEmpty Set: a set with no elements. S = \\{\\}. It is denoted by the symbol \\emptyset.\nSet operations:\n\n\nUnion: The union of two sets A and B, A \\cup B, is the set containing all of the elements in A or B. A_1 \\cup A_2  \\cup \\cdots \\cup A_n = \\bigcup_{i=1}^n A_i\n\n\nIntersection: The intersection of sets A and B, A \\cap B, is the set containing all of the elements in both A and B. A_1 \\cap A_2  \\cap \\cdots \\cap A_n = \\bigcap_{i=1}^n A_i\n\n\nComplement: If set A is a subset of S, then the complement of A, denoted A^C, is the set containing all of the elements in S that are not in A.\n\nProperties of set operations:\n\n\nCommutative: A \\cup B = B \\cup A; A \\cap B = B \\cap A\n\n\nAssociative: A \\cup (B \\cup C) = (A \\cup B) \\cup C; A \\cap (B \\cap C) = (A \\cap B) \\cap C\n\n\nDistributive: A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C); A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\n\n\nde Morgan’s laws: (A \\cup B)^C = A^C \\cap B^C; (A \\cap B)^C = A^C \\cup B^C\n\n\nDisjointness: Sets are disjoint when they do not intersect, such that A \\cap B = \\emptyset. A collection of sets is pairwise disjoint (mutually exclusive) if, for all i \\neq j, A_i \\cap A_j = \\emptyset. A collection of sets form a partition of set S if they are pairwise disjoint and they cover set S, such that \\bigcup_{i = 1}^k A_i = S.\n\n\nExample 13.3 (Sets) Let set A be {1, 2, 3, 4}, B be {3, 4, 5, 6}, and C be {5, 6, 7, 8}. Sets A, B, and C are all subsets of the sample space S which is {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nWrite out the following sets:\n\nA \\cup B\nC \\cap B\nB^c\nA \\cap (B \\cup C)\n\n\n\nExercise 13.2 Suppose you had a pair of four-sided dice. You sum the results from a single toss.\nWhat is the set of possible outcomes (i.e. the sample space)?\nConsider subsets A {2, 8} and B {2,3,7} of the sample space you found. What is\n\nA^c\n(A \\cup B)^c"
  },
  {
    "objectID": "41_probability.html#probdef",
    "href": "41_probability.html#probdef",
    "title": "13  Probability Theory",
    "section": "\n13.3 Probability",
    "text": "13.3 Probability\n\n\n\n\nFigure 13.1: Probablity as a Measure1\n\n\n\n\nProbability Definitions: Formal and Informal\nMany things in the world are uncertain. In everyday speech, we say that we are uncertain about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules (Figure 13.1). A different model of uncertainty would, of course, have a set of rules different from anything we discuss here. Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty.\nProbability Distribution Function: a mapping of each event in the sample space S to the real numbers that satisfy the following three axioms (also called Kolmogorov’s Axioms).\nFormally,\n\nDefinition 13.1 (Probability) \nProbability is a function that maps events to a real number, obeying the axioms of probability.\n\nThe axioms of probability make sure that the separate events add up in terms of probability, and – for standardization purposes – that they add up to 1.\n\n\nDefinition 13.2 (Axioms of Probability) \nFor any event A, P(A)\\ge 0.\nP(S)=1\nThe Countable Additivity Axiom: For any sequence of disjoint (mutually exclusive) events A_1,A_2,\\ldots (of which there may be infinitely many), P\\left( \\bigcup\\limits_{i=1}^k\nA_i\\right)=\\sum\\limits_{i=1}^k P(A_i)\n\n\nThe last axiom is an extension of a union to infinite sets. When there are only two events in the space, it boils down to:\n\\begin{align*}\nP(A_1 \\cup A_2) = P(A_1) + P(A_2) \\quad\\text{for disjoint } A_1, A_2\n\\end{align*}\n\nProbability Operations\nUsing these three axioms, we can define all of the common rules of probability.\n\n\nP(\\emptyset)=0\nFor any event A, 0\\le P(A) \\le 1\n\nP({A}^C)=1-P(A)\nIf A\\subset B (A is a subset of B), then P(A)\\le P(B)\n\nFor any two events A and B, P(A\\cup B)=P(A)+P(B)-P(A\\cap B)\n\nBoole’s Inequality: For any sequence of n events (which need not be disjoint) A_1,A_2,\\ldots,A_n, then P\\left( \\bigcup\\limits_{i=1}^n A_i\\right) \\leq \\sum\\limits_{i=1}^n P(A_i)\n\n\n\n\nExample 13.4 Assume we have an evenly-balanced, six-sided die.\nThen,\n\nSample space S =\nP(1)=\\cdots=P(6)=\nP(\\emptyset)=P(7)=\nP\\left( \\{ 1, 3, 5 \\} \\right)=\nP\\left( \\{ 1, 2 \\}^C \\right)= P\\left( \\{ 3, 4, 5, 6 \\}\\right)=\nLet A=\\{ 1,2,3,4,5 \\}\\subset S. Then P(A)=5/6<P(S)=\n\nLet A=\\{ 1, 2, 3 \\} and B=\\{ 2, 4, 6 \\}. Then A\\cup B? A\\cap B? P(A \\cup B)?\n\n\n\nExercise 13.3 Suppose you had a pair of four-sided dice. You sum the results from a single toss. Let us call this sum, or the outcome, X.\n\nWhat is P(X = 5), P(X = 3), P(X = 6)?\nWhat is P(X=5 \\cup X = 3)^C?"
  },
  {
    "objectID": "41_probability.html#conditional-probability",
    "href": "41_probability.html#conditional-probability",
    "title": "13  Probability Theory",
    "section": "\n13.4 Conditional Probability",
    "text": "13.4 Conditional Probability\nConditional Probability: The conditional probability P(A|B) of an event A is the probability of A, given that another event B has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event. It is calculated as\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\nNote that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability.\n\nExample 13.5 (Conditional Probability) Assume A and B occur with the following frequencies: \\quad\n\n\n\nA\nA^c\n\n\n\nB\nn_{ab}\nn_{a^cb}\n\n\nB^C\nn_{ab^c}\nn_{(ab)^c}\n\n\n\nand let n_{ab}+n_{a^Cb}+n_{ab^C}+n_{(ab)^C}=N. Then\n\nP(A)=\nP(B)=\nP(A\\cap B)=\nP(A|B)= \\frac{P(A\\cap B)}{P(B)}=\nP(B|A)= \\frac{P(A\\cap B)}{P(A)}=\n\n\n\nExample 13.6 (Conditional Probability 2) \nA six-sided die is rolled. What is the probability of a 1, given the outcome is an odd number?\n\nYou could rearrange the fraction to highlight how a joint probability could be expressed as the product of a conditional probability.\n\nDefinition 13.3 (Multiplicative Law of Probability) The probability of the intersection of two events A and B is\nP(A\\cap B)=P(A)P(B|A)=P(B)P(A|B)\nwhich follows directly from the definition of conditional probability. More generally,\n\\begin{align*}\nP(A_1\\cap \\cdots\\cap A_k) = &P(A_k| A_{k-1}\\cap \\cdots \\cap A_1) \\\\\n\\times &P(A_{k-1}|A_{k-2}\\cap \\cdots A_1) \\\\\n\\vdots & \\\\\n\\times &P(A_2|A_1) \\\\\n\\times &P(A_1)\n\\end{align*}\nSometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate P(A) directly.\n\n\nDefinition 13.4 (Law of Total Probability) Let S be the sample space of some experiment and let the disjoint k events B_1,\\ldots,B_k partition S, such that P(B_1\\cup ... \\cup B_k) = P(S) = 1. If A is some other event in S, then the events A\\cap B_1, A\\cap B_2, \\ldots, A\\cap B_k will form a partition of A and we can write A as A=(A\\cap B_1)\\cup\\cdots\\cup (A\\cap B_k).\nSince the k events are disjoint,\n\\begin{align*}\nP(A)&=\\sum\\limits_{i=1}^k P(A \\cap B_i)\\\\\n    &=\\sum\\limits_{i=1}^k P(B_i)P(A|B_i)\n\\end{align*}"
  },
  {
    "objectID": "41_probability.html#bayes-rule",
    "href": "41_probability.html#bayes-rule",
    "title": "13  Probability Theory",
    "section": "\n13.5 Bayes Rule",
    "text": "13.5 Bayes Rule\nBayes Rule: Assume that events B_1,\\ldots,B_k form a partition of the space S. Then by the Law of Total Probability\nP(B_j|A)= \\frac{P(A \\cap B_j)} {P(A)} = \\frac{P(B_j) P(A|B_j)}{\\sum\\limits_{i=1}^k P(B_i)P(A|B_i)}\nIf there are only two states of B, then this is just\nP(B_1|A)=\\frac{P(B_1)P(A|B_1)} {P(B_1)P(A|B_1)+P(B_2)P(A|B_2)}\nBayes’ rule determines the posterior probability of a state P(B_j|A) by calculating the probability P(A \\cap B_j) that both the event A and the state B_j will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all B_i). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc. The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position.\nPrior and Posterior Probabilities: Above, P(B_1) is often called the prior probability, since it’s the probability of B_1 before anything else is known. P(B_1|A) is called the posterior probability, since it’s the probability after other information is taken into account.\n\nExample 13.7 (Bayes’ Rule) \nIn a given town, 40% of the voters are Democrat and 60% are Republican. The president’s budget is supported by 50% of the Democrats and 90% of the Republicans. If a randomly (equally likely) selected voter is found to support the president’s budget, what is the probability that they are a Democrat?\n\n\nExercise 13.4 (Conditional Probability) \nAssume that 2% of the population of the U.S. are members of some extremist militia group. We develop a survey that positively classifies someone as being a member of a militia group given that they are a member 95% of the time and negatively classifies someone as not being a member of a militia group given that they are not a member 97% of the time. What is the probability that someone positively classified as being a member of a militia group is actually a militia member?"
  },
  {
    "objectID": "41_probability.html#independence",
    "href": "41_probability.html#independence",
    "title": "13  Probability Theory",
    "section": "\n13.6 Independence",
    "text": "13.6 Independence\n\nDefinition 13.5 (Independence) \nIf the occurrence or nonoccurrence of either events A and B have no effect on the occurrence or nonoccurrence of the other, then A and B are independent.\n\nIf A and B are independent, then\n\n\nP(A|B)=P(A)\nP(B|A)=P(B)\nP(A\\cap B)=P(A)P(B)\nMore generally than the above, P(\\bigcap_{i=1}^k A_i) = \\prod_{i = 1}^K P(A_i)\n\n\n\nAre mutually exclusive events independent of each other?\nNo. If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn’t have occurred. Because of this, A and B aren’t independent.\nPairwise Independence: A set of more than two events A_1, A_2, \\dots, A_k is pairwise independent if P(A_i\\cap A_j)=P(A_i)P(A_j), \\forall i\\neq j. Note that this does not necessarily imply joint independence.\nConditional Independence: If A and B are independent once you know the occurrence of a third event C, then A and B are conditionally independent (conditional on C):\n\nP(A|B \\cap C)=P(A|C)\nP(B|A \\cap C)=P(B|C)\nP(A\\cap B|C)=P(A|C)P(B|C)\n\nJust because two events are conditionally independent does not mean that they are independent. Actually it is hard to think of real-world things that are “unconditionally” independent. That’s why it’s always important to ask about a finding: What was it conditioned on? For example, suppose that a graduate school admission decisions are done by only one professor, who picks a group of 50 bright students and flips a coin for each student to generate a class of about 25 students. Then the the probability that two students get accepted are conditionally independent, because they are determined by two separate coin tosses. However, this does not mean that their admittance is not completely independent. Knowing that student A got in gives us information about whether student B got in, if we think that the professor originally picked her pool of 50 students by merit.\nPerhaps more counter-intuitively: If two events are already independent, then it might seem that no amount of “conditioning” will make them dependent. But this is not always so. For example2, suppose I only get a call from two people, Alice and Bob. Let A be the event that Alice calls, and B be the event that Bob calls. Alice and Bob do not communicate, so P(A \\mid B) = P(A). But now let C be the event that your phone rings. For conditional independence to hold here, then P(A \\mid C) must be equal to P(A \\mid B \\cap C). But this is not true – A \\mid C may or may not be true, but P(A \\mid B \\cap C) certainly is true."
  },
  {
    "objectID": "41_probability.html#random-variables",
    "href": "41_probability.html#random-variables",
    "title": "13  Probability Theory",
    "section": "\n13.7 Random Variables",
    "text": "13.7 Random Variables\nMost questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantitatively, we need a way of mapping events to numbers. A random variable does exactly that.\n\n\n\n\nFigure 13.2: The Random Variable as a Real-Valued Function\n\n\n\n\n\nDefinition 13.6 (Random Variable) \nA random variable is a measurable function X that maps from the sample space S to the set of real numbers R. It assigns a real number to every outcome s \\in S.\n\nFigure 13.2 shows a image of the function. It might seem strange to define a random variable as a function – which is neither random nor variable. The randomness comes from the realization of an event from the sample space s.\nRandomness means that the outcome of some experiment is not deterministic, i.e. there is some probability (0 < P(A) < 1) that the event will occur.\nThe support of a random variable is all values for which there is a positive probability of occurrence.\nExample: Flip a fair coin two times. What is the sample space?\nA random variable must map events to the real line. For example, let a random variable X be the number of heads. The event (H, H) gets mapped to 2 X(s) = 2, and the events \\{(H, T), (T, H)\\} gets mapped to 1 (X(s) = 1), the event (T, T) gets mapped to 0 (X(s) = 0).\nWhat are other possible random variables?"
  },
  {
    "objectID": "41_probability.html#distributions",
    "href": "41_probability.html#distributions",
    "title": "13  Probability Theory",
    "section": "\n13.8 Distributions",
    "text": "13.8 Distributions\nWe now have two main concepts in this section – probability and random variables. Given a sample space S and the same experiment, both probability and random variables take events as their inputs. But they output different things (probabilities measure the “size” of events, random variables give a number in a way that the analyst chose to define the random variable). How do the two concepts relate?\nThe concept of distributions is the natural bridge between these two concepts.\n\nDefinition 13.7 (Distribution of a random variable) \nA distribution of a random variable is a function that specifies the probabilities of all events associated with that random variable. There are several types of distributions: A probability mass function for a discrete random variable and probability density function for a continuous random variable.\n\nNotice how the definition of distributions combines two ideas of random variables and probabilities of events. First, the distribution considers a random variable, call it X. X can take a number of possible numeric values.\n\nExample 13.8 \nConsider three binary outcomes, one for each patient recovering from a disease: R_i denotes the event in which patient i (i = 1, 2, 3) recovers from a disease. R_1, R_2, and R_3. How would we represent the total number of people who end up recovering from the disease?\n\n\nSolution. Define the random variable X be the total number of people (out of three) who recover from the disease. Random variables are functions, that take as an input a set of events (in the sample space S) and deterministically assigns them to a number of the analyst’s choice.\nRecall that with each of these numerical values there is a class of events. In the previous example,\n\nFor X = 3 there is one outcome (R_1, R_2, R_3)\nFor X = 1 there are multiple \\{(R_1, R_2^c, R_3^c), (R_1^c, R_2, R_3^c), (R_1^c, R_2^c, R_3), \\}\n\n\nNow, the thing to notice here is that each of these events naturally come with a probability associated with them. That is, P(R_1, R_2, R_3) is a number from 0 to 1, as is P(R_1, R_2^c, R_3^c). These all have probabilities because they are in the sample space S. The function that tells us these probabilities that are associated with a numerical value of a random variable is called a distribution.\nIn other words, a random variable X induces a probability distribution P (sometimes written P_X to emphasize that the probability density is about the r.v. X)\n\nDiscrete Random Variables\nThe formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete, and continuous random variables when they are continuous.\n\nDefinition 13.8 (Discrete Random Variable) \nX is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples: number of wars per year, heads or tails.\n\nThe distribution of a discrete r.v. is a PMF:\n\nDefinition 13.9 (Probability Mass Function) For a discrete random variable X, the probability mass function (Also referred to simply as the “probability distribution.”) (PMF), p(x)=P(X=x), assigns probabilities to a countable number of distinct x values such that\n\n0\\le p(x)\\le 1\n\\sum\\limits_y p(x)=1\n\n\n\nExample 13.9 \nFor a fair six-sided die, there is an equal probability of rolling any number. Since there are six sides, the probability mass function is then p(y)=1/6 for y=1,\\ldots,6, 0 otherwise.\n\nIn a discrete random variable, cumulative distribution function (Also referred to simply as the “cumulative distribution” or previously as the “distribution function”), F(x) or P(X\\le x), is the probability that X is less than or equal to some value x, or P(X\\le x)=\\sum\\limits_{i\\le x} p(i)\nProperties a CDF must satisfy:\n\n\nF(x) is non-decreasing in x.\n\n\\lim\\limits_{x \\to -\\infty} F(x) = 0 and \\lim\\limits_{x \\to \\infty} F(x) = 1\n\n\nF(x) is right-continuous.\n\nNote that P(X > x) = 1 - P(X \\le x).\n\nExample 13.10 For a fair die with its value as Y, What are the following?\n\nP(Y\\le 1)\nP(Y\\le 3)\nP(Y\\le 6)\n\n\nContinuous Random Variables\nWe also have a similar definition for continuous random variables.\n\nDefinition 13.10 (Continuous Random Variable) \nX is a continuous random variable if there exists a nonnegative function f(x) defined for all real x\\in (-\\infty,\\infty), such that for any interval A, P(X\\in A)=\\int\\limits_A f(x)dx. Examples: age, income, GNP, temperature.\n\n\nDefinition 13.11 (Probability Density Function) The function f above is called the probability density function (pdf) of X and must satisfy\nf(x)\\ge 0\n\\int\\limits_{-\\infty}^\\infty f(x)dx=1\nNote also that P(X = x)=0 — i.e., the probability of any point y is zero.\n\nFor both discrete and continuous random variables, we have a unifying concept of another measure: the cumulative distribution:\n\nDefinition 13.12 (Cumulative Distribution Function) \nBecause the probability that a continuous random variable will assume any particular value is zero, we can only make statements about the probability of a continuous random variable being within an interval. The cumulative distribution gives the probability that Y lies on the interval (-\\infty,y) and is defined as F(x)=P(X\\le x)=\\int\\limits_{-\\infty}^x f(s)ds. Note that F(x) has similar properties with continuous distributions as it does with discrete - non-decreasing, continuous (not just right-continuous), and \\lim\\limits_{x \\to -\\infty} F(x) = 0 and \\lim\\limits_{x \\to \\infty} F(x) = 1.\n\nWe can also make statements about the probability of Y falling in an interval a\\le y\\le b.\nP(a\\le x\\le b)=\\int\\limits_a^b f(x)dx\nThe PDF and CDF are linked by the integral: The CDF of the integral of the PDF: f(x) = F'(x)=\\frac{dF(x)}{dx}\n\nExample 13.11 \nFor f(y)=1, \\quad 0<y<1, find: (1) The CDF F(y) and (2) The probability P(0.5<y<0.75)."
  },
  {
    "objectID": "41_probability.html#answers-to-examples-and-exercises",
    "href": "41_probability.html#answers-to-examples-and-exercises",
    "title": "13  Probability Theory",
    "section": "Answers to Examples and Exercises",
    "text": "Answers to Examples and Exercises\nAnswer to Example 13.2:\n\n5 \\times 5 \\times 5 = 125\n5 \\times 4 \\times 3 = 60\n\\binom{5}{3} = \\frac{5!}{(5-3)!3!} = \\frac{5 \\times 4}{2 \\times 1} = 10\n\nAnswer to Exercise 13.1:\n\n\\binom{52}{4} = \\frac{52!}{(52-4)!4!} = 270725\n\nAnswer to Example 13.3:\n\n{1, 2, 3, 4, 5, 6}\n{5, 6}\n{1, 2, 7, 8, 9, 10}\n{3, 4}\n\nAnswer to Exercise 13.2:\nSample Space: {2, 3, 4, 5, 6, 7, 8}\n\n{3, 4, 5, 6, 7}\n{4, 5, 6}\n\nAnswer to Example 13.4:\n\n{1, 2, 3, 4, 5, 6}\n\\frac{1}{6}\n0\n\\frac{1}{2}\n\\frac{4}{6} = \\frac{2}{3}\n1\nA\\cup B=\\{1, 2, 3, 4, 6\\}, A\\cap B=\\{2\\}, \\frac{5}{6}\n\nAnswer to Exercise 13.3:\n\nP(X = 5) = \\frac{4}{16}, P(X = 3) = \\frac{2}{16}, P(X = 6) = \\frac{3}{16}\nWhat is P(X=5 \\cup X = 3)^C = \\frac{10}{16}?\n\nAnswer to Example 13.5:\n\n\\frac{n_{ab} + n_{ab^c}}{N}\n\\frac{n_{ab} + n_{a^cb}}{N}\n\\frac{n_{ab}}{N}\n\\frac{\\frac{n_{ab}}{N}}{\\frac{n_{ab} + n_{a^cb}}{N}} = \\frac{n_{ab}}{n_{ab} + n_{a^cb}}\n\\frac{\\frac{n_{ab}}{N}}{\\frac{n_{ab} + n_{ab^c}}{N}} = \\frac{n_{ab}}{n_{ab} + n_{ab^c}}\n\nAnswer to Example 13.6:\nP(1|Odd) = \\frac{P(1 \\cap Odd)}{P(Odd)} = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\nAnswer to Example 13.7:\nWe are given that\nP(D) = .4, P(D^c) = .6, P(S|D) = .5, P(S|D^c) = .9\nUsing this, Bayes’ Law and the Law of Total Probability, we know:\nP(D|S) = \\frac{P(D)P(S|D)}{P(D)P(S|D) + P(D^c)P(S|D^c)}\nP(D|S) = \\frac{.4 \\times .5}{.4 \\times .5 + .6 \\times .9 } = .27\nAnswer to Exercise 13.4:\nWe are given that\nP(M) = .02, P(C|M) = .95, P(C^c|M^c) = .97\nP(M|C) = \\frac{P(C|M)P(M)}{P(C)}\n= \\frac{P(C|M)P(M)}{P(C|M)P(M) + P(C|M^c)P(M^c)}\n= \\frac{P(C|M)P(M)}{P(C|M)P(M) + [1-P(C^c|M^c)]P(M^c)}\n = \\frac{.95 \\times .02}{.95 \\times .02 + .03 \\times .98} = .38"
  },
  {
    "objectID": "42_distribution.html",
    "href": "42_distribution.html",
    "title": "14  Summarizing Distributions",
    "section": "",
    "text": "We often want to summarize some characteristics of the distribution of a random variable. The most important summary is the expectation (or expected value, or mean), in which the possible values of a random variable are weighted by their probabilities.\n\nDefinition 14.1 (Expectation of a Discrete Random Variable) The expected value of a discrete random variable Y is\nE(Y)=\\sum\\limits_{y} y P(Y=y)= \\sum\\limits_{y} y p(y)\nIn words, it is the weighted average of all possible values of Y, weighted by the probability that y occurs. It is not necessarily the number we would expect Y to take on, but the average value of Y after a large number of repetitions of an experiment.\n\n\nExample 14.1 \nWhat is the expectation of a fair, six-sided die?\n\nExpectation of a Continuous Random Variable: The expected value of a continuous random variable is similar in concept to that of the discrete random variable, except that instead of summing using probabilities as weights, we integrate using the density to weight. Hence, the expected value of the continuous variable Y is defined by\nE(Y)=\\int\\limits_{y} y f(y) dy\n\nExample 14.2 (Expectation of a Continuous Random Variable) \nFind E(Y) for f(y)=\\frac{1}{1.5}, \\quad 0<y<1.5.\n\n\nRemember: An Expected Value is a type of weighted average. We can extend this to composite functions. For random variable Y,\nIf Y is Discrete with PMF p(y),\nE[g(Y)]=\\sum\\limits_y g(y)p(y)\nIf Y is Continuous with PDF f(y),\nE[g(Y)]=\\int\\limits_{-\\infty}^\\infty g(y)f(y)dy\n\nDealing with Expectations is easier when the thing inside is a sum. The intuition behind this that Expectation is an integral, which is a type of sum.\n\n\nExpectation of a constant is a constant E(c)=c\n\nConstants come out E(c g(Y))= c E(g(Y))\n\nExpectation is Linear E(g(Y_1) + \\cdots + g(Y_n))=E(g(Y_1)) +\\cdots+E(g(Y_n)), regardless of independence\nExpected Value of Expected Values: E(E(Y)) = E(Y) (because the expected value of a random variable is a constant)\n\nFinally, if X and Y are independent, even products are easy:\nX \\;\\; \\mathrm{ and } \\;\\; Y \\mathrm{are independent } \\;\\Rightarrow\\; E(XY) = E(X)E(Y)\n\nConditional Expectation: With joint distributions, we are often interested in the expected value of a variable Y if we could hold the other variable X fixed. This is the conditional expectation of Y given X = x:\n\n\nY discrete: E(Y|X = x) = \\sum_y yp_{Y|X}(y|x)\n\n\nY continuous: E(Y|X = x) = \\int_y yf_{Y|X}(y|x)dy\n\n\nThe conditional expectation is often used for prediction when one knows the value of X but not Y"
  },
  {
    "objectID": "42_distribution.html#variance-and-covariance",
    "href": "42_distribution.html#variance-and-covariance",
    "title": "14  Summarizing Distributions",
    "section": "\n14.2 Variance and Covariance",
    "text": "14.2 Variance and Covariance\nWe can also look at other summaries of the distribution, which build on the idea of taking expectations. Variance tells us about the “spread” of the distribution; it is the expected value of the squared deviations from the mean of the distribution. The standard deviation is simply the square root of the variance.\n\nDefinition 14.2 (Variance) The Variance of a Random Variable Y is\n\\text{Var}(Y) = E[(Y - E(Y))^2] =  E(Y^2)-[E(Y)]^2\nThe Standard Deviation is the square root of the variance :\nSD(Y) = \\sigma_Y= \\sqrt{\\text{Var}(Y)}\n\n\nExample 14.3 Given the following PMF:\nf(x) = \\begin{cases}\n    \\frac{3!}{x!(3-x)!}(\\frac{1}{2})^3 \\quad x = 0,1,2,3\\\\\n      0 \\quad otherwise\n  \\end{cases}\nWhat is \\text{Var}(x)?\nHint: First calculate E(X) and E(X^2)\n\n\nDefinition 14.3 (Covariance) The covariance measures the degree to which two random variables vary together; if the covariance between X and Y is positive, X tends to be larger than its mean when Y is larger than its mean.\n\\text{Cov}(X,Y) = E[(X - E(X))(Y - E(Y))] \nWe can also write this as\n\\begin{align*}\n\\text{Cov}(X,Y) &= E\\left(XY - XE(Y) - E(X)Y + E(X)E(Y)\\right)\\\\\n&= E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y)\\\\\n&= E(XY) - E(X)E(Y)\n\\end{align*}\n\nThe covariance of a variable with itself is the variance of that variable.\nThe Covariance is unfortunately hard to interpret in magnitude. The correlation is a standardized version of the covariance, and always ranges from -1 to 1.\n\nDefinition 14.4 (Correlation) The correlation coefficient is the covariance divided by the standard deviations of X and Y. It is a unitless measure and always takes on values in the interval [-1,1].\n\\text{Corr}(X, Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} = \\frac{\\text{Cov}(X,Y)}{SD(X)SD(Y)}\n\nProperties of Variance and Covariance:\n\n\n\\text{Var}(c) = 0\n\\text{Var}(cY) = c^2 \\text{Var}(Y)\n\\text{Cov}(Y,Y) = \\text{Var}(Y)\n\\text{Cov}(X,Y) = \\text{Cov}(Y,X)\n\\text{Cov}(aX,bY) = ab \\text{Cov}(X,Y)\n\\text{Cov}(X+a,Y) = \\text{Cov}(X,Y)\n\\text{Cov}(X+Z,Y+W) = \\text{Cov}(X,Y) + \\text{Cov}(X,W) + \\text{Cov}(Z,Y) + \\text{Cov}(Z,W)\n\\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\n\n\n\nExercise 14.1 (Expectation and Variance) Suppose we have a PMF with the following characteristics: \\begin{align*}\n  P(X = -2) &= \\frac{1}{5}\\\\\n  P(X = -1) &= \\frac{1}{6}\\\\\n  P(X = 0) &= \\frac{1}{5}\\\\\n  P(X = 1) &= \\frac{1}{15}\\\\\n  P(X = 2) &= \\frac{11}{30}\n\\end{align*}\n\nCalculate the expected value of X\n\nDefine the random variable Y = X^2.\n\nCalculate the expected value of Y. (Hint: It would help to derive the PMF of Y first in order to calculate the expected value of Y in a straightforward way)\nCalculate the variance of X.\n\n\n\nExercise 14.2 Given the following PDF:\nf(x) = \\begin{cases} \\frac{3}{10}(3x - x^2) \\quad 0 \\leq x \\leq 2\\\\ 0 \\quad \\mathrm{ otherwise} \\end{cases}\nFind the expectation and variance of X.\n\n\nExercise 14.3 Find the mean and standard deviation of random variable X. The PDF of this X is as follows:\nf(x) = \\begin{cases} \\frac{1}{4}x \\quad 0 \\leq x \\leq 2\\\\ \\frac{1}{4}(4 - x)  \\quad 2 \\leq x \\leq 4\\\\ 0 \\quad \\mathrm{ otherwise} \\end{cases}\nNext, calculate P(X < \\mu - \\sigma) Remember, \\mu is the mean and \\sigma is the standard deviation."
  },
  {
    "objectID": "42_distribution.html#common-distributions",
    "href": "42_distribution.html#common-distributions",
    "title": "14  Summarizing Distributions",
    "section": "\n14.3 Common Distributions",
    "text": "14.3 Common Distributions\nTwo discrete distributions used often are:\n\nDefinition 14.5 (Binomial Distribution) \nY is distributed binomial if it represents the number of “successes” observed in n independent, identical “trials,” where the probability of success in any trial is p and the probability of failure is q=1-p.\n\nFor any particular sequence of y successes and n-y failures, the probability of obtaining that sequence is p^y q^{n-y} (by the multiplicative law and independence). However, there are \\binom{n}{y}=\\frac{n!}{(n-y)!y!} ways of obtaining a sequence with y successes and n-y failures. So the binomial distribution is given by p(y)=\\binom{n}{y}p^y q^{n-y}, \\quad y=0,1,2,\\ldots,n with mean \\mu=E(Y)=np and variance \\sigma^2=\\text{Var}(Y)=npq.\n\nExample 14.4 \nRepublicans vote for Democrat-sponsored bills 2% of the time. What is the probability that out of 10 Republicans questioned, half voted for a particular Democrat-sponsored bill? What is the mean number of Republicans voting for Democrat-sponsored bills? The variance? 1. P(Y=5)= 2. E(Y)= 3. \\text{Var}(Y)=6\n\n\nDefinition 14.6 (Poisson Distribution) A random variable Y has a Poisson distribution if\nP(Y = y)=\\frac{\\lambda^y}{y!}e^{-\\lambda}, \\quad y=0,1,2,\\ldots, \\quad \\lambda>0\nThe Poisson has the unusual feature that its expectation equals its variance: E(Y)=\\text{Var}(Y)=\\lambda. The Poisson distribution is often used to model rare event counts: counts of the number of events that occur during some unit of time. \\lambda is often called the “arrival rate.”\n\n\nExample 14.5 \nBorder disputes occur between two countries through a Poisson Distribution, at a rate of 2 per month. What is the probability of 0, 2, and less than 5 disputes occurring in a month?\n\nTwo continuous distributions used often are:\n\nDefinition 14.7 (Uniform Distribution) \nA random variable Y has a continuous uniform distribution on the interval (\\alpha,\\beta) if its density is given by f(y)=\\frac{1}{\\beta-\\alpha}, \\quad \\alpha\\le y\\le \\beta The mean and variance of Y are E(Y)=\\frac{\\alpha+\\beta}{2} and \\text{Var}(Y)=\\frac{(\\beta-\\alpha)^2}{12}.\n\n\nExample 14.6 For Y uniformly distributed over (1,3), what are the following probabilities?\n\nP(Y=2)\nIts density evaluated at 2, or f(2)\n\nP(Y \\le 2)\nP(Y > 2)\n\n\n\nDefinition 14.8 (Normal Distribution) A random variable Y is normally distributed with mean E(Y)=\\mu and variance \\text{Var}(Y)=\\sigma^2 if its density is\nf(y)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}\n\nSee Figure Figure 14.1 are various Normal Distributions with the same \\mu = 1 and two versions of the variance.\n\n\n\n\nFigure 14.1: Normal Distribution Density"
  },
  {
    "objectID": "42_distribution.html#joint-distributions",
    "href": "42_distribution.html#joint-distributions",
    "title": "14  Summarizing Distributions",
    "section": "\n14.4 Joint Distributions",
    "text": "14.4 Joint Distributions\nOften, we are interested in two or more random variables defined on the same sample space. The distribution of these variables is called a joint distribution. Joint distributions can be made up of any combination of discrete and continuous random variables.\nJoint Probability Distribution: If both X and Y are random variable, their joint probability mass/density function assigns probabilities to each pair of outcomes\nDiscrete:\np(x, y) = P(X = x, Y = y)\nsuch that p(x,y) \\in [0,1] and \\sum\\sum p(x,y) = 1\nContinuous:\nf(x,y);P((X,Y) \\in A) = \\int\\!\\!\\!\\int_A f(x,y)dx dy \ns.t. f(x,y)\\ge 0 and\n\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f(x,y)dxdy = 1\nIf X and Y are independent, then P(X=x,Y=y) = P(X=x)P(Y=y) and f(x,y) = f(x)f(y)\nMarginal Probability Distribution: probability distribution of only one of the two variables (ignoring information about the other variable), we can obtain the marginal distribution by summing/integrating across the variable that we don’t care about:\n\nDiscrete: p_X(x) = \\sum_i p(x, y_i)\n\nContinuous: f_X(x) = \\int_{-\\infty}^\\infty f(x,y)dy\n\n\nConditional Probability Distribution: probability distribution for one variable, holding the other variable fixed. Recalling from the previous lecture that P(A|B)=\\frac{P(A\\cap B)}{P(B)}, we can write the conditional distribution as\n\nDiscrete: p_{Y|X}(y|x) = \\frac{p(x,y)}{p_X(x)}, \\quad p_X(x) > 0\n\nContinuous: f_{Y|X}(y|x) = \\frac{f(x,y)}{f_X(x)},\\quad f_X(x) > 0\n\n\n\nExercise 14.4 Suppose we are interested in the outcomes of flipping a coin and rolling a 6-sided die at the same time. The sample space for this process contains 12 elements: \\{(H, 1), (H, 2), (H, 3), (H, 4), (H, 5), (H, 6), (T, 1), (T, 2), (T, 3), (T, 4), (T, 5), (T, 6)\\} We can define two random variables X and Y such that X = 1 if heads and X = 0 if tails, while Y equals the number on the die.\nWe can then make statements about the joint distribution of X and Y. What are the following?\n\nP(X=x)\nP(Y=y)\nP(X=x, Y=y)\nP(X=x|Y=y)\nAre X and Y independent?"
  },
  {
    "objectID": "42_distribution.html#answers-to-examples-and-exercises",
    "href": "42_distribution.html#answers-to-examples-and-exercises",
    "title": "14  Summarizing Distributions",
    "section": "Answers to Examples and Exercises",
    "text": "Answers to Examples and Exercises\nAnswer to Example Example 14.1:\nE(Y)=7/2\nWe would never expect the result of a rolled die to be 7/2, but that would be the average over a large number of rolls of the die.\nAnswer to Example 14.2\n0.75\nAnswer to Example 14.3:\nE(X) = 0 \\times \\frac{1}{8} + 1 \\times \\frac{3}{8} + 2 \\times \\frac{3}{8} + 3 \\times \\frac{1}{8} = \\frac{3}{2}\nSince there is a 1 to 1 mapping from X to X^2: E(X^2) = 0 \\times \\frac{1}{8} + 1 \\times \\frac{3}{8} + 4 \\times \\frac{3}{8} + 9 \\times \\frac{1}{8} = \\frac{24}{8} = 3\n\\begin{align*}\n\\text{Var}(x) &= E(X^2) - E(x)^2\\\\\n&= 3 - (\\frac{3}{2})^2\\\\\n&= \\frac{3}{4}\n\\end{align*}\nAnswer to Exercise 14.1:\n\nE(X) = -2(\\frac{1}{5}) + -1(\\frac{1}{6}) + 0(\\frac{1}{5}) + 1(\\frac{1}{15}) + 2(\\frac{11}{30}) = \\frac{7}{30}\nE(Y) = 0(\\frac{1}{5}) + 1(\\frac{7}{30}) + 4(\\frac{17}{30}) = \\frac{5}{2}\n\n\n\\begin{align*}\n\\text{Var}(X) &= E[X^2] - E[X]^2\\\\\n&= E(Y) - E(X)^2\\\\\n&= \\frac{5}{2} - \\frac{7}{30}^2 \\approx 2.45\n\\end{align*}\nAnswer to Exercise 14.2:\n\nexpectation = \\frac{6}{5}, variance = \\frac{6}{25}\n\n\nAnswer to Exercise 14.3:\n\nmean = 2, standard deviation = \\sqrt{\\frac{2}{3}}\n\\frac{1}{8}(2 - \\sqrt{\\frac{2}{3}})^2"
  },
  {
    "objectID": "43_statistics.html",
    "href": "43_statistics.html",
    "title": "15  Learning from Data",
    "section": "",
    "text": "So far, we’ve talked about distributions in a theoretical sense, looking at different properties of random variables. We don’t observe random variables; we observe realizations of the random variable. These realizations of events are roughly equivalent to what we mean by “data”.\nSample mean: This is the most common measure of central tendency, calculated by summing across the observations and dividing by the number of observations.\n\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\nThe sample mean is an estimate of the expected value of a distribution.\nDispersion: We also typically want to know how spread out the data are relative to the center of the observed distribution. There are several ways to measure dispersion.\nSample variance: The sample variance is the sum of the squared deviations from the sample mean, divided by the number of observations minus 1.\n \\hat{\\text{Var}}(X) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2\nAgain, this is an estimate of the variance of a random variable; we divide by n - 1 instead of n in order to get an unbiased estimate.\nStandard deviation: The sample standard deviation is the square root of the sample variance.\n \\hat{SD}(X) = \\sqrt{\\hat{\\text{Var}}(X)} = \\sqrt{\\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2}\nCovariance and Correlation: Both of these quantities measure the degree to which two variables vary together, and are estimates of the covariance and correlation of two random variables as defined above.\n\n\nSample covariance: \\hat{\\text{Cov}}(X,Y) = \\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\bar{x})(y_i - \\bar{y})\n\n\nSample correlation: \\hat{\\text{Corr}} = \\frac{\\hat{\\text{Cov}}(X,Y)}{\\sqrt{\\hat{\\text{Var}}(X)\\hat{\\text{Var}}(Y)}}\n\n\n\nExample 15.1 Example: Using the above table, calculate the sample versions of:\n\n\\text{Cov}(X,Y)\n\\text{Corr}(X, Y)"
  },
  {
    "objectID": "43_statistics.html#law-of-large-numbers",
    "href": "43_statistics.html#law-of-large-numbers",
    "title": "15  Learning from Data",
    "section": "\n15.2 Law of Large Numbers",
    "text": "15.2 Law of Large Numbers\nIn probability theory, asymptotic analysis is the study of limiting behavior. By limiting behavior, we mean the behavior of some random process as the number of observations gets larger and larger.\nWhy is this important? We rarely know the true process governing the events we see in the social world. It is helpful to understand how such unknown processes theoretically must behave and asymptotic theory helps us do this.\n\nTheorem 15.1 (Law of Large Numbers (LLN)) For any draw of independent random variables with the same mean \\mu, the sample average after n draws, \\bar{X}_n = \\frac{1}{n}(X_1 + X_2 + \\ldots + X_n), converges in probability to the expected value of X, \\mu as n \\rightarrow \\infty:\n\\lim\\limits_{n\\to \\infty} P(|\\bar{X}_n - \\mu | > \\varepsilon) = 0\n\nA shorthand of which is \\bar{X}_n \\xrightarrow{p} \\mu, where the arrow is read as “converges in probability to” as n\\to \\infty. In other words, P( \\lim_{n\\to\\infty}\\bar{X}_n = \\mu) = 1. This is an important motivation for the widespread use of the sample mean, as well as the intuition link between averages and expected values.\nMore precisely this version of the LLN is called the weak law of large numbers because it leaves open the possibility that |\\bar{X}_n - \\mu | > \\varepsilon occurs many times. The strong law of large numbers states that, under a few more conditions, the probability that the limit of the sample average is the true mean is 1 (and other possibilities occur with probability 0), but the difference is rarely consequential in practice.\nThe Strong Law of Large Numbers holds so long as the expected value exists; no other assumptions are needed. However, the rate of convergence will differ greatly depending on the distribution underlying the observed data. When extreme observations occur often (i.e. kurtosis is large), the rate of convergence is much slower. Cf. The distribution of financial returns."
  },
  {
    "objectID": "43_statistics.html#central-limit-theorem",
    "href": "43_statistics.html#central-limit-theorem",
    "title": "15  Learning from Data",
    "section": "\n15.3 Central Limit Theorem",
    "text": "15.3 Central Limit Theorem\nWe are now finally ready to revisit, with a bit more precise terms, the two pillars of statistical theory we motivated Probability with.\n\nTheorem 15.2 (Central Limit Theorem (i.i.d. case)) Let \\{X_n\\} = \\{X_1, X_2, \\ldots\\} be a sequence of i.i.d. random variables with finite mean (\\mu) and variance (\\sigma^2). Then, the sample mean \\bar{X}_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n} increasingly converges into a Normal distribution.\n\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\text{Normal}(0, 1),\n\nAnother way to write this as a probability statement is that for all real numbers a,\nP\\left(\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\le a\\right) \\rightarrow \\Phi(a)\nas n\\to \\infty, where \\Phi(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}} \\, dx is the CDF of a Normal distribution with mean 0 and variance 1.\nThis result means that, as n grows, the distribution of the sample mean \\bar X_n = \\frac{1}{n} (X_1 + X_2 + \\cdots + X_n) is approximately normal with mean \\mu and standard deviation \\frac{\\sigma}{\\sqrt n}, i.e.,\n\\bar{X}_n \\approx \\mathcal{N}\\bigg(\\mu, \\frac{\\sigma^2}{n}\\bigg). The standard deviation of \\bar X_n (which is roughly a measure of the precision of \\bar X_n as an estimator of \\mu) decreases at the rate 1/\\sqrt{n}, so, for example, to increase its precision by 10 (i.e., to get one more digit right), one needs to collect 10^2=100 times more units of data.\nIntuitively, this result also justifies that whenever a lot of small, independent processes somehow combine together to form the realized observations, practitioners often feel comfortable assuming Normality."
  },
  {
    "objectID": "51_solutions-warmup.html",
    "href": "51_solutions-warmup.html",
    "title": "Warmup Questions Solutions",
    "section": "",
    "text": "Define the vectors u = \\begin{pmatrix} 1 \\\\2 \\\\3 \\end{pmatrix}, v = \\begin{pmatrix} 4\\\\5\\\\6 \\end{pmatrix}, and the scalar c = 2.\n\nu + v = \\begin{pmatrix}5\\\\7\\\\9\\end{pmatrix}\ncv = \\begin{pmatrix}8\\\\10\\\\12\\end{pmatrix}\nu \\cdot v = 1(4) + 2(5) + 3(6) = 32\n\nAre the following sets of vectors linearly independent?\n\n\nu = \\begin{pmatrix} 1\\\\ 2\\end{pmatrix}, v = \\begin{pmatrix} 2\\\\4\\end{pmatrix}\n\n\n\\leadsto No: 2u = \\begin{pmatrix} 2\\\\ 4\\end{pmatrix}, v = \\begin{pmatrix} 2\\\\ 4\\end{pmatrix} so infinitely many linear combinations of u and v that amount to 0 exist.\n\n\nu = \\begin{pmatrix} 1\\\\ 2\\\\ 5 \\end{pmatrix}, v = \\begin{pmatrix} 3\\\\ 7\\\\ 9 \\end{pmatrix}\n\n\n\\leadsto Yes: we cannot find linear combination of these two vectors that would amount to zero.\n\n\na = \\begin{pmatrix} 2\\\\ -1\\\\ 1 \\end{pmatrix}, b = \\begin{pmatrix} 3\\\\ -4\\\\ -2 \\end{pmatrix}, c = \\begin{pmatrix} 5\\\\ -10\\\\ -8 \\end{pmatrix}\n\n\n\\leadsto No: After playing around with some numbers, we can find that\n-2a = \\begin{pmatrix} -4\\\\ 2\\\\ -2 \\end{pmatrix}, 3b = \\begin{pmatrix} 9\\\\ -12\\\\ -6 \\end{pmatrix}, -1c = \\begin{pmatrix} -5\\\\ 10\\\\ 8 \\end{pmatrix}\nSo\n-2a + 3b - c = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\ni.e., a linear combination of these three vectors that would amount to zero exists.\n\n\\mathbf{A}=\\begin{pmatrix} 7 & 5 & 1 \\\\ 11 & 9 & 3 \\\\ 2 & 14 & 21 \\\\ 4 & 1 & 5 \\end{pmatrix}\nWhat is the dimensionality of matrix {\\bf A}? 4 \\times 3\nWhat is the element a_{23} of {\\bf A}? 3\nGiven that\n\\mathbf{B}=\\begin{pmatrix} 1 & 2 & 8 \\\\ 3 & 9 & 11 \\\\ 4 & 7 & 5 \\\\ 5 & 1 & 9 \\end{pmatrix}\n\\mathbf{A} + \\mathbf{B} = \\begin{pmatrix} 8 & 7 & 9 \\\\ 14 & 18 & 14 \\\\ 6 & 21 & 26 \\\\ 9 & 2 & 14 \\end{pmatrix}\nGiven that\n{\\bf C}=\\begin{pmatrix} 1 & 2 & 8 \\\\ 3 & 9 & 11 \\\\  4 & 7 & 5 \\\\ \\end{pmatrix}\n\\mathbf{A} + \\mathbf{C} = \\text{No solution, matrices non-conformable}\nGiven that\nc = 2\nc\\textbf{A} = \\begin{pmatrix}\n            14 & 10 & 2 \\\\\n            22 & 18 & 6 \\\\\n            4 & 28 & 42 \\\\\n            8 & 2 & 10\n        \\end{pmatrix}"
  },
  {
    "objectID": "51_solutions-warmup.html#operations",
    "href": "51_solutions-warmup.html#operations",
    "title": "Warmup Questions Solutions",
    "section": "Operations",
    "text": "Operations\nSummation\nSimplify the following\n\n\\sum\\limits_{i = 1}^3 i = 1 + 2+ 3 = 6\n\\sum\\limits_{k = 1}^3(3k + 2) = 3\\sum\\limits_{k=1}^3k + \\sum\\limits_{k=1}^3 2= 3\\times 6 + 3\\times 2 = 24\n\\sum\\limits_{i= 1}^4 (3k + i + 2) = 3\\sum\\limits_{i= 1}^4k + \\sum\\limits_{i= 1}^4i + \\sum\\limits_{i= 1}^42 = 12k + 10 + 8 = 12k + 18\nProducts\n\n\\prod\\limits_{i= 1}^3 i = 1\\cdot 2\\cdot 3 = 6\n\\prod\\limits_{k=1}^3(3k + 2) = (3 + 2)\\cdot (6 + 2)\\cdot (9 + 2) = 440\nLogs and exponents\nSimplify the following\n\n4^2 = 16\n4^2 2^3 = 2^{2\\cdot 2}2^{3} = 2^{4 + 3} = 128\n\\log_{10}100 = \\log_{10}10^2 = 2\n\\log_{2}4 = \\log_{2}2^2 = 2\nwhen \\log is the natural log, \\log e = \\log_{e} e^1 = 1\n\nwhen a, b, c are each constants, e^a e^b e^c = e^{a + b + c},\n\n\\log 0 = \\text{undefined} – no exponentiation of anything will result in a 0.\n\ne^0 = 1 – any number raised to the 0 is always 1.\n\ne^1 = e – any number raised to the 1 is always itself\n\\log e^2 = \\log_e e^2 = 2"
  },
  {
    "objectID": "51_solutions-warmup.html#limits",
    "href": "51_solutions-warmup.html#limits",
    "title": "Warmup Questions Solutions",
    "section": "Limits",
    "text": "Limits\nFind the limit of the following.\n\n\\lim\\limits_{x \\to 2} (x - 1) = 1\n\n\\lim\\limits_{x \\to 2} \\frac{(x - 2) (x - 1)}{(x - 2)} = 1, though note that the original function \\frac{(x - 2) (x - 1)}{(x - 2)} would have been undefined at x = 2 because of a divide by zero problem; otherwise it would have been equal to x - 1.\n\n\\lim\\limits_{x \\to 2}\\frac{x^2 - 3x + 2}{x- 2} = 1, same as above."
  },
  {
    "objectID": "51_solutions-warmup.html#calculus",
    "href": "51_solutions-warmup.html#calculus",
    "title": "Warmup Questions Solutions",
    "section": "Calculus",
    "text": "Calculus\nFor each of the following functions f(x), find the derivative f'(x) or \\frac{d}{dx}f(x)\n\n\nf(x)=c, f'(x) = 0\n\n\nf(x)=x, f'(x) = 1\n\n\nf(x)=x^2, f'(x) = 2x\n\n\nf(x)=x^3, f'(x) = 3x^2\n\n\nf(x)=3x^2+2x^{1/3}, f'(x) = 6x + \\frac{2}{3}x^{-2/3}\n\n\nf(x)=(x^3)(2x^4), f'(x) = \\frac{d}{dx}2x^7 = 14x^6"
  },
  {
    "objectID": "51_solutions-warmup.html#optimization",
    "href": "51_solutions-warmup.html#optimization",
    "title": "Warmup Questions Solutions",
    "section": "Optimization",
    "text": "Optimization\nFor each of the followng functions f(x), does a maximum and minimum exist in the domain x \\in \\mathbf{R}? If so, for what are those values and for which values of x?\n\n\nf(x) = x \\leadsto neither exists.\n\nf(x) = x^2 \\leadsto a minimum f(x) = 0 exists at x = 0, but not a maximum.\n\nf(x) = -(x - 2)^2 \\leadsto a maximum f(x) = 0 exists at x = 2, but not a minimum.\n\nIf you are stuck, please try sketching out a picture of each of the functions."
  },
  {
    "objectID": "51_solutions-warmup.html#probability",
    "href": "51_solutions-warmup.html#probability",
    "title": "Warmup Questions Solutions",
    "section": "Probability",
    "text": "Probability\n\nIf there are 12 cards, numbered 1 to 12, and 4 cards are chosen, \\binom{12}{4} = \\frac{12\\cdot 11\\cdot 10\\cdot 9}{4!} = 495 possible hands exist (unordered, without replacement) .\nLet A = \\{1,3,5,7,8\\} and B = \\{2,4,7,8,12,13\\}. Then A \\cup B = \\{1, 2, 3, 4, 5, 7, 8, 12, 13\\}, A \\cap B = \\{7, 8\\}? If A is a subset of the Sample Space S = \\{1,2,3,4,5,6,7,8,9,10\\}, then the complement A^C = \\{2, 4, 6, 9, 10\\}\nIf we roll two fair dice, what is the probability that their sum would be 11? \\leadsto \\frac{1}{18}\nIf we roll two fair dice, what is the probability that their sum would be 12? \\leadsto \\frac{1}{36}. There are two independent dice, so 6^2 = 36 options in total. While the previous question had two possibilities for a sum of 11 (5,6 and 6,5), there is only one possibility out of 36 for a sum of 12 (6,6)."
  }
]