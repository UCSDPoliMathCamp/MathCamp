<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>UCSD Political Science Math Camp - 14&nbsp; The Logic of Probability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./43_conditional.html" rel="next">
<link href="./41_measuring_uncertainty.html" rel="prev">
<link href="./favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script><script async="" src="https://hypothes.is/embed.js"></script><script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
<link rel="stylesheet" href="style.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The Logic of Probability</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">UCSD Political Science Math Camp</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/UCSDPoliMathCamp/MathCamp/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle sidebar-tool" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">About this Booklet</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_warmup.html" class="sidebar-item-text sidebar-link">Warmup Questions</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_prerequisites.html" class="sidebar-item-text sidebar-link">Prerequisites</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">I Introduction to R</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_orientation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">RStudio and Reading in Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_visualization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_data_wrangling_cleaning.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Wrangling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_loops_simulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Loops and Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_non-wysiwyg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">LaTeX and Markdown</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">II Linear Algebra</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_vector_matrix.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Matrix Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_linear_systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Systems of Linear Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_matrix_inverse.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Matrix Inverse and Linear Independence</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">III Calculus</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31_limits.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Limits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32_derivatives.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Differential Calculus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33_optimization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./34_intergrals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Integral Calculus</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">IV Probability</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./41_measuring_uncertainty.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Measuring Uncertainty</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./42_logic_probability.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The Logic of Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./43_conditional.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Conditional Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./44_parameter_estimation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Parameter Estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./45_distributions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Probability Distributions</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./51_solutions-warmup.html" class="sidebar-item-text sidebar-link">Warmup Questions Solutions</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li><a href="#not" id="toc-not" class="nav-link active" data-scroll-target="#not">NOT</a></li>
  <li>
<a href="#combining-probability-statements" id="toc-combining-probability-statements" class="nav-link" data-scroll-target="#combining-probability-statements"><span class="toc-section-number">14.1</span>  Combining Probability Statements</a>
  <ul>
<li><a href="#and" id="toc-and" class="nav-link" data-scroll-target="#and">AND</a></li>
  <li><a href="#or" id="toc-or" class="nav-link" data-scroll-target="#or">OR</a></li>
  </ul>
</li>
  <li>
<a href="#the-binomial-probability-distribution" id="toc-the-binomial-probability-distribution" class="nav-link" data-scroll-target="#the-binomial-probability-distribution"><span class="toc-section-number">14.2</span>  The Binomial Probability Distribution</a>
  <ul>
<li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example">An Example</a></li>
  <li><a href="#generalizing-the-binomial-distribution" id="toc-generalizing-the-binomial-distribution" class="nav-link" data-scroll-target="#generalizing-the-binomial-distribution">Generalizing the Binomial Distribution</a></li>
  <li><a href="#visualizing-the-binomial-pmf" id="toc-visualizing-the-binomial-pmf" class="nav-link" data-scroll-target="#visualizing-the-binomial-pmf"><span class="toc-section-number">14.2.1</span>  Visualizing the Binomial PMF</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/UCSDPoliMathCamp/MathCamp/edit/main/42_logic_probability.Rmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="logic_probability" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The Logic of Probability</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><p>Armed now with our understanding of probability as an extension of logic, in this chapter we will learn to use the three basic logical operators on probability statements: NOT, AND, and OR. These three simple tools form the building blocks of every probability problem we will encounter.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="not" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="not">NOT</h3>
<p>If we were absolutely certain about a proposition being true, we would say that its probability equals one: <span class="math inline">\text{P}(A) = 1</span>. Conversely, if we were absolutely certain that <span class="math inline">A</span> was false, its probability would equal zero: <span class="math inline">\text{P}(A) = 0</span>. The logical concept of <em>negation</em> allows us to switch between these two statements easily. That’s because something that is “NOT true” is false, and something that is “NOT false” is true. The following formula provides a general method for us to work with the negation of probabilities</p>
<p><span class="math display">
\text{P}(A) + \neg\text{P}(A) = 1
</span></p>
<p>In words: the sum of the probability of one proposition and its negation must equal one. We are 100% certain that something happens, or that it doesn’t happen! The symbol <span class="math inline">\neg</span> means “not” and denotes that we are negating some probability statement. Switching the terms around gives us a handy way to solve for this value</p>
<p><span class="math display">
\neg\text{P}(A) = 1 - \text{P}(A)
</span></p>
</section><section id="combining-probability-statements" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="combining-probability-statements">
<span class="header-section-number">14.1</span> Combining Probability Statements</h2>
<p>So far we have only been looking at probability statements individually. “What is the probability of flipping a coin and getting heads?” or “What is the probability that the social democrat candidate wins?” But in real data analysis it is rare to analyze probabilities in isolation. The logical operators AND and OR provide the tools for combining probability statements into a single probability. “What is the probability of flipping a coin and getting heads <em>AND</em> rolling a dice and getting a six?” “What is the probability that the social democrat candidate wins <em>OR</em> the green party candidate wins?” One way of thinking about complex statistical models is that all they are doing is combining a bunch of probability statements together in order to generate predictions.</p>
<section id="and" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="and">AND</h3>
<p>When calculating the joint probability of two things occurring—that is, the probability of <span class="math inline">A</span> <em>AND</em> the probability of <span class="math inline">B</span>—we use the following notation:</p>
<p><span class="math display">
\text{P}(A, B)
</span></p>
<p>If <span class="math inline">A</span> and <span class="math inline">B</span> are <em>independent</em>, meaning that the probability of one does not depend on the other, this calculation is very simple. The following formula is known as the <em>product rule of probability</em>:</p>
<p><span class="math display">
\text{P}(A, B) = \text{P}(A) * \text{P}(B)
</span></p>
<p>This formula can get generalized to include any number of individual probabilities. By considering <span class="math inline">\text{P}(A, B)</span> to be a single probability we get</p>
<p><span class="math display">
\text{P}(\text{P}(A, B), C) = \text{P}(A, B) * \text{P}(C) = \text{P}(A) * \text{P}(B) * \text{P}(C)
</span></p>
<p>Easy!</p>
<p>Unfortunately, the probabilities we would like to combine with <em>AND</em> are rarely independent of one another. We will cover what to do in those situations in the next chapter.</p>
</section><section id="or" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="or">OR</h3>
<p>Calculating the probability of one event <em>OR</em> another event is slightly more complicated than combining those two events with <em>AND</em>. This is because the <em>OR</em> calculation is different depending on whether the two events are <em>mutually exclusive</em> or not. If two events are mutually exclusive, their joint probability is zero:</p>
<p><span class="math display">
\text{P}(A, B) = 0
</span></p>
<p>Intuitively, if event <span class="math inline">A</span> happens that makes event <span class="math inline">B</span> is impossible, or vice-versa. Flipping a heads and flipping a tails are two mutually exclusive events because each one precludes the possibility of the other (in a single flip). Combining probabilities of mutually exclusive events with <em>OR</em> is actually pretty easy—we simply add up each individual probability.</p>
<p><span class="math display">
\text{P}(heads) \ OR \ \text{P}(tails) = \frac{1}{2} + \frac{1}{2} = 1
</span></p>
<p>It is certain that when we flip a coin we will get a heads <em>OR</em> a tails.</p>
<p>Things get trickier when trying to use <em>OR</em> on probabilities that are <em>not</em> mutually exclusive. Say we wanted to know the probability of flipping heads <em>OR</em> rolling a number less than six on a six-sided die. If we try adding these probabilities we get:</p>
<p><span class="math display">
\text{P}(heads) \ OR \ \text{P}(&lt;6) = \frac{1}{2} + \frac{5}{6} = \frac{4}{3}
</span></p>
<p>Uh oh! Our final probability of <span class="math inline">4/3</span> is greater than <span class="math inline">1</span>, which is impossible! The problem is that we are double counting outcomes where both events occur. In order to fix this, we need to subtract the joint probability of both events occurring from the sum of both events individually. This gives us the <em>sum rule of probability</em>:</p>
<p><span class="math display">
\text{P}(A) \ OR \ \text{P}(B) = \text{P}(A) + \text{P}(B) - \text{P}(A, B)
</span></p>
<p>Recall how we defined whether two events are mutually exclusive earlier: <span class="math inline">\text{P}(A, B) = 0</span>. So if the two probabilities we want to combine with <em>OR</em> <em>are</em> mutually exclusive, that term drops out of the sum rule equation and we are able to add the individual probabilities together as before: <span class="math inline">\text{P}(A) + \text{P}(B)</span></p>
</section></section><section id="the-binomial-probability-distribution" class="level2" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="the-binomial-probability-distribution">
<span class="header-section-number">14.2</span> The Binomial Probability Distribution</h2>
<p>We encountered probability distributions back in chapter 4 in the context of generating fake data. Now we will look deeper into the math behind how probability distributions work. So far in this chapter we have only been able to use probability theory to solve very <em>specific</em> problems one at a time. “What is the probability of flipping a heads and rolling a six?” Sure, we now have the tools to answer this question, but we will have to recalculate everything from scratch if we changed “rolling a six” to “rolling a five or six”. Probability distributions are functions which we can use as templates to solve an entire class of problems at once!</p>
<p>Each type of probability distribution describes a specific data generating process. In other words, given some causal sequence of events, what data should we expect to see? The binomial distribution comes about when we want to model the probability of getting a number of successful outcomes, given a number of trials and a probability of a successful outcome. The “bi” refers to having two types of outcomes: successes and not-successes. In social science research, the binomial distribution is used all the time to model binary outcomes via logistic regression. Examples include:</p>
<ul>
<li>Did a country go to war or not in a particular year?</li>
<li>Did an individual vote?</li>
<li>Was the bill passed or vetoed?</li>
</ul>
<section id="an-example" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="an-example">An Example</h3>
<p>The binomial distribution has three parameters which govern its shape</p>
<ul>
<li>
<em>k</em>, the number of successes</li>
<li>
<em>n</em>, the number of trials</li>
<li>
<em>p</em>, the probability of success in each trial</li>
</ul>
<p>Let’s use a concrete example of voting behavior to make things clearer. Say we wanted to know the probability that an individual named Max turned out to vote in two of the past three elections, given that Max’s turnout rate is 30%. To solve this question we would plug in the following values for the parameters in a binomial distribution:</p>
<ul>
<li>
<em>2</em>, the number of times Max turned out to vote</li>
<li>
<em>3</em>, the number of elections</li>
<li>
<em>0.3</em>, Max’s turn out rate^[For this example we are assuming that Max’s probability of turning out to vote in each election is <em>independent</em> of one another. In other words, voting in a previous election will not influence Max’s probability to vote in the next election.</li>
</ul>
<p>Let’s try to get a handle on this problem by counting the number of outcomes we care about. In a series of three elections, the possible ways Max can vote in exactly two of them are:</p>
<p><span class="math display">
\text{V} = \text{Max turned out to vote}
</span></p>
<p><span class="math display">
\text{N} = \text{Max did not turn out to vote}
</span></p>
<p><span class="math display">
\text{VVN, VNV, NVV}
</span></p>
<p>Each of these sequences is equally likely because we assumed that each turn out decision Max makes is independent of the last. Notice how each of these sequences is also <em>mutually exclusive</em>.</p>
<p><span class="math display">
\text{P(VVN, VNV, NVV)} = 0
</span></p>
<p>One, and only one, of these sequences of votes will actually occur. Because each of these sequences is mutually exclusive, therefore, we can use the sum rule to add their probabilities together!</p>
<p><span class="math display">
\text{P(VVN)} + \text{P(VNV)} + \text{P(NVV)}
</span></p>
<p>Or in more compact form:</p>
<p><span class="math display">
3 * \text{P(Sequence where Max voted twice)}
</span></p>
<p>Now let’s work on calculating <span class="math inline">\text{P(Sequence where Max voted twice)}</span> and we will be all done. Because we know that each of the three sequences is equally likely, we will work with one of the sequences, <span class="math inline">\text{P(VVN)}</span>, and generalize from there. We know <span class="math inline">\text{P(V)} = 0.3</span> because we assumed Max has an overall turnout rate of 30%. And from the negation rule, we know that <span class="math inline">\text{P(N)} = 0.7</span> because <span class="math inline">\text{P(V)} + \text{P(N)} = 1</span>. It is certain that Max either turns out to vote or he does not. Now we have everything we need to solve for <span class="math inline">\text{P(VVN)}</span> using the product rule:</p>
<p><span class="math display">
\text{P(VVN)} = \text{P(V)} * \text{P(V)} * \text{P(N)} = 0.3 * 0.3 * 0.7 = 0.063
</span></p>
<p>We can now take that answer and multiply it by 3, the amount of outcomes where Max voted twice:</p>
<p><span class="math display">
3 * 0.063 = 0.189
</span></p>
<p>To conclude, Max’s probability of turning out to vote in exactly two out of three elections, given that he turns out to vote 30% of the time, is 0.189. We can confirm this by using R’s <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> function:</p>
<div class="cell" data-hash="42_logic_probability_cache/html/unnamed-chunk-1_b1b1408c83049c423203e1275fd2ab8a">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">2</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.189</code></pre>
</div>
</div>
</section><section id="generalizing-the-binomial-distribution" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="generalizing-the-binomial-distribution">Generalizing the Binomial Distribution</h3>
<p>Max’s voting behavior gave us a nice look at the binomial distribution in action. However, our solution relied on counting the relatively few sequences in which Max could have voted twice in three elections. If we wanted to know the probability of Max voting five times in ten elections, writing all the possible outcomes out would take forever! The solution involves using the <em>binomial coefficient</em>:</p>
<p><span class="math display">
{n \choose k}
</span></p>
<p>We read this expression as “n choose k”. It tells us the number of ways we can select the <em>k</em> outcomes we care about from the total number of trials <em>n</em> using the following formula:</p>
<p><span class="math display">
{n \choose k} = \frac{n!}{k!(n-k)!}
</span></p>
<p>R has a function for computing this value without typing out the whole formula.</p>
<div class="cell" data-hash="42_logic_probability_cache/html/unnamed-chunk-2_4ada95ada468d83fa77e4338a2205f84">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 252</code></pre>
</div>
</div>
<p>We also want to find an expression for multiplying many independent probabilities together, as we did when we calculated <span class="math inline">\text{P(VVN)}</span>. Rather than manually counting how many values for <span class="math inline">\text{P(V)}</span> and <span class="math inline">\text{P(N)}</span> we need to multiply together, let’s use exponents:</p>
<p><span class="math display">
\text{P(VVN)} = \text{P(V)}^2 * \text{P(N)}^1
</span></p>
<p>Which becomes the following in terms of <em>k</em> and <em>n</em>:</p>
<p><span class="math display">
\text{P(V)}^k * \text{P(N)}^{n-k}
</span></p>
<p>And we also want everything in terms of <span class="math inline">\text{P(V)}</span>, which is easy to do using our rule of negation:</p>
<p><span class="math display">
\text{P(V)}^k * \text{P(N)}^{n-k} = \text{P(V)}^k * (1 -\text{P(V)})^{n-k}
</span></p>
<p>Lastly we wrap everything up by multiplying by our binomial coefficient and substituting the parameter <em>p</em> for <span class="math inline">\text{P(V)}</span>:</p>
<p><span class="math display">
{n \choose k} * p^k * (1 - p)^{n-k}
</span></p>
<p>And this is the general equation for the binomial distribution! We call this a <em>probability mass function</em> (PMF) because it tells us how much of the total probability for a binomial distribution with fixed <em>n</em> and <em>p</em> is under the value <em>k</em>. Rather than writing this equation out each time we will usually use the following shorthand:</p>
<p><span class="math display">
\text{Binomial}(k; n, p) = {n \choose k} p^k (1 - p)^{n-k}
</span></p>
</section><section id="visualizing-the-binomial-pmf" class="level3" data-number="14.2.1"><h3 data-number="14.2.1" class="anchored" data-anchor-id="visualizing-the-binomial-pmf">
<span class="header-section-number">14.2.1</span> Visualizing the Binomial PMF</h3>
<p>Sometimes it can be nice to visualize a probability distribution to get a better sense of what it looks like when we change the parameters. Let’s take a look at the following binomial distribution with fixed <span class="math inline">n = 3</span>.</p>
<div class="cell" data-hash="42_logic_probability_cache/html/unnamed-chunk-3_ee89a8f1683e93460fa6bceef3f34677">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"prob = 0.3"</span>, </span>
<span>                       <span class="st">"prob = 0.5"</span>, </span>
<span>                       <span class="st">"prob = 0.7"</span><span class="op">)</span>,</span>
<span>             prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/expand.html">crossing</a></span><span class="op">(</span>k <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">k</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">prob</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">k</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"identity"</span>, fill <span class="op">=</span> <span class="st">"steelblue"</span>, width <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">group</span>, nrow <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"k"</span>, y <span class="op">=</span> <span class="st">"Probability"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Binomial PMFs for n = 3"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="42_logic_probability_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The height of each bar corresponds to the probability of a given value of <em>k</em>.</p>
<div class="cell" data-hash="42_logic_probability_cache/html/unnamed-chunk-4_e11e98c89fc36959afec37ef56c474d5">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"n = 1"</span>, </span>
<span>                       <span class="st">"n = 3"</span>, </span>
<span>                       <span class="st">"n = 7"</span><span class="op">)</span>,</span>
<span>             n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">7</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/expand.html">crossing</a></span><span class="op">(</span>k <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">k</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">k</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"identity"</span>, fill <span class="op">=</span> <span class="st">"steelblue"</span>, width <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">group</span>, nrow <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"k"</span>, y <span class="op">=</span> <span class="st">"Probability"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Binomial PMFs for p = 0.5"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="42_logic_probability_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The graph above shows a binomial distribution with <span class="math inline">p = 0.5</span> with different values of <em>n</em>.</p>


<!-- -->

</section></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Technically we only need NOT and AND, as the OR operation can be derived from the other two.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./41_measuring_uncertainty.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Measuring Uncertainty</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./43_conditional.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Conditional Probability</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># The Logic of Probability {#logic_probability}</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>Armed now with our understanding of probability as an extension of logic, in this chapter we will learn to use the three basic logical operators on probability statements: NOT, AND, and OR. These three simple tools form the building blocks of every probability problem we will encounter.^<span class="co">[</span><span class="ot">Technically we only need NOT and AND, as the OR operation can be derived from the other two.</span><span class="co">]</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">### NOT {.unnumbered}</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>If we were absolutely certain about a proposition being true, we would say that its probability equals one: $\text{P}(A) = 1$. Conversely, if we were absolutely certain that $A$ was false, its probability would equal zero: $\text{P}(A) = 0$. The logical concept of *negation* allows us to switch between these two statements easily. That's because something that is "NOT true" is false, and something that is "NOT false" is true. The following formula provides a general method for us to work with the negation of probabilities</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>\text{P}(A) + \neg\text{P}(A) = 1</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>In words: the sum of the probability of one proposition and its negation must equal one. We are 100% certain that something happens, or that it doesn't happen! The symbol $\neg$ means "not" and denotes that we are negating some probability statement. Switching the terms around gives us a handy way to solve for this value</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>\neg\text{P}(A) = 1 - \text{P}(A)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## Combining Probability Statements</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>So far we have only been looking at probability statements individually. "What is the probability of flipping a coin and getting heads?" or "What is the probability that the social democrat candidate wins?" But in real data analysis it is rare to analyze probabilities in isolation. The logical operators AND and OR provide the tools for combining probability statements into a single probability. "What is the probability of flipping a coin and getting heads *AND* rolling a dice and getting a six?" "What is the probability that the social democrat candidate wins *OR* the green party candidate wins?" One way of thinking about complex statistical models is that all they are doing is combining a bunch of probability statements together in order to generate predictions.</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="fu">### AND {.unnumbered}</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>When calculating the joint probability of two things occurring---that is, the probability of $A$ *AND* the probability of $B$---we use the following notation:</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>\text{P}(A, B)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>If $A$ and $B$ are *independent*, meaning that the probability of one does not depend on the other, this calculation is very simple. The following formula is known as the *product rule of probability*:</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>\text{P}(A, B) = \text{P}(A) * \text{P}(B)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>This formula can get generalized to include any number of individual probabilities. By considering $\text{P}(A, B)$ to be a single probability we get</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>\text{P}(\text{P}(A, B), C) = \text{P}(A, B) * \text{P}(C) = \text{P}(A) * \text{P}(B) * \text{P}(C)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>Easy! </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>Unfortunately, the probabilities we would like to combine with *AND* are rarely independent of one another. We will cover what to do in those situations in the next chapter.</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="fu">### OR {.unnumbered}</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>Calculating the probability of one event *OR* another event is slightly more complicated than combining those two events with *AND*. This is because the *OR* calculation is different depending on whether the two events are *mutually exclusive* or not. If two events are mutually exclusive, their joint probability is zero:</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>\text{P}(A, B) = 0</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>Intuitively, if event $A$ happens that makes event $B$ is impossible, or vice-versa. Flipping a heads and flipping a tails are two mutually exclusive events because each one precludes the possibility of the other (in a single flip). Combining probabilities of mutually exclusive events with *OR* is actually pretty easy---we simply add up each individual probability.</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>\text{P}(heads) \ OR \ \text{P}(tails) = \frac{1}{2} + \frac{1}{2} = 1</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>It is certain that when we flip a coin we will get a heads *OR* a tails.</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>Things get trickier when trying to use *OR* on probabilities that are *not* mutually exclusive. Say we wanted to know the probability of flipping heads *OR* rolling a number less than six on a six-sided die. If we try adding these probabilities we get:</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>\text{P}(heads) \ OR \ \text{P}(&lt;6) = \frac{1}{2} + \frac{5}{6} = \frac{4}{3}</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>Uh oh! Our final probability of $4/3$ is greater than $1$, which is impossible! The problem is that we are double counting outcomes where both events occur. In order to fix this, we need to subtract the joint probability of both events occurring from the sum of both events individually. This gives us the *sum rule of probability*:</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>\text{P}(A) \ OR \ \text{P}(B) = \text{P}(A) + \text{P}(B) - \text{P}(A, B)</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>Recall how we defined whether two events are mutually exclusive earlier: $\text{P}(A, B) = 0$. So if the two probabilities we want to combine with *OR* *are* mutually exclusive, that term drops out of the sum rule equation and we are able to add the individual probabilities together as before: $\text{P}(A) + \text{P}(B)$</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Binomial Probability Distribution</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>We encountered probability distributions back in chapter 4 in the context of generating fake data. Now we will look deeper into the math behind how probability distributions work. So far in this chapter we have only been able to use probability theory to solve very *specific* problems one at a time. "What is the probability of flipping a heads and rolling a six?" Sure, we now have the tools to answer this question, but we will have to recalculate everything from scratch if we changed "rolling a six" to "rolling a five or six". Probability distributions are functions which we can use as templates to solve an entire class of problems at once!</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>Each type of probability distribution describes a specific data generating process. In other words, given some causal sequence of events, what data should we expect to see? The binomial distribution comes about when we want to model the probability of getting a number of successful outcomes, given a number of trials and a probability of a successful outcome. The "bi" refers to having two types of outcomes: successes and not-successes. In social science research, the binomial distribution is used all the time to model binary outcomes via logistic regression. Examples include:</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Did a country go to war or not in a particular year?</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Did an individual vote?</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Was the bill passed or vetoed?</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a><span class="fu">### An Example {.unnumbered}</span></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>The binomial distribution has three parameters which govern its shape</span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*k*, the number of successes</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*n*, the number of trials</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*p*, the probability of success in each trial</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>Let's use a concrete example of voting behavior to make things clearer. Say we wanted to know the probability that an individual named Max turned out to vote in two of the past three elections, given that Max's turnout rate is 30%. To solve this question we would plug in the following values for the parameters in a binomial distribution:</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*2*, the number of times Max turned out to vote</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*3*, the number of elections</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>*0.3*, Max's turn out rate^[For this example we are assuming that Max's probability of turning out to vote in each election is *independent* of one another. In other words, voting in a previous election will not influence Max's probability to vote in the next election.</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>Let's try to get a handle on this problem by counting the number of outcomes we care about. In a series of three elections, the possible ways Max can vote in exactly two of them are:</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>\text{V} = \text{Max turned out to vote}</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>\text{N} = \text{Max did not turn out to vote}</span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>\text{VVN, VNV, NVV} </span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>Each of these sequences is equally likely because we assumed that each turn out decision Max makes is independent of the last. Notice how each of these sequences is also *mutually exclusive*.</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a>\text{P(VVN, VNV, NVV)} = 0</span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a>One, and only one, of these sequences of votes will actually occur. Because each of these sequences is mutually exclusive, therefore, we can use the sum rule to add their probabilities together!</span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>\text{P(VVN)} + \text{P(VNV)} + \text{P(NVV)}</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>Or in more compact form:</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>3 * \text{P(Sequence where Max voted twice)}</span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a>Now let's work on calculating $\text{P(Sequence where Max voted twice)}$ and we will be all done. Because we know that each of the three sequences is equally likely, we will work with one of the sequences, $\text{P(VVN)}$, and generalize from there. We know $\text{P(V)} = 0.3$ because we assumed Max has an overall turnout rate of 30%. And from the negation rule, we know that $\text{P(N)} = 0.7$ because $\text{P(V)} + \text{P(N)} = 1$. It is certain that Max either turns out to vote or he does not. Now we have everything we need to solve for $\text{P(VVN)}$ using the product rule:</span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a>\text{P(VVN)} = \text{P(V)} * \text{P(V)} * \text{P(N)} = 0.3 * 0.3 * 0.7 = 0.063</span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a>We can now take that answer and multiply it by 3, the amount of outcomes where Max voted twice:</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>3 * 0.063 = 0.189</span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>To conclude, Max's probability of turning out to vote in exactly two out of three elections, given that he turns out to vote 30% of the time, is 0.189. We can confirm this by using R's <span class="in">`dbinom()`</span> function:</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">2</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> <span class="fl">0.3</span>)</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### Generalizing the Binomial Distribution {.unnumbered}</span></span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a>Max's voting behavior gave us a nice look at the binomial distribution in action. However, our solution relied on counting the relatively few sequences in which Max could have voted twice in three elections. If we wanted to know the probability of Max voting five times in ten elections, writing all the possible outcomes out would take forever! The solution involves using the *binomial coefficient*:</span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a>{n \choose k}</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a>We read this expression as "n choose k". It tells us the number of ways we can select the *k* outcomes we care about from the total number of trials *n* using the following formula:</span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a>{n \choose k} = \frac{n!}{k!(n-k)!}</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a>R has a function for computing this value without typing out the whole formula.</span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a><span class="fu">choose</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">k =</span> <span class="dv">5</span>)</span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a>We also want to find an expression for multiplying many independent probabilities together, as we did when we calculated $\text{P(VVN)}$. Rather than manually counting how many values for $\text{P(V)}$ and $\text{P(N)}$ we need to multiply together, let's use exponents:</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a>\text{P(VVN)} = \text{P(V)}^2 * \text{P(N)}^1</span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a>Which becomes the following in terms of *k* and *n*:</span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>\text{P(V)}^k * \text{P(N)}^{n-k}</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a>And we also want everything in terms of $\text{P(V)}$, which is easy to do using our rule of negation:</span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a>\text{P(V)}^k * \text{P(N)}^{n-k} = \text{P(V)}^k * (1 -\text{P(V)})^{n-k}</span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a>Lastly we wrap everything up by multiplying by our binomial coefficient and substituting the parameter *p* for $\text{P(V)}$:</span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a>{n \choose k} * p^k * (1 - p)^{n-k}</span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a>And this is the general equation for the binomial distribution! We call this a *probability mass function* (PMF) because it tells us how much of the total probability for a binomial distribution with fixed *n* and *p* is under the value *k*. Rather than writing this equation out each time we will usually use the following shorthand:</span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a>\text{Binomial}(k; n, p) = {n \choose k} p^k (1 - p)^{n-k}</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualizing the Binomial PMF</span></span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a>Sometimes it can be nice to visualize a probability distribution to get a better sense of what it looks like when we change the parameters. Let's take a look at the following binomial distribution with fixed $n = 3$.</span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, warning=FALSE}</span></span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">"prob = 0.3"</span>, </span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"prob = 0.5"</span>, </span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"prob = 0.7"</span>),</span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a>             <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>  <span class="fu">crossing</span>(<span class="at">k =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> k, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> prob))</span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> k, <span class="at">y =</span> y) <span class="sc">+</span></span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"steelblue"</span>, <span class="at">width =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> group, <span class="at">nrow =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"k"</span>, <span class="at">y =</span> <span class="st">"Probability"</span>,</span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Binomial PMFs for n = 3"</span>)</span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a>The height of each bar corresponds to the probability of a given value of *k*.</span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">group =</span> <span class="fu">c</span>(<span class="st">"n = 1"</span>, </span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"n = 3"</span>, </span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a>                       <span class="st">"n = 7"</span>),</span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a>             <span class="at">n =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>  <span class="fu">crossing</span>(<span class="at">k =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">7</span>) <span class="sc">|&gt;</span> </span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> k, <span class="at">size =</span> n, <span class="at">prob =</span> <span class="fl">0.5</span>))</span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span></span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> k, <span class="at">y =</span> y) <span class="sc">+</span></span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"steelblue"</span>, <span class="at">width =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> group, <span class="at">nrow =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"k"</span>, <span class="at">y =</span> <span class="st">"Probability"</span>,</span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"Binomial PMFs for p = 0.5"</span>) <span class="sc">+</span></span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">7</span>)</span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a>The graph above shows a binomial distribution with $p = 0.5$ with different values of *n*. </span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>