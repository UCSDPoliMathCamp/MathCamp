<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.179">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>UCSD Political Science Math Camp - 13&nbsp; Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./42_distribution.html" rel="next">
<link href="./34_intergrals.html" rel="prev">
<link href="./favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script type="application/json" class="js-hypothesis-config">
{
  "theme": "clean"
}
</script><script async="" src="https://hypothes.is/embed.js"></script><script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
<link rel="stylesheet" href="style.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Probability Theory</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">UCSD Political Science Math Camp</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/UCSDPoliMathCamp/MathCamp/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle sidebar-tool" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">About this Booklet</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_warmup.html" class="sidebar-item-text sidebar-link">Warmup Questions</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_prerequisites.html" class="sidebar-item-text sidebar-link">Prerequisites</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">I Introduction to R</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_orientation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">RStudio and Reading in Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_visualization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_data_wrangling_cleaning.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Wrangling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_loops_simulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Loops and Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_non-wysiwyg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">LaTeX and Markdown</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">II Linear Algebra</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_vector_matrix.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vector and Matrix</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_linear_systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Systems of Linear Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_matrix_inverse.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Rank and Matrix Inverse</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">III Calculus</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./31_limits.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Limits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./32_derivatives.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Differential Calculus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./33_optimization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./34_intergrals.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Integral Calculus</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">IV Probability</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./41_probability.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./42_distribution.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Summarizing Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./43_statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Learning from Data</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./51_solutions-warmup.html" class="sidebar-item-text sidebar-link">Warmup Questions Solutions</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li><a href="#counting-rules" id="toc-counting-rules" class="nav-link active" data-scroll-target="#counting-rules"><span class="toc-section-number">13.1</span>  Counting Rules</a></li>
  <li><a href="#setoper" id="toc-setoper" class="nav-link" data-scroll-target="#setoper"><span class="toc-section-number">13.2</span>  Sets</a></li>
  <li>
<a href="#probdef" id="toc-probdef" class="nav-link" data-scroll-target="#probdef"><span class="toc-section-number">13.3</span>  Probability</a>
  <ul>
<li><a href="#probability-definitions-formal-and-informal" id="toc-probability-definitions-formal-and-informal" class="nav-link" data-scroll-target="#probability-definitions-formal-and-informal">Probability Definitions: Formal and Informal</a></li>
  <li><a href="#probability-operations" id="toc-probability-operations" class="nav-link" data-scroll-target="#probability-operations">Probability Operations</a></li>
  </ul>
</li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability"><span class="toc-section-number">13.4</span>  Conditional Probability</a></li>
  <li><a href="#bayes-rule" id="toc-bayes-rule" class="nav-link" data-scroll-target="#bayes-rule"><span class="toc-section-number">13.5</span>  Bayes Rule</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="toc-section-number">13.6</span>  Independence</a></li>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link" data-scroll-target="#random-variables"><span class="toc-section-number">13.7</span>  Random Variables</a></li>
  <li>
<a href="#distributions" id="toc-distributions" class="nav-link" data-scroll-target="#distributions"><span class="toc-section-number">13.8</span>  Distributions</a>
  <ul>
<li><a href="#discrete-random-variables" id="toc-discrete-random-variables" class="nav-link" data-scroll-target="#discrete-random-variables">Discrete Random Variables</a></li>
  <li><a href="#continuous-random-variables" id="toc-continuous-random-variables" class="nav-link" data-scroll-target="#continuous-random-variables">Continuous Random Variables</a></li>
  </ul>
</li>
  <li><a href="#answers-to-examples-and-exercises" id="toc-answers-to-examples-and-exercises" class="nav-link" data-scroll-target="#answers-to-examples-and-exercises">Answers to Examples and Exercises</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/UCSDPoliMathCamp/MathCamp/edit/main/41_probability.Rmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="probability-theory" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Probability Theory</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><p>Probability and Inferences are mirror images of each other, and both are integral to social science. Probability quantifies uncertainty, which is important because many things in the social world are at first uncertain. Inference is then the study of how to learn about facts you don’t observe from facts you do observe.</p>
<section id="counting-rules" class="level2" data-number="13.1"><h2 data-number="13.1" class="anchored" data-anchor-id="counting-rules">
<span class="header-section-number">13.1</span> Counting Rules</h2>
<p>Probability in high school is usually really about combinatorics: the probability of event <em>A</em> is the number of ways in which <em>A</em> can occur divided by the number of all other possibilities. This is a very simplified version of probability, which we can call the “counting definition of probability”, essentially because each possible event to count is often equally likely and discrete. But it is still good to review the underlying rules here.</p>
<p><strong>Fundamental Theorem of Counting</strong>: If an object has <span class="math inline">j</span> different characteristics that are independent of each other, and each characteristic <span class="math inline">i</span> has <span class="math inline">n_i</span> ways of being expressed, then there are <span class="math inline">\prod_{i = 1}^j n_i</span> possible unique objects.</p>
<div id="exm-countingrules" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.1 </strong></span>Suppose we are given a stack of cards. Cards can be either red or black and can take on any of 13 values. There is only one of each color-number combination. In this case,</p>
<ol type="1">
<li><p><span class="math inline">j =</span></p></li>
<li><p><span class="math inline">n_{\text{color}} =</span></p></li>
<li><p><span class="math inline">n_{\text{number}} =</span></p></li>
<li><p>Number of Outcomes <span class="math inline">=</span></p></li>
</ol>
</div>
<p>We often need to count the number of ways to choose a subset from some set of possibilities. The number of outcomes depends on two characteristics of the process: does the order matter and is replacement allowed?</p>
<p>It is useful to think of any problem concretely, e.g.&nbsp;through a <strong>sampling table</strong>: If there are <span class="math inline">n</span> objects which are numbered 1 to <span class="math inline">n</span> and we select <span class="math inline">k &lt; n</span> of them, how many different outcomes are possible?</p>
<p>If the order in which a given object is selected matters, selecting 4 numbered objects in the following order (1, 3, 7, 2) and selecting the same four objects but in a different order such as (7, 2, 1, 3) will be counted as different outcomes.</p>
<p>If replacement is allowed, there are always the same <span class="math inline">n</span> objects to select from. However, if replacement is not allowed, there is always one less option than the previous round when making a selection. For example, if replacement is not allowed and I am selecting 3 elements from the following set {1, 2, 3, 4, 5, 6}, I will have 6 options at first, 5 options as I make my second selection, and 4 options as I make my third.</p>
<ol type="1">
<li><p>So if <strong><em>order matters</em></strong> AND we are sampling <strong><em>with replacement</em></strong>, the number of different outcomes is <span class="math inline">n^k</span>.</p></li>
<li><p>If <strong><em>order matters</em></strong> AND we are sampling <strong><em>without replacement</em></strong>, the number of different outcomes is <span class="math inline">n(n-1)(n-2)...(n-k+1)=\frac{n!}{(n-k)!}</span>.</p></li>
<li><p>If <strong><em>order doesn’t matter</em></strong> AND we are sampling <strong><em>without replacement</em></strong>, the number of different outcomes is <span class="math inline">\binom{n}{k} = \frac{n!}{(n-k)!k!}</span>.</p></li>
</ol>
<p>Expression <span class="math inline">\binom{n}{k}</span> is read as “n choose k” and denotes <span class="math inline">\frac{n!}{(n-k)!k!}</span>. Also, note that <span class="math inline">0! = 1</span>.</p>
<div id="exm-counting" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.2 (Counting) </strong></span>There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there?</p>
<ol type="1">
<li><p>Ordered, with replacement <span class="math inline">=</span></p></li>
<li><p>Ordered, without replacement <span class="math inline">=</span></p></li>
<li><p>Unordered, without replacement <span class="math inline">=</span></p></li>
</ol>
</div>
<div id="exr-counting1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.1 (Counting) </strong></span>Four cards are selected from a deck of 52 cards. Once a card has been drawn, it is not reshuffled back into the deck. Moreover, we care only about the complete hand that we get (i.e.&nbsp;we care about the set of selected cards, not the sequence in which it was drawn). How many possible outcomes are there?</p>
</div>
</section><section id="setoper" class="level2" data-number="13.2"><h2 data-number="13.2" class="anchored" data-anchor-id="setoper">
<span class="header-section-number">13.2</span> Sets</h2>
<p>Probability is about quantifying the uncertainty of events. <em>Sets</em> (set theory) are the mathematical way we choose to formalize those events. Events are not inherently numerical: the onset of war or the stock market crashing is not inherently a number. Sets can define such events, and we wrap math around so that we have a transparent language to communicate about those events. <em>Measure theory</em> might sound mysterious or hard, but it is also just a mathematical way to quantify things like length, volume, and mass. Probability can be thought of as a particular application of measure theory where we want to quantify the measure of a set.</p>
<p><strong>Set</strong> : A set is any well defined collection of elements. If <span class="math inline">x</span> is an element of <span class="math inline">S</span>, <span class="math inline">x \in S</span>.</p>
<p><strong>Sample Space (S)</strong>: A set or collection of all possible outcomes from some process. Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable).</p>
<p>Examples:</p>
<ol type="1">
<li>Discrete: the numbers on a die, whether a vote cast is republican or democrat.</li>
<li>Continuous: GNP, arms spending, age.</li>
</ol>
<p><strong>Event</strong>: Any collection of possible outcomes of an experiment. Any subset of the full set of possibilities, including the full set itself. Event A <span class="math inline">\subset</span> S.</p>
<p><strong>Empty Set</strong>: a set with no elements. <span class="math inline">S = \{\}</span>. It is denoted by the symbol <span class="math inline">\emptyset</span>.</p>
<p>Set operations:</p>
<ol type="1">
<li>
<strong>Union</strong>: The union of two sets <span class="math inline">A</span> and <span class="math inline">B</span>, <span class="math inline">A \cup B</span>, is the set containing all of the elements in <span class="math inline">A</span> or <span class="math inline">B</span>. <span class="math display">A_1 \cup A_2  \cup \cdots \cup A_n = \bigcup_{i=1}^n A_i</span>
</li>
<li>
<strong>Intersection</strong>: The intersection of sets <span class="math inline">A</span> and <span class="math inline">B</span>, <span class="math inline">A \cap B</span>, is the set containing all of the elements in both <span class="math inline">A</span> and <span class="math inline">B</span>. <span class="math display">A_1 \cap A_2  \cap \cdots \cap A_n = \bigcap_{i=1}^n A_i</span>
</li>
<li>
<strong>Complement</strong>: If set <span class="math inline">A</span> is a subset of <span class="math inline">S</span>, then the complement of <span class="math inline">A</span>, denoted <span class="math inline">A^C</span>, is the set containing all of the elements in <span class="math inline">S</span> that are not in <span class="math inline">A</span>.</li>
</ol>
<p>Properties of set operations:</p>
<ul>
<li>
<strong>Commutative</strong>: <span class="math inline">A \cup B = B \cup A</span>; <span class="math inline">A \cap B = B \cap A</span>
</li>
<li>
<strong>Associative</strong>: <span class="math inline">A \cup (B \cup C) = (A \cup B) \cup C</span>; <span class="math inline">A \cap (B \cap C) = (A \cap B) \cap C</span>
</li>
<li>
<strong>Distributive</strong>: <span class="math inline">A \cap (B \cup C) = (A \cap B) \cup (A \cap C)</span>; <span class="math inline">A \cup (B \cap C) = (A \cup B) \cap (A \cup C)</span>
</li>
<li>
<strong>de Morgan’s laws</strong>: <span class="math inline">(A \cup B)^C = A^C \cap B^C</span>; <span class="math inline">(A \cap B)^C = A^C \cup B^C</span>
</li>
<li>
<strong>Disjointness</strong>: Sets are disjoint when they do not intersect, such that <span class="math inline">A \cap B = \emptyset</span>. A collection of sets is pairwise disjoint (<strong>mutually exclusive</strong>) if, for all <span class="math inline">i \neq j</span>, <span class="math inline">A_i \cap A_j = \emptyset</span>. A collection of sets form a partition of set <span class="math inline">S</span> if they are pairwise disjoint and they cover set <span class="math inline">S</span>, such that <span class="math inline">\bigcup_{i = 1}^k A_i = S</span>.</li>
</ul>
<div id="exm-sets" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.3 (Sets) </strong></span>Let set <span class="math inline">A</span> be {1, 2, 3, 4}, <span class="math inline">B</span> be {3, 4, 5, 6}, and <span class="math inline">C</span> be {5, 6, 7, 8}. Sets <span class="math inline">A</span>, <span class="math inline">B</span>, and <span class="math inline">C</span> are all subsets of the sample space <span class="math inline">S</span> which is {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}</p>
<p>Write out the following sets:</p>
<ol type="1">
<li><span class="math inline">A \cup B</span></li>
<li><span class="math inline">C \cap B</span></li>
<li><span class="math inline">B^c</span></li>
<li><span class="math inline">A \cap (B \cup C)</span></li>
</ol>
</div>
<div id="exr-sets1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.2 </strong></span>Suppose you had a pair of four-sided dice. You sum the results from a single toss.</p>
<p>What is the set of possible outcomes (i.e.&nbsp;the sample space)?</p>
<p>Consider subsets A {2, 8} and B {2,3,7} of the sample space you found. What is</p>
<ol type="1">
<li><span class="math inline">A^c</span></li>
<li><span class="math inline">(A \cup B)^c</span></li>
</ol>
</div>
</section><section id="probdef" class="level2" data-number="13.3"><h2 data-number="13.3" class="anchored" data-anchor-id="probdef">
<span class="header-section-number">13.3</span> Probability</h2>
<div class="cell" data-hash="41_probability_cache/html/fig-prob-image_ea171f1179d6e1d0045f5bb596a1b7c4">
<div class="cell-output-display">
<div id="fig-prob-image" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/probability.png" class="img-fluid figure-img" width="1075"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;13.1: Probablity as a Measure<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption><p></p>
</figure>
</div>
</div>
</div>
<section id="probability-definitions-formal-and-informal" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="probability-definitions-formal-and-informal">Probability Definitions: Formal and Informal</h3>
<p>Many things in the world are uncertain. In everyday speech, we say that we are <em>uncertain</em> about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules (<a href="#fig-prob-image">Figure&nbsp;<span>13.1</span></a>). A different model of uncertainty would, of course, have a set of rules different from anything we discuss here. Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty.</p>
<p><strong>Probability Distribution Function</strong>: a mapping of each event in the sample space <span class="math inline">S</span> to the real numbers that satisfy the following three axioms (also called Kolmogorov’s Axioms).</p>
<p>Formally,</p>
<div id="def-prob" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.1 (Probability) </strong></span>Probability is a function that maps events to a real number, obeying the axioms of probability.</p>
</div>
<p>The axioms of probability make sure that the separate events add up in terms of probability, and – for standardization purposes – that they add up to 1.</p>
<div id="def-" class="theorem definition">
<ol type="1">
<li><span class="theorem-title"><strong>Definition 13.2 (Axioms of Probability) </strong></span></li>
<li>For any event <span class="math inline">A</span>, <span class="math inline">P(A)\ge 0</span>.</li>
<li><span class="math inline">P(S)=1</span></li>
<li>The Countable Additivity Axiom: For any sequence of <em>disjoint</em> (mutually exclusive) events <span class="math inline">A_1,A_2,\ldots</span> (of which there may be infinitely many), <span class="math display">P\left( \bigcup\limits_{i=1}^k
A_i\right)=\sum\limits_{i=1}^k P(A_i)</span>
</li>
</ol>
<p>The last axiom is an extension of a union to infinite sets. When there are only two events in the space, it boils down to:</p>
<p><span class="math display">\begin{align*}
P(A_1 \cup A_2) = P(A_1) + P(A_2) \quad\text{for disjoint } A_1, A_2
\end{align*}</span></p>
</div>
</section><section id="probability-operations" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="probability-operations">Probability Operations</h3>
<p>Using these three axioms, we can define all of the common rules of probability.</p>
<div id="prop-prob">
<ol type="1">
<li><span class="math inline">P(\emptyset)=0</span></li>
<li>For any event <span class="math inline">A</span>, <span class="math inline">0\le P(A) \le 1</span>
</li>
<li><span class="math inline">P({A}^C)=1-P(A)</span></li>
<li>If <span class="math inline">A\subset B</span> (<span class="math inline">A</span> is a subset of <span class="math inline">B</span>), then <span class="math inline">P(A)\le P(B)</span>
</li>
<li>For <em>any</em> two events <span class="math inline">A</span> and <span class="math inline">B</span>, <span class="math inline">P(A\cup B)=P(A)+P(B)-P(A\cap B)</span>
</li>
<li>Boole’s Inequality: For any sequence of <span class="math inline">n</span> events (which need not be disjoint) <span class="math inline">A_1,A_2,\ldots,A_n</span>, then <span class="math display">P\left( \bigcup\limits_{i=1}^n A_i\right) \leq \sum\limits_{i=1}^n P(A_i)</span>
</li>
</ol>
</div>
<div id="exm-prob" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.4 </strong></span>Assume we have an evenly-balanced, six-sided die.</p>
<p>Then,</p>
<ol type="1">
<li>Sample space <span class="math inline">S</span> =</li>
<li><span class="math inline">P(1)=\cdots=P(6)=</span></li>
<li><span class="math inline">P(\emptyset)=P(7)=</span></li>
<li><span class="math inline">P\left( \{ 1, 3, 5 \} \right)=</span></li>
<li><span class="math inline">P\left( \{ 1, 2 \}^C \right)= P\left( \{ 3, 4, 5, 6 \}\right)=</span></li>
<li>Let <span class="math inline">A=\{ 1,2,3,4,5 \}\subset S</span>. Then <span class="math inline">P(A)=5/6&lt;P(S)=</span>
</li>
<li>Let <span class="math inline">A=\{ 1, 2, 3 \}</span> and <span class="math inline">B=\{ 2, 4, 6 \}</span>. Then <span class="math inline">A\cup B</span>? <span class="math inline">A\cap B</span>? <span class="math inline">P(A \cup B)</span>?</li>
</ol>
</div>
<div id="exr-prob1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.3 </strong></span>Suppose you had a pair of four-sided dice. You sum the results from a single toss. Let us call this sum, or the outcome, X.</p>
<ol type="1">
<li>What is <span class="math inline">P(X = 5)</span>, <span class="math inline">P(X = 3)</span>, <span class="math inline">P(X = 6)</span>?</li>
<li>What is <span class="math inline">P(X=5 \cup X = 3)^C</span>?</li>
</ol>
</div>
</section></section><section id="conditional-probability" class="level2" data-number="13.4"><h2 data-number="13.4" class="anchored" data-anchor-id="conditional-probability">
<span class="header-section-number">13.4</span> Conditional Probability</h2>
<p><strong>Conditional Probability</strong>: The conditional probability <span class="math inline">P(A|B)</span> of an event <span class="math inline">A</span> is the probability of <span class="math inline">A</span>, given that another event <span class="math inline">B</span> has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event. It is calculated as</p>
<p><span class="math display">P(A|B)=\frac{P(A\cap B)}{P(B)}</span></p>
<p>Note that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability.</p>
<div id="exm-condprobexm1" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.5 (Conditional Probability) </strong></span>Assume <span class="math inline">A</span> and <span class="math inline">B</span> occur with the following frequencies: <span class="math inline">\quad</span></p>
<table class="table">
<thead><tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">A</span></th>
<th style="text-align: center;"><span class="math inline">A^c</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">B</span></td>
<td style="text-align: center;"><span class="math inline">n_{ab}</span></td>
<td style="text-align: center;"><span class="math inline">n_{a^cb}</span></td>
</tr>
<tr class="even">
<td><span class="math inline">B^C</span></td>
<td style="text-align: center;"><span class="math inline">n_{ab^c}</span></td>
<td style="text-align: center;"><span class="math inline">n_{(ab)^c}</span></td>
</tr>
</tbody>
</table>
<p>and let <span class="math inline">n_{ab}+n_{a^Cb}+n_{ab^C}+n_{(ab)^C}=N</span>. Then</p>
<ol type="1">
<li><span class="math inline">P(A)=</span></li>
<li><span class="math inline">P(B)=</span></li>
<li><span class="math inline">P(A\cap B)=</span></li>
<li><span class="math inline">P(A|B)= \frac{P(A\cap B)}{P(B)}=</span></li>
<li><span class="math inline">P(B|A)= \frac{P(A\cap B)}{P(A)}=</span></li>
</ol>
</div>
<div id="exm-condprobexm2" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.6 (Conditional Probability 2) </strong></span>A six-sided die is rolled. What is the probability of a 1, given the outcome is an odd number?</p>
</div>
<p>You could rearrange the fraction to highlight how a joint probability could be expressed as the product of a conditional probability.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.3 (Multiplicative Law of Probability) </strong></span>The probability of the intersection of two events <span class="math inline">A</span> and <span class="math inline">B</span> is</p>
<p><span class="math display">P(A\cap B)=P(A)P(B|A)=P(B)P(A|B)</span></p>
<p>which follows directly from the definition of conditional probability. More generally,</p>
<p><span class="math display">\begin{align*}
P(A_1\cap \cdots\cap A_k) = &amp;P(A_k| A_{k-1}\cap \cdots \cap A_1) \\
\times &amp;P(A_{k-1}|A_{k-2}\cap \cdots A_1) \\
\vdots &amp; \\
\times &amp;P(A_2|A_1) \\
\times &amp;P(A_1)
\end{align*}</span></p>
<p>Sometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate <span class="math inline">P(A)</span> directly.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.4 (Law of Total Probability) </strong></span>Let <span class="math inline">S</span> be the sample space of some experiment and let the disjoint <span class="math inline">k</span> events <span class="math inline">B_1,\ldots,B_k</span> partition <span class="math inline">S</span>, such that <span class="math inline">P(B_1\cup ... \cup B_k) = P(S) = 1</span>. If <span class="math inline">A</span> is some other event in <span class="math inline">S</span>, then the events <span class="math inline">A\cap B_1, A\cap B_2, \ldots, A\cap B_k</span> will form a partition of <span class="math inline">A</span> and we can write <span class="math inline">A</span> as <span class="math display">A=(A\cap B_1)\cup\cdots\cup (A\cap B_k)</span>.</p>
<p>Since the <span class="math inline">k</span> events are disjoint,</p>
<p><span class="math display">\begin{align*}
P(A)&amp;=\sum\limits_{i=1}^k P(A \cap B_i)\\
    &amp;=\sum\limits_{i=1}^k P(B_i)P(A|B_i)
\end{align*}</span></p>
</div>
</section><section id="bayes-rule" class="level2" data-number="13.5"><h2 data-number="13.5" class="anchored" data-anchor-id="bayes-rule">
<span class="header-section-number">13.5</span> Bayes Rule</h2>
<p><strong>Bayes Rule</strong>: Assume that events <span class="math inline">B_1,\ldots,B_k</span> form a partition of the space <span class="math inline">S</span>. Then by the Law of Total Probability</p>
<p><span class="math display">P(B_j|A)= \frac{P(A \cap B_j)} {P(A)} = \frac{P(B_j) P(A|B_j)}{\sum\limits_{i=1}^k P(B_i)P(A|B_i)}</span></p>
<p>If there are only two states of <span class="math inline">B</span>, then this is just</p>
<p><span class="math display">P(B_1|A)=\frac{P(B_1)P(A|B_1)} {P(B_1)P(A|B_1)+P(B_2)P(A|B_2)}</span></p>
<p>Bayes’ rule determines the posterior probability of a state <span class="math inline">P(B_j|A)</span> by calculating the probability <span class="math inline">P(A \cap B_j)</span> that both the event <span class="math inline">A</span> and the state <span class="math inline">B_j</span> will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all <span class="math inline">B_i</span>). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc. The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position.</p>
<p><strong>Prior and Posterior Probabilities</strong>: Above, <span class="math inline">P(B_1)</span> is often called the prior probability, since it’s the probability of <span class="math inline">B_1</span> before anything else is known. <span class="math inline">P(B_1|A)</span> is called the posterior probability, since it’s the probability after other information is taken into account.</p>
<div id="exm-bayesrule" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.7 (Bayes’ Rule) </strong></span>In a given town, 40% of the voters are Democrat and 60% are Republican. The president’s budget is supported by 50% of the Democrats and 90% of the Republicans. If a randomly (equally likely) selected voter is found to support the president’s budget, what is the probability that they are a Democrat?</p>
</div>
<div id="exr-condprobexr" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 13.4 (Conditional Probability) </strong></span>Assume that 2% of the population of the U.S. are members of some extremist militia group. We develop a survey that positively classifies someone as being a member of a militia group given that they are a member 95% of the time and negatively classifies someone as not being a member of a militia group given that they are not a member 97% of the time. What is the probability that someone positively classified as being a member of a militia group is actually a militia member?</p>
</div>
</section><section id="independence" class="level2" data-number="13.6"><h2 data-number="13.6" class="anchored" data-anchor-id="independence">
<span class="header-section-number">13.6</span> Independence</h2>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.5 (Independence) </strong></span>If the occurrence or nonoccurrence of either events <span class="math inline">A</span> and <span class="math inline">B</span> have no effect on the occurrence or nonoccurrence of the other, then <span class="math inline">A</span> and <span class="math inline">B</span> are independent.</p>
</div>
<p>If <span class="math inline">A</span> and <span class="math inline">B</span> are independent, then</p>
<div id="prop-">
<ol type="1">
<li><span class="math inline">P(A|B)=P(A)</span></li>
<li><span class="math inline">P(B|A)=P(B)</span></li>
<li><span class="math inline">P(A\cap B)=P(A)P(B)</span></li>
<li>More generally than the above, <span class="math inline">P(\bigcap_{i=1}^k A_i) = \prod_{i = 1}^K P(A_i)</span>
</li>
</ol>
</div>
<p>Are mutually exclusive events independent of each other?</p>
<p>No.&nbsp;If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn’t have occurred. Because of this, A and B aren’t independent.</p>
<p><strong>Pairwise Independence</strong>: A set of more than two events <span class="math inline">A_1, A_2, \dots, A_k</span> is pairwise independent if <span class="math inline">P(A_i\cap A_j)=P(A_i)P(A_j)</span>, <span class="math inline">\forall i\neq j</span>. Note that this does <strong>not</strong> necessarily imply joint independence.</p>
<p><strong>Conditional Independence</strong>: If <span class="math inline">A</span> and <span class="math inline">B</span> are independent once you know the occurrence of a third event <span class="math inline">C</span>, then <span class="math inline">A</span> and <span class="math inline">B</span> are conditionally independent (conditional on <span class="math inline">C</span>):</p>
<ol type="1">
<li><span class="math inline">P(A|B \cap C)=P(A|C)</span></li>
<li><span class="math inline">P(B|A \cap C)=P(B|C)</span></li>
<li><span class="math inline">P(A\cap B|C)=P(A|C)P(B|C)</span></li>
</ol>
<p>Just because two events are conditionally independent does not mean that they are independent. Actually it is hard to think of real-world things that are “unconditionally” independent. That’s why it’s always important to ask about a finding: What was it conditioned on? For example, suppose that a graduate school admission decisions are done by only one professor, who picks a group of 50 bright students and flips a coin for each student to generate a class of about 25 students. Then the the probability that two students get accepted are conditionally independent, because they are determined by two separate coin tosses. However, this does not mean that their admittance is not completely independent. Knowing that student <span class="math inline">A</span> got in gives us information about whether student <span class="math inline">B</span> got in, if we think that the professor originally picked her pool of 50 students by merit.</p>
<p>Perhaps more counter-intuitively: If two events are already independent, then it might seem that no amount of “conditioning” will make them dependent. But this is not always so. For example<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, suppose I only get a call from two people, Alice and Bob. Let <span class="math inline">A</span> be the event that Alice calls, and <span class="math inline">B</span> be the event that Bob calls. Alice and Bob do not communicate, so <span class="math inline">P(A \mid B) = P(A).</span> But now let <span class="math inline">C</span> be the event that your phone rings. For conditional independence to hold here, then <span class="math inline">P(A \mid C)</span> must be equal to <span class="math inline">P(A \mid B \cap C).</span> But this is not true – <span class="math inline">A \mid C</span> may or may not be true, but <span class="math inline">P(A \mid B \cap C)</span> certainly is true.</p>
</section><section id="random-variables" class="level2" data-number="13.7"><h2 data-number="13.7" class="anchored" data-anchor-id="random-variables">
<span class="header-section-number">13.7</span> Random Variables</h2>
<p>Most questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantitatively, we need a way of mapping events to numbers. A random variable does exactly that.</p>
<div class="cell" data-hash="41_probability_cache/html/fig-rv-image_c8b8d3b63b786e3b723cc54f2739660c">
<div class="cell-output-display">
<div id="fig-rv-image" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/rv.png" class="img-fluid figure-img" width="1070"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;13.2: The Random Variable as a Real-Valued Function</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.6 (Random Variable) </strong></span>A random variable is a measurable function <span class="math inline">X</span> that maps from the sample space <span class="math inline">S</span> to the set of real numbers <span class="math inline">R.</span> It assigns a real number to every outcome <span class="math inline">s \in S</span>.</p>
</div>
<p><a href="#fig-rv-image">Figure&nbsp;<span>13.2</span></a> shows a image of the function. It might seem strange to define a random variable as a function – which is neither random nor variable. The randomness comes from the realization of an event from the sample space <span class="math inline">s</span>.</p>
<p><strong>Randomness</strong> means that the outcome of some experiment is not deterministic, i.e.&nbsp;there is some probability (<span class="math inline">0 &lt; P(A) &lt; 1</span>) that the event will occur.</p>
<p>The support of a random variable is all values for which there is a positive probability of occurrence.</p>
<p>Example: Flip a fair coin two times. What is the sample space?</p>
<p>A random variable must map events to the real line. For example, let a random variable <span class="math inline">X</span> be the number of heads. The event <span class="math inline">(H, H)</span> gets mapped to 2 <span class="math inline">X(s) = 2</span>, and the events <span class="math inline">\{(H, T), (T, H)\}</span> gets mapped to 1 <span class="math inline">(X(s) = 1)</span>, the event <span class="math inline">(T, T)</span> gets mapped to 0 <span class="math inline">(X(s) = 0)</span>.</p>
<p>What are other possible random variables?</p>
</section><section id="distributions" class="level2" data-number="13.8"><h2 data-number="13.8" class="anchored" data-anchor-id="distributions">
<span class="header-section-number">13.8</span> Distributions</h2>
<p>We now have two main concepts in this section – probability and random variables. Given a sample space <span class="math inline">S</span> and the same experiment, both probability and random variables take events as their inputs. But they output different things (probabilities measure the “size” of events, random variables give a number in a way that the analyst chose to define the random variable). How do the two concepts relate?</p>
<p>The concept of distributions is the natural bridge between these two concepts.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.7 (Distribution of a random variable) </strong></span>A distribution of a random variable is a function that specifies the probabilities of all events associated with that random variable. There are several types of distributions: A probability mass function for a discrete random variable and probability density function for a continuous random variable.</p>
</div>
<p>Notice how the definition of distributions combines two ideas of random variables and probabilities of events. First, the distribution considers a random variable, call it <span class="math inline">X</span>. <span class="math inline">X</span> can take a number of possible numeric values.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.8 </strong></span>Consider three binary outcomes, one for each patient recovering from a disease: <span class="math inline">R_i</span> denotes the event in which patient <span class="math inline">i</span> (<span class="math inline">i = 1, 2, 3</span>) recovers from a disease. <span class="math inline">R_1</span>, <span class="math inline">R_2</span>, and <span class="math inline">R_3</span>. How would we represent the total number of people who end up recovering from the disease?</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Define the random variable <span class="math inline">X</span> be the total number of people (out of three) who recover from the disease. Random variables are functions, that take as an input a set of events (in the sample space <span class="math inline">S</span>) and deterministically assigns them to a number of the analyst’s choice.</p>
<p>Recall that with each of these numerical values there is a class of <em>events</em>. In the previous example,</p>
<ul>
<li>For <span class="math inline">X = 3</span> there is one outcome (<span class="math inline">R_1, R_2, R_3</span>)</li>
<li>For <span class="math inline">X = 1</span> there are multiple <span class="math inline">\{(R_1, R_2^c, R_3^c), (R_1^c, R_2, R_3^c), (R_1^c, R_2^c, R_3), \}</span>
</li>
</ul>
<p>Now, the thing to notice here is that each of these events naturally come with a probability associated with them. That is, <span class="math inline">P(R_1, R_2, R_3)</span> is a number from 0 to 1, as is <span class="math inline">P(R_1, R_2^c, R_3^c)</span>. These all have probabilities because they are in the sample space <span class="math inline">S</span>. The function that tells us these probabilities that are associated with a numerical value of a random variable is called a distribution.</p>
<p>In other words, a random variable <span class="math inline">X</span> <em>induces a probability distribution</em> <span class="math inline">P</span> (sometimes written <span class="math inline">P_X</span> to emphasize that the probability density is about the r.v. <span class="math inline">X</span>)</p>
</div>
<section id="discrete-random-variables" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="discrete-random-variables">Discrete Random Variables</h3>
<p>The formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete, and continuous random variables when they are continuous.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.8 (Discrete Random Variable) </strong></span><span class="math inline">X</span> is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples: number of wars per year, heads or tails.</p>
</div>
<p>The distribution of a discrete r.v. is a PMF:</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.9 (Probability Mass Function) </strong></span>For a discrete random variable <span class="math inline">X</span>, the probability mass function (Also referred to simply as the “probability distribution.”) (PMF), <span class="math inline">p(x)=P(X=x)</span>, assigns probabilities to a countable number of distinct <span class="math inline">x</span> values such that</p>
<ol type="1">
<li><span class="math inline">0\le p(x)\le 1</span></li>
<li><span class="math inline">\sum\limits_y p(x)=1</span></li>
</ol>
</div>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.9 </strong></span>For a fair six-sided die, there is an equal probability of rolling any number. Since there are six sides, the probability mass function is then <span class="math inline">p(y)=1/6</span> for <span class="math inline">y=1,\ldots,6</span>, 0 otherwise.</p>
</div>
<p>In a discrete random variable, <strong>cumulative distribution function</strong> (Also referred to simply as the “cumulative distribution” or previously as the “distribution function”), <span class="math inline">F(x)</span> or <span class="math inline">P(X\le x)</span>, is the probability that <span class="math inline">X</span> is less than or equal to some value <span class="math inline">x</span>, or <span class="math display">P(X\le x)=\sum\limits_{i\le x} p(i)</span></p>
<p>Properties a CDF must satisfy:</p>
<ol type="1">
<li>
<span class="math inline">F(x)</span> is non-decreasing in <span class="math inline">x</span>.</li>
<li>
<span class="math inline">\lim\limits_{x \to -\infty} F(x) = 0</span> and <span class="math inline">\lim\limits_{x \to \infty} F(x) = 1</span>
</li>
<li>
<span class="math inline">F(x)</span> is right-continuous.</li>
</ol>
<p>Note that <span class="math inline">P(X &gt; x) = 1 - P(X \le x)</span>.</p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.10 </strong></span>For a fair die with its value as <span class="math inline">Y</span>, What are the following?</p>
<ol type="1">
<li><span class="math inline">P(Y\le 1)</span></li>
<li><span class="math inline">P(Y\le 3)</span></li>
<li><span class="math inline">P(Y\le 6)</span></li>
</ol>
</div>
</section><section id="continuous-random-variables" class="level3 unnumbered"><h3 class="unnumbered anchored" data-anchor-id="continuous-random-variables">Continuous Random Variables</h3>
<p>We also have a similar definition for <em>continuous</em> random variables.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.10 (Continuous Random Variable) </strong></span><span class="math inline">X</span> is a continuous random variable if there exists a nonnegative function <span class="math inline">f(x)</span> defined for all real <span class="math inline">x\in (-\infty,\infty)</span>, such that for any interval <span class="math inline">A</span>, <span class="math inline">P(X\in A)=\int\limits_A f(x)dx</span>. Examples: age, income, GNP, temperature.</p>
</div>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.11 (Probability Density Function) </strong></span>The function <span class="math inline">f</span> above is called the probability density function (pdf) of <span class="math inline">X</span> and must satisfy</p>
<p><span class="math display">f(x)\ge 0</span></p>
<p><span class="math display">\int\limits_{-\infty}^\infty f(x)dx=1</span></p>
<p>Note also that <span class="math inline">P(X = x)=0</span> — i.e., the probability of any point <span class="math inline">y</span> is zero.</p>
</div>
<p>For both discrete and continuous random variables, we have a unifying concept of another measure: the cumulative distribution:</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.12 (Cumulative Distribution Function) </strong></span>Because the probability that a continuous random variable will assume any particular value is zero, we can only make statements about the probability of a continuous random variable being within an interval. The cumulative distribution gives the probability that <span class="math inline">Y</span> lies on the interval <span class="math inline">(-\infty,y)</span> and is defined as <span class="math display">F(x)=P(X\le x)=\int\limits_{-\infty}^x f(s)ds.</span> Note that <span class="math inline">F(x)</span> has similar properties with continuous distributions as it does with discrete - non-decreasing, continuous (not just right-continuous), and <span class="math inline">\lim\limits_{x \to -\infty} F(x) = 0</span> and <span class="math inline">\lim\limits_{x \to \infty} F(x) = 1</span>.</p>
</div>
<p>We can also make statements about the probability of <span class="math inline">Y</span> falling in an interval <span class="math inline">a\le y\le b</span>.</p>
<p><span class="math display">P(a\le x\le b)=\int\limits_a^b f(x)dx</span></p>
<p>The PDF and CDF are linked by the integral: The CDF of the integral of the PDF: <span class="math display">f(x) = F'(x)=\frac{dF(x)}{dx}</span></p>
<div id="exm-" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.11 </strong></span>For <span class="math inline">f(y)=1, \quad 0&lt;y&lt;1</span>, find: (1) The CDF <span class="math inline">F(y)</span> and (2) The probability <span class="math inline">P(0.5&lt;y&lt;0.75)</span>.</p>
</div>
</section></section><section id="answers-to-examples-and-exercises" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="answers-to-examples-and-exercises">Answers to Examples and Exercises</h2>
<p>Answer to <a href="#exm-counting">Example&nbsp;<span>13.2</span></a>:</p>
<ol type="1">
<li><p><span class="math inline">5 \times 5 \times 5 = 125</span></p></li>
<li><p><span class="math inline">5 \times 4 \times 3 = 60</span></p></li>
<li><p><span class="math inline">\binom{5}{3} = \frac{5!}{(5-3)!3!} = \frac{5 \times 4}{2 \times 1} = 10</span></p></li>
</ol>
<p>Answer to <a href="#exr-counting1">Exercise&nbsp;<span>13.1</span></a>:</p>
<ol type="1">
<li><span class="math inline">\binom{52}{4} = \frac{52!}{(52-4)!4!} = 270725</span></li>
</ol>
<p>Answer to <a href="#exm-sets">Example&nbsp;<span>13.3</span></a>:</p>
<ol type="1">
<li>{1, 2, 3, 4, 5, 6}</li>
<li>{5, 6}</li>
<li>{1, 2, 7, 8, 9, 10}</li>
<li>{3, 4}</li>
</ol>
<p>Answer to <a href="#exr-sets1">Exercise&nbsp;<span>13.2</span></a>:</p>
<p>Sample Space: {2, 3, 4, 5, 6, 7, 8}</p>
<ol type="1">
<li>{3, 4, 5, 6, 7}</li>
<li>{4, 5, 6}</li>
</ol>
<p>Answer to <a href="#exm-prob">Example&nbsp;<span>13.4</span></a>:</p>
<ol type="1">
<li><p><span class="math inline">{1, 2, 3, 4, 5, 6}</span></p></li>
<li><p><span class="math inline">\frac{1}{6}</span></p></li>
<li><p><span class="math inline">0</span></p></li>
<li><p><span class="math inline">\frac{1}{2}</span></p></li>
<li><p><span class="math inline">\frac{4}{6} = \frac{2}{3}</span></p></li>
<li><p><span class="math inline">1</span></p></li>
<li><p><span class="math inline">A\cup B=\{1, 2, 3, 4, 6\}</span>, <span class="math inline">A\cap B=\{2\}</span>, <span class="math inline">\frac{5}{6}</span></p></li>
</ol>
<p>Answer to <a href="#exr-prob1">Exercise&nbsp;<span>13.3</span></a>:</p>
<ol type="1">
<li><p><span class="math inline">P(X = 5) = \frac{4}{16}</span>, <span class="math inline">P(X = 3) = \frac{2}{16}</span>, <span class="math inline">P(X = 6) = \frac{3}{16}</span></p></li>
<li><p>What is <span class="math inline">P(X=5 \cup X = 3)^C = \frac{10}{16}</span>?</p></li>
</ol>
<p>Answer to <a href="#exm-condprobexm1">Example&nbsp;<span>13.5</span></a>:</p>
<ol type="1">
<li><p><span class="math inline">\frac{n_{ab} + n_{ab^c}}{N}</span></p></li>
<li><p><span class="math inline">\frac{n_{ab} + n_{a^cb}}{N}</span></p></li>
<li><p><span class="math inline">\frac{n_{ab}}{N}</span></p></li>
<li><p><span class="math inline">\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{a^cb}}{N}} = \frac{n_{ab}}{n_{ab} + n_{a^cb}}</span></p></li>
<li><p><span class="math inline">\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{ab^c}}{N}} = \frac{n_{ab}}{n_{ab} + n_{ab^c}}</span></p></li>
</ol>
<p>Answer to <a href="#exm-condprobexm2">Example&nbsp;<span>13.6</span></a>:</p>
<p><span class="math inline">P(1|Odd) = \frac{P(1 \cap Odd)}{P(Odd)} = \frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}</span></p>
<p>Answer to <a href="#exm-bayesrule">Example&nbsp;<span>13.7</span></a>:</p>
<p>We are given that</p>
<p><span class="math display">P(D) = .4, P(D^c) = .6, P(S|D) = .5, P(S|D^c) = .9</span></p>
<p>Using this, Bayes’ Law and the Law of Total Probability, we know:</p>
<p><span class="math display">P(D|S) = \frac{P(D)P(S|D)}{P(D)P(S|D) + P(D^c)P(S|D^c)}</span></p>
<p><span class="math display">P(D|S) = \frac{.4 \times .5}{.4 \times .5 + .6 \times .9 } = .27</span></p>
<p>Answer to <a href="#exr-condprobexr">Exercise&nbsp;<span>13.4</span></a>:</p>
<p>We are given that</p>
<p><span class="math display">P(M) = .02, P(C|M) = .95, P(C^c|M^c) = .97</span></p>
<p><span class="math display">P(M|C) = \frac{P(C|M)P(M)}{P(C)}</span></p>
<p><span class="math display">= \frac{P(C|M)P(M)}{P(C|M)P(M) + P(C|M^c)P(M^c)}</span></p>
<p><span class="math display">= \frac{P(C|M)P(M)}{P(C|M)P(M) + [1-P(C^c|M^c)]P(M^c)}</span></p>
<p><span class="math display"> = \frac{.95 \times .02}{.95 \times .02 + .03 \times .98} = .38</span></p>


<!-- -->

</section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1"><p>Images of Probability and Random Variables drawn by Shiro Kuriwaki and inspired by Blitzstein and Morris<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Example taken from Blitzstein and Hwang, Example 2.5.10<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./34_intergrals.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Integral Calculus</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./42_distribution.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Summarizing Distributions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Probability Theory {#probability-theory}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>Probability and Inferences are mirror images of each other, and both are integral to social science. Probability quantifies uncertainty, which is important because many things in the social world are at first uncertain. Inference is then the study of how to learn about facts you don't observe from facts you do  observe.</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include = FALSE}</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">knitr.graphics.auto_pdf =</span> <span class="cn">TRUE</span>) <span class="co"># use pdf for images</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## Counting Rules</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Probability in high school is usually really about combinatorics: the probability of event _A_ is the number of ways in which _A_ can occur divided by the number of all other possibilities. This is a very simplified version of probability, which we can call the "counting definition of probability", essentially because each possible event to count is often equally likely and discrete. But it is still good to review the underlying rules here.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>__Fundamental Theorem of Counting__: If an object has $j$ different characteristics that are independent of each other, and each characteristic $i$ has $n_i$ ways of being expressed, then there are $\prod_{i = 1}^j n_i$ possible unique objects.</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>:::{#exm-countingrules}</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>Suppose we are given a stack of cards. Cards can be either red or black and can take on any of 13 values. There is only one of each color-number combination. In this case,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$j =$</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$n_{\text{color}} =$ </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$n_{\text{number}} =$ </span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Number of Outcomes $=$</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>We often need to count the number of ways to choose a subset from some set of possibilities.  The number of outcomes depends on two characteristics of the process: does the order matter and is replacement allowed?</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>It is useful to think of any problem concretely, e.g. through a __sampling table__: If there are $n$ objects which are numbered 1 to $n$ and we select $k &lt; n$ of them, how many different outcomes are possible?</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>If the order in which a given object is selected matters, selecting 4 numbered objects in the following order (1, 3, 7, 2) and selecting the same four objects but in a different order such as (7, 2, 1, 3) will be counted as different outcomes. </span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>If replacement is allowed, there are always the same $n$ objects to select from. However, if replacement is not allowed, there is always one less option than the previous round when making a selection. For example, if replacement is not allowed and I am selecting 3 elements from the following set {1, 2, 3, 4, 5, 6}, I will have 6 options at first, 5 options as I make my second selection, and 4 options as I make my third. </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>So if ___order matters___ AND we are sampling ___with replacement___, the number of different outcomes is $n^k$.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>If  ___order matters___ AND we are sampling ___without replacement___, the number of different outcomes is $n(n-1)(n-2)...(n-k+1)=\frac{n!}{(n-k)!}$.</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>If  ___order doesn't matter___ AND we are sampling ___without replacement___, the number of different outcomes is $\binom{n}{k} = \frac{n!}{(n-k)!k!}$.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>Expression $\binom{n}{k}$ is read as "n choose k" and denotes $\frac{n!}{(n-k)!k!}$. Also, note that $0! = 1$.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>:::{#exm-counting}</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="fu">### Counting</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there?</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Ordered, with replacement $=$ </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Ordered, without replacement $=$ </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Unordered, without replacement $=$ </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>:::{#exr-counting1}</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="fu">### Counting</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>Four cards are selected from a deck of 52 cards. Once a card has been drawn, it is not reshuffled back into the deck. Moreover, we care only about the complete hand that we get (i.e. we care about the set of selected cards, not the sequence in which it was drawn). How many possible outcomes are there?</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sets {#setoper}</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>Probability is about quantifying the uncertainty of events. _Sets_ (set theory) are the mathematical way we choose to formalize those events. Events are not inherently numerical: the onset of war or the stock market crashing is not inherently a number. Sets can define such events, and we wrap math around so that we have a transparent language to communicate about those events. _Measure theory_ might sound mysterious or hard, but it is also just a mathematical way to quantify things like length, volume, and mass. Probability can be thought of as a particular application of measure theory where we want to quantify the measure of a set. </span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>__Set__ : A set is any well defined collection of elements.  If $x$ is an element of $S$, $x \in S$.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>__Sample Space (S)__:  A set or collection of all possible outcomes from some process.  Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable).</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>Examples:</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Discrete:  the numbers on a die, whether a vote cast is republican or democrat.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Continuous: GNP, arms spending, age.</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>__Event__: Any collection of possible outcomes of an experiment. Any subset of the full set of possibilities, including the full set itself. Event A $\subset$ S.</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>__Empty Set__: a set with no elements.  $S = <span class="sc">\{\}</span>$. It is denoted by the symbol $\emptyset$.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>Set operations:</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>__Union__: The union of two sets $A$ and $B$, $A \cup B$, is the set containing all of the elements in $A$ or $B$. $$A_1 \cup A_2  \cup \cdots \cup A_n = \bigcup_{i=1}^n A_i$$</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>__Intersection__: The intersection of sets $A$ and $B$, $A \cap B$, is the set containing all of the elements in both $A$ and $B$. $$A_1 \cap A_2  \cap \cdots \cap A_n = \bigcap_{i=1}^n A_i$$</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>__Complement__: If set $A$ is a subset of $S$, then the complement of $A$, denoted $A^C$, is the set containing all of the elements in $S$ that are not in $A$.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>Properties of set operations:</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>__Commutative__: $A \cup B = B \cup A$; $A \cap B = B \cap A$</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>__Associative__: $A \cup (B \cup C) = (A \cup B) \cup C$; $A \cap (B \cap C) = (A \cap B) \cap C$</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>__Distributive__: $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$; $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>__de Morgan's laws__: $(A \cup B)^C = A^C \cap B^C$; $(A \cap B)^C = A^C \cup B^C$</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>__Disjointness__: Sets are disjoint when they do not intersect, such that $A \cap B = \emptyset$.  A collection of sets is pairwise disjoint (**mutually exclusive**) if, for all $i \neq j$, $A_i \cap A_j = \emptyset$.  A collection of sets form a partition of set $S$ if they are pairwise disjoint and they cover set $S$, such that $\bigcup_{i = 1}^k A_i = S$.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>:::{#exm-sets}</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sets</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>Let set $A$ be {1, 2, 3, 4}, $B$ be {3, 4, 5, 6}, and $C$ be {5, 6, 7, 8}. Sets $A$, $B$, and $C$ are all subsets of the sample space $S$ which is {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>Write out the following sets:</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$A \cup B$</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$C \cap B$</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$B^c$</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>$A \cap (B \cup C)$</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>:::{#exr-sets1}</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>Suppose you had a pair of four-sided dice. You sum the results from a single toss.</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>What is the set of possible outcomes (i.e. the sample space)?</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>Consider subsets A {2, 8} and B {2,3,7} of the sample space you found. What is</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$A^c$</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$(A \cup B)^c$</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu">## Probability {#probdef}</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, #fig-prob-image, fig.cap='Probablity as a Measure^[Images of Probability and Random Variables drawn by Shiro Kuriwaki and inspired by Blitzstein and Morris]', echo = FALSE}</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'images/probability.png'</span>)</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Definitions: Formal and Informal {-}</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>Many things in the world are uncertain. In everyday speech, we say that we are  _uncertain_ about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules (@fig-prob-image). A different model of uncertainty would, of course, have a set of rules different from anything we discuss here.  Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty.</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>__Probability Distribution Function__: a mapping of each event in the sample space $S$ to the real numbers that satisfy the following three axioms (also called Kolmogorov's Axioms).</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>Formally, </span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>:::{#def-prob}</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>Probability is a function that maps events to a real number, obeying the axioms of probability.</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>The axioms of probability make sure that the separate events add up in terms of probability, and -- for standardization purposes -- that they add up to 1.</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### Axioms of Probability</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>For any event $A$, $P(A)\ge 0$.</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$P(S)=1$</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>The Countable Additivity Axiom: For any sequence of _disjoint_ (mutually exclusive) events $A_1,A_2,\ldots$ (of which there may be infinitely many), $$P\left( \bigcup\limits_{i=1}^k</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>A_i\right)=\sum\limits_{i=1}^k P(A_i)$$</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>The last axiom is an extension of a union to infinite sets. When there are only two events in the space, it boils down to:</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>P(A_1 \cup A_2) = P(A_1) + P(A_2) \quad\text{for disjoint } A_1, A_2</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Operations  {-}</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>Using these three axioms, we can define all of the common rules of probability.</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>:::{#prop-prob}</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>$P(\emptyset)=0$</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>For any event $A$, $0\le P(A) \le 1$</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$P({A}^C)=1-P(A)$</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>If $A\subset B$ ($A$ is a subset of $B$), then $P(A)\le P(B)$</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>For _any_ two events $A$ and $B$, $P(A\cup B)=P(A)+P(B)-P(A\cap B)$</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Boole's Inequality: For any sequence of $n$ events (which need not be disjoint) $A_1,A_2,\ldots,A_n$,  then $$P\left( \bigcup\limits_{i=1}^n A_i\right) \leq \sum\limits_{i=1}^n P(A_i)$$</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>:::{#exm-prob}</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>Assume we have an evenly-balanced, six-sided die.</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>Then,</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Sample space $S$ = </span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$P(1)=\cdots=P(6)=$</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$P(\emptyset)=P(7)=$</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>$P\left( <span class="sc">\{</span> 1, 3, 5 <span class="sc">\}</span> \right)=$</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>$P\left( <span class="sc">\{</span> 1, 2 <span class="sc">\}</span>^C \right)= P\left( <span class="sc">\{</span> 3, 4, 5, 6 <span class="sc">\}</span>\right)=$</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Let $A=<span class="sc">\{</span> 1,2,3,4,5 <span class="sc">\}</span>\subset S$.  Then $P(A)=5/6&lt;P(S)=$ </span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="ss">7.  </span>Let $A=<span class="sc">\{</span> 1, 2, 3 <span class="sc">\}</span>$ and $B=<span class="sc">\{</span> 2, 4, 6 <span class="sc">\}</span>$.  Then $A\cup B$? $A\cap B$? $P(A \cup B)$?</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>:::{#exr-prob1}</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>Suppose you had a pair of four-sided dice. You sum the results from a single toss. Let us call this sum, or the outcome, X.</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>What is $P(X = 5)$, $P(X = 3)$, $P(X = 6)$?</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>What is $P(X=5 \cup X = 3)^C$? </span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conditional Probability</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>__Conditional Probability__:  The conditional probability $P(A|B)$ of an event $A$ is the probability of $A$, given that another event $B$ has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event.  It is calculated as</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>$$P(A|B)=\frac{P(A\cap B)}{P(B)}$$</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>Note that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability.</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>:::{#exm-condprobexm1}</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditional Probability</span></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>Assume $A$ and $B$ occur with the following frequencies: $\quad$</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a><span class="in">           $A$          $A^c$</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>--------- ---------  ---------</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>$B$       $n_{ab}$   $n_{a^cb}$</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>$B^C$     $n_{ab^c}$ $n_{(ab)^c}$</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>and let $n_{ab}+n_{a^Cb}+n_{ab^C}+n_{(ab)^C}=N$.  Then</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>$P(A)=$ </span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>$P(B)=$ </span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>$P(A\cap B)=$ </span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>$P(A|B)= \frac{P(A\cap B)}{P(B)}=$ </span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>$P(B|A)= \frac{P(A\cap B)}{P(A)}=$ </span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>:::{#exm-condprobexm2}</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditional Probability 2</span></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a> A six-sided die is rolled.  What is the probability of a 1, given the outcome is an odd number? </span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>You could rearrange the fraction to highlight how a joint probability could be expressed as the product of a conditional probability. </span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multiplicative Law of Probability</span></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>The probability of the intersection of two events $A$ and $B$ is </span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>$$P(A\cap B)=P(A)P(B|A)=P(B)P(A|B)$$ </span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>which follows directly from the definition of conditional probability. More generally,</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>P(A_1\cap \cdots\cap A_k) = &amp;P(A_k| A_{k-1}\cap \cdots \cap A_1) <span class="sc">\\</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>\times &amp;P(A_{k-1}|A_{k-2}\cap \cdots A_1) <span class="sc">\\</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>\vdots &amp; <span class="sc">\\</span></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>\times &amp;P(A_2|A_1) <span class="sc">\\</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>\times &amp;P(A_1)</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>Sometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate $P(A)$ directly.</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="fu">### Law of Total Probability</span></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>Let $S$ be the sample space of some experiment and let the disjoint $k$ events $B_1,\ldots,B_k$ partition $S$, such that $P(B_1\cup ... \cup B_k) = P(S) = 1$.  If $A$ is some other event in $S$, then the events $A\cap B_1, A\cap B_2, \ldots, A\cap B_k$ will form a partition of $A$ and we can write $A$ as $$A=(A\cap B_1)\cup\cdots\cup (A\cap B_k)$$.  </span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a>Since the $k$ events are disjoint,</span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a>P(A)&amp;=\sum\limits_{i=1}^k P(A \cap B_i)<span class="sc">\\</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>    &amp;=\sum\limits_{i=1}^k P(B_i)P(A|B_i)</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bayes Rule</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>__Bayes Rule__: Assume that events $B_1,\ldots,B_k$ form a partition of the space $S$.  Then by the Law of Total Probability </span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a>$$P(B_j|A)= \frac{P(A \cap B_j)} {P(A)} = \frac{P(B_j) P(A|B_j)}{\sum\limits_{i=1}^k P(B_i)P(A|B_i)}$$</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>If there are only two states of $B$, then this is just </span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a>$$P(B_1|A)=\frac{P(B_1)P(A|B_1)} {P(B_1)P(A|B_1)+P(B_2)P(A|B_2)}$$</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>Bayes' rule  determines the posterior probability of a state  $P(B_j|A)$ by calculating the probability $P(A \cap B_j)$ that both the event $A$ and the state $B_j$ will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all $B_i$). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc.  The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position.</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>__Prior and Posterior Probabilities__:  Above, $P(B_1)$ is often called the prior probability, since it's the probability of $B_1$ before anything else is known.  $P(B_1|A)$ is called the posterior probability, since it's the probability after other information is taken into account.</span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>:::{#exm-bayesrule}</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayes' Rule</span></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>In a given town, 40% of the voters are Democrat and 60% are Republican. The president's budget is supported by 50% of the Democrats and 90% of the Republicans. If a randomly (equally likely) selected voter is found to support the president's budget, what is the probability that they are a Democrat?</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>:::{#exr-condprobexr}</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="fu">### Conditional Probability</span></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>Assume that 2% of the population of the U.S. are members of some extremist militia group. We develop a survey that positively classifies someone as being a member of a militia group given that they are a member 95% of the time and negatively classifies someone as not being a member of a militia group given that they are not a member 97% of the time. What is the probability that someone positively classified as being a member of a militia group is actually a militia member?</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a><span class="fu">## Independence </span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a><span class="fu">### Independence</span></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>If the occurrence or nonoccurrence of either events $A$ and $B$ have no effect on the occurrence or nonoccurrence of the other, then $A$ and $B$ are independent. </span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>If $A$ and $B$ are independent, then</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>:::{#prop-}</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$P(A|B)=P(A)$</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$P(B|A)=P(B)$</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$P(A\cap B)=P(A)P(B)$</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>More generally than the above, $P(\bigcap_{i=1}^k A_i) = \prod_{i = 1}^K P(A_i)$</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>Are mutually exclusive events independent of each other?</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>No. If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn't have occurred. Because of this, A and B aren't independent.</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>**Pairwise Independence**: A set of more than two events $A_1, A_2, \dots, A_k$ is pairwise independent if  $P(A_i\cap A_j)=P(A_i)P(A_j)$, $\forall i\neq j$.  Note that this does __not__ necessarily imply joint independence.</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>**Conditional Independence**: If $A$ and $B$ are independent once you know the occurrence of a third event $C$, then $A$ and $B$ are conditionally independent (conditional on $C$):</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$P(A|B \cap C)=P(A|C)$</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$P(B|A \cap C)=P(B|C)$</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$P(A\cap B|C)=P(A|C)P(B|C)$</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a>Just because two events are conditionally independent does not mean that they are independent. Actually it is hard to think of real-world things that are "unconditionally" independent. That's why it's always important to ask about a finding: What was it conditioned on?  For example, suppose that a graduate school admission decisions are done by only one professor, who picks a group of 50 bright students and flips a coin for each student to generate a class of about 25 students. Then the the probability that two students get accepted are conditionally independent, because they are determined by two separate coin tosses. However, this does not mean that their admittance is not completely independent. Knowing that student $A$ got in gives us information about whether student $B$ got in, if we think that the professor originally picked her pool of 50 students by merit. </span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>Perhaps more counter-intuitively: If two events are already independent, then it might seem that no amount of "conditioning" will make them dependent. But this is not always so. For example^<span class="co">[</span><span class="ot">Example taken from Blitzstein and Hwang, Example 2.5.10</span><span class="co">]</span>, suppose I only get a call from two people, Alice and Bob. Let $A$ be the event that Alice calls, and $B$ be the event that Bob calls. Alice and Bob do not communicate, so $P(A \mid B) = P(A).$ But now let $C$ be the event that your phone rings. For conditional independence to hold here, then $P(A \mid C)$ must be equal to $P(A \mid B \cap C).$ But this is not true -- $A \mid C$  may or may not be true, but $P(A \mid B \cap C)$ certainly is true. </span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Variables</span></span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a>Most questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantitatively, we need a way of mapping events to numbers. A random variable does exactly that.</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, #fig-rv-image, fig.cap='The Random Variable as a Real-Valued Function', echo = FALSE}</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">'images/rv.png'</span>)</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Variable</span></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>A random variable is a measurable function $X$ that maps from the sample space $S$ to the set of real numbers $R.$ It assigns a real number to every outcome $s \in S$. </span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>@fig-rv-image shows a image of the function. It might seem strange to define a random variable as a function -- which is neither random nor variable. The randomness comes from the realization of an event from the sample space $s$.</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>__Randomness__  means that the outcome of some experiment is not deterministic, i.e. there is some probability ($0 &lt; P(A) &lt; 1$) that the event will occur.</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>The support of a random variable is all values for which there is a positive probability of occurrence.</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>Example: Flip a fair coin two times.   What is the sample space? </span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>A random variable must map events to the real line. For example, let a random variable $X$ be the number of heads. The event $(H, H)$ gets mapped to 2 $X(s) = 2$, and the events $<span class="sc">\{</span>(H, T), (T, H)<span class="sc">\}</span>$ gets mapped to 1 $(X(s) = 1)$, the event $(T, T)$ gets mapped to 0 $(X(s) = 0)$. </span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>What are other possible random variables?</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="fu">## Distributions</span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a>We now have two main concepts in this section -- probability and random variables. Given a sample space $S$ and the same experiment, both probability and random variables take events as their inputs. But they output different things (probabilities measure the "size" of events, random variables give a number in a way that the analyst chose to define the random variable). How do the two concepts relate?</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a>The concept of distributions is the natural bridge between these two concepts.</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="fu">### Distribution of a random variable</span></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a>A distribution of a random variable is a function that specifies the probabilities of all events associated with that random variable. There are several types of distributions: A probability mass function for a discrete random variable and probability density function for a continuous random variable.</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>Notice how the definition of distributions combines two ideas of random variables and probabilities of events. First, the distribution considers a random variable, call it $X$. $X$ can take a number of possible numeric values. </span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>Consider three binary outcomes, one for each patient recovering from a disease: $R_i$ denotes the event in which patient $i$ ($i = 1, 2, 3$) recovers from a disease. $R_1$, $R_2$, and $R_3$.  How would we represent the total number of people who end up recovering from the disease?</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a>:::{.solution}</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a>Define the random variable $X$ be the total number of people (out of three) who recover from the disease. Random variables are functions, that take as an input a set of events (in the sample space $S$) and deterministically assigns them to a number of the analyst's choice.</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a>Recall that with each of these numerical values there is a class of *events*. In the previous example, </span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For $X = 3$ there is one outcome ($R_1, R_2, R_3$) </span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For $X = 1$ there are multiple $<span class="sc">\{</span>(R_1, R_2^c, R_3^c), (R_1^c, R_2, R_3^c), (R_1^c, R_2^c, R_3), <span class="sc">\}</span>$</span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a>Now, the thing to notice here is that each of these events naturally come with a probability associated with them. That is, $P(R_1, R_2, R_3)$ is a number from 0 to 1, as is $P(R_1, R_2^c, R_3^c)$. These all have probabilities because they are in the sample space $S$. The function that tells us these probabilities that are associated with a numerical value of a random variable is called a distribution.</span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a>In other words, a random variable $X$ *induces a probability distribution* $P$ (sometimes written $P_X$ to emphasize that the probability density is about the r.v. $X$)</span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="fu">### Discrete Random Variables {-}</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>The formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete,  and continuous random variables when they are continuous.</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="fu">### Discrete Random Variable</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>$X$ is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples:  number of wars per year, heads or tails.</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>The distribution of a discrete r.v. is a PMF:</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Mass Function</span></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>For a discrete random variable $X$, the probability mass function (Also referred to simply as the "probability distribution.") (PMF), $p(x)=P(X=x)$, assigns probabilities to a countable number of distinct $x$ values such that</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$0\le p(x)\le 1$</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>$\sum\limits_y p(x)=1$</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a>For a fair six-sided die, there is an equal probability of rolling any number.  Since there are six sides, the probability mass function is then $p(y)=1/6$ for $y=1,\ldots,6$, 0 otherwise.</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a>In a discrete random variable,  __cumulative distribution function__ (Also referred to simply as the "cumulative distribution" or previously as the "distribution function"), $F(x)$ or $P(X\le x)$, is the probability that $X$ is less than or equal to some value $x$, or $$P(X\le x)=\sum\limits_{i\le x} p(i)$$</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>Properties a CDF must satisfy:</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$F(x)$ is non-decreasing in $x$.</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$\lim\limits_{x \to -\infty} F(x) = 0$ and $\lim\limits_{x \to \infty} F(x) = 1$</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$F(x)$ is right-continuous.</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>Note that $P(X &gt; x) = 1 - P(X \le x)$.</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>For a fair die with its value as $Y$, What are the following?</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$P(Y\le 1)$</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$P(Y\le 3)$</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$P(Y\le 6)$</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a><span class="fu">### Continuous Random Variables {-}</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>We also have a similar definition for _continuous_ random variables. </span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a><span class="fu">### Continuous Random Variable</span></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>$X$ is a continuous random variable if there exists a nonnegative function $f(x)$ defined for all real $x\in (-\infty,\infty)$, such that for any interval $A$, $P(X\in A)=\int\limits_A f(x)dx$. Examples: age, income, GNP, temperature.</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a><span class="fu">### Probability Density Function</span></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>The function $f$ above is called the probability density function (pdf) of $X$ and must satisfy</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a>$$f(x)\ge 0$$</span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>$$\int\limits_{-\infty}^\infty f(x)dx=1$$</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a>Note also that $P(X = x)=0$ --- i.e., the probability of any point $y$ is zero.</span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a>For both discrete and continuous random variables, we have a unifying concept of another measure: the cumulative distribution: </span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a>:::{#def-}</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cumulative Distribution Function</span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>Because the probability that a continuous random variable will assume any particular value is zero, we can only make statements about the probability of a continuous random variable being within an interval.  The cumulative distribution gives the probability that $Y$ lies on the interval $(-\infty,y)$ and is defined as $$F(x)=P(X\le x)=\int\limits_{-\infty}^x f(s)ds.$$  Note that $F(x)$ has similar  properties with continuous distributions as it does with discrete - non-decreasing, continuous (not just right-continuous), and $\lim\limits_{x \to -\infty} F(x) = 0$ and $\lim\limits_{x \to \infty} F(x) = 1$.</span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>We can also make statements about the probability of $Y$ falling in an interval $a\le y\le b$. </span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>$$P(a\le x\le b)=\int\limits_a^b f(x)dx$$</span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>The PDF and CDF are linked by the integral: The CDF of the integral of the PDF: $$f(x) = F'(x)=\frac{dF(x)}{dx}$$</span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>:::{#exm-}</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>For $f(y)=1, \quad 0&lt;y&lt;1$, find: (1) The CDF $F(y)$ and  (2) The probability $P(0.5&lt;y&lt;0.75)$.</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a><span class="fu">## Answers to Examples and Exercises  {-}</span></span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>Answer to @exm-counting:</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$5 \times 5 \times 5 = 125$</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$5 \times 4 \times 3 = 60$</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$\binom{5}{3} = \frac{5!}{(5-3)!3!} = \frac{5 \times 4}{2 \times 1} = 10$</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>Answer to @exr-counting1:</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$\binom{52}{4} = \frac{52!}{(52-4)!4!} = 270725$</span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>Answer to @exm-sets:</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>{1, 2, 3, 4, 5, 6}</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>{5, 6}</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>{1, 2, 7, 8, 9, 10}</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>{3, 4}</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a>Answer to @exr-sets1:</span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a>Sample Space: {2, 3, 4, 5, 6, 7, 8}</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>{3, 4, 5, 6, 7}</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>{4, 5, 6}</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>Answer to @exm-prob:</span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>${1, 2, 3, 4, 5, 6}$</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$\frac{1}{6}$</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$0$</span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>$\frac{1}{2}$</span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>$\frac{4}{6} = \frac{2}{3}$</span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>$1$</span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>$A\cup B=<span class="sc">\{</span>1, 2, 3, 4, 6<span class="sc">\}</span>$, $A\cap B=<span class="sc">\{</span>2<span class="sc">\}</span>$, $\frac{5}{6}$</span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a>Answer to @exr-prob1:</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$P(X = 5) = \frac{4}{16}$, $P(X = 3) = \frac{2}{16}$, $P(X = 6) = \frac{3}{16}$</span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>What is $P(X=5 \cup X = 3)^C = \frac{10}{16}$? </span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>Answer to @exm-condprobexm1:</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>$\frac{n_{ab} + n_{ab^c}}{N}$</span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>$\frac{n_{ab} + n_{a^cb}}{N}$</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>$\frac{n_{ab}}{N}$</span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>$\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{a^cb}}{N}} = \frac{n_{ab}}{n_{ab} + n_{a^cb}}$</span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>$\frac{\frac{n_{ab}}{N}}{\frac{n_{ab} + n_{ab^c}}{N}} = \frac{n_{ab}}{n_{ab} + n_{ab^c}}$</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a>Answer to @exm-condprobexm2:</span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a>$P(1|Odd) = \frac{P(1 \cap Odd)}{P(Odd)} = \frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}$</span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>Answer to @exm-bayesrule:</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a>We are given that</span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>$$P(D) = .4, P(D^c) = .6, P(S|D) = .5, P(S|D^c) = .9$$</span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>Using this, Bayes' Law and the Law of Total Probability, we know: </span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>$$P(D|S) = \frac{P(D)P(S|D)}{P(D)P(S|D) + P(D^c)P(S|D^c)}$$</span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>$$P(D|S) = \frac{.4 \times .5}{.4 \times .5 + .6 \times .9 } = .27$$</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a>Answer to @exr-condprobexr:</span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>We are given that</span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>$$P(M) = .02, P(C|M) = .95, P(C^c|M^c) = .97$$</span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a>$$P(M|C) = \frac{P(C|M)P(M)}{P(C)}$$</span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a>$$= \frac{P(C|M)P(M)}{P(C|M)P(M) + P(C|M^c)P(M^c)}$$</span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a>$$= \frac{P(C|M)P(M)}{P(C|M)P(M) + <span class="co">[</span><span class="ot">1-P(C^c|M^c)</span><span class="co">]</span>P(M^c)}$$</span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a>$$ = \frac{.95 \times .02}{.95 \times .02 + .03 \times .98} = .38$$</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>